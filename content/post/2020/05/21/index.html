---
title: 'Presentation Data Science and Decision Making 1'
authors: 
  - admin
date: '2020-05-21'
slug: exploratory-data-analysis-basics-part2
categories:
- R and Python
tags:
- R Markdown
- reticulate
- pandas
- dplyr
- modeling

subtitle: 'Using multiple packages from R and Python'
summary: 'Part of our gradution grading exercises'
output:
  blogdown::html_page:
    toc: true # table of content true
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>

<div id="TOC">
<ul>
<li><a href="#goal">Goal</a></li>
<li><a href="#python">Python</a>
<ul>
<li><a href="#import-libraries">Import libraries</a></li>
<li><a href="#read-feather-data-frame">Read feather data frame</a></li>
<li><a href="#describe-the-dataframe">Describe the dataframe</a></li>
<li><a href="#drop-features">Drop features</a></li>
<li><a href="#rename-target">Rename target</a></li>
<li><a href="#na-enconding">NA enconding</a></li>
<li><a href="#feature-engeniring">Feature Engeniring</a></li>
<li><a href="#target-variable">Target Variable</a></li>
<li><a href="#na-imputing">NA imputing</a></li>
<li><a href="#feature-encoding">Feature encoding</a></li>
<li><a href="#prepare-df-to-export-to-r">Prepare df to export to r</a></li>
</ul></li>
<li><a href="#r">R</a>
<ul>
<li><a href="#import-df-from-python">Import df from python</a></li>
<li><a href="#import-libraries-1">Import libraries</a></li>
<li><a href="#encode-types">Encode types</a></li>
<li><a href="#explore-in-r-with-data-explorer">Explore in r with data explorer</a></li>
<li><a href="#more-exploration">More exploration</a></li>
<li><a href="#train-test-split">Train test split</a></li>
<li><a href="#recipe-for-models">Recipe for models</a></li>
<li><a href="#prep-data">Prep Data</a></li>
<li><a href="#logistic-regression">Logistic Regression</a>
<ul>
<li><a href="#metrics-logistic">Metrics Logistic</a></li>
<li><a href="#metrics-lasso">Metrics Lasso</a></li>
</ul></li>
<li><a href="#ridge">Ridge</a>
<ul>
<li><a href="#metrics-ridge">Metrics Ridge</a></li>
</ul></li>
<li><a href="#random-forest">Random Forest</a>
<ul>
<li><a href="#metrics-random-forest">Metrics Random forest</a></li>
</ul></li>
<li><a href="#h2o">h2o</a>
<ul>
<li><a href="#start-cluster">Start CLuster</a></li>
<li><a href="#upload-dfs">Upload df’s</a></li>
<li><a href="#fit-auto-ml">Fit auto ml</a></li>
<li><a href="#model-results">Model results</a></li>
<li><a href="#using-a-stacked-model">Using a stacked model</a></li>
<li><a href="#performance">Performance</a></li>
</ul></li>
</ul></li>
<li><a href="#dalex---are-machinge-learning-models-black-boxes">DALEX - Are machinge learning models Black Boxes?</a>
<ul>
<li><a href="#dalex-x-e-y">Dalex X e Y</a></li>
<li><a href="#model-explainer">Model Explainer</a></li>
<li><a href="#feature-importance">Feature Importance</a></li>
<li><a href="#variable-explanation">Variable explanation</a>
<ul>
<li><a href="#accumulated-local-effects-profiles-aka-aleplots">Accumulated Local Effects Profiles aka ALEPlots</a></li>
<li><a href="#factor-explanation">Factor explanation</a></li>
</ul></li>
<li><a href="#single-prediction-explanation">Single prediction explanation</a></li>
</ul></li>
</ul>
</div>

<div id="goal" class="section level1">
<h1>Goal</h1>
<p>Read data from Brazil’s cell phone companies and predict customer satisfaction</p>
<pre class="r"><code>library(reticulate)
use_miniconda(&quot;r-reticulate&quot;,required = TRUE)
options(reticulate.repl.quiet = TRUE)</code></pre>
<pre class="r"><code>file_path &lt;- here::here()
file_path_linux &lt;- &quot;C:/GitHub/TwoSidesData2/content/post/data&quot;</code></pre>
</div>
<div id="python" class="section level1">
<h1>Python</h1>
<div id="import-libraries" class="section level2">
<h2>Import libraries</h2>
<pre class="python"><code>import pandas as pd
import numpy as np</code></pre>
</div>
<div id="read-feather-data-frame" class="section level2">
<h2>Read feather data frame</h2>
<pre class="python"><code>df1 = pd.read_feather(r.file_path_linux + &quot;/BD_PRE.feather&quot;)</code></pre>
</div>
<div id="describe-the-dataframe" class="section level2">
<h2>Describe the dataframe</h2>
<pre class="python"><code>df1.describe()</code></pre>
<pre><code>##               IDTNS       ANO_BASE  ...           PESO            I2
## count  1.284110e+05  128411.000000  ...  128411.000000  84441.000000
## mean   2.062114e+07    2016.269774  ...       0.999992      1.179806
## std    2.192746e+07       1.120365  ...       1.315625      0.384028
## min    3.780000e+02    2015.000000  ...       0.015936      1.000000
## 25%    6.160118e+06    2015.000000  ...       0.180556      1.000000
## 50%    6.804225e+06    2016.000000  ...       0.601990      1.000000
## 75%    4.105798e+07    2017.000000  ...       1.348837      1.000000
## max    6.203986e+07    2018.000000  ...      10.965368      2.000000
## 
## [8 rows x 47 columns]</code></pre>
</div>
<div id="drop-features" class="section level2">
<h2>Drop features</h2>
<p>My group read the data dictionary and glanced at the data to decido to drop of multipe features with for low variance or too high cardinality</p>
<pre class="python"><code>df1=df1.drop([&quot;IDTNS&quot;,&quot;TIPO&quot;,&quot;DATA&quot;,&quot;H0&quot;,&quot;Q1&quot;,&quot;Q2&quot;,&quot;Q3&quot;,&quot;Q4&quot;,&quot;Q6&quot;,&quot;Q7&quot;],axis=1)

df1.head()</code></pre>
<pre><code>##   OPERADORA ESTADO  ANO_BASE  Q5  Q8  ...      H2  H2a  I1      PESO   I2
## 0        OI     RJ      2018   1  44  ...  999998    1   2  1.165414  2.0
## 1        OI     BA      2018   1  50  ...  999998    6   1  1.911877  1.0
## 2      VIVO     ES      2018   1  37  ...    1000    1   1  0.695489  1.0
## 3     CLARO     RR      2018   1  19  ...  999998    2   1  0.054054  1.0
## 4        OI     ES      2018   1  39  ...  999998    7   1  0.111111  1.0
## 
## [5 rows x 42 columns]</code></pre>
</div>
<div id="rename-target" class="section level2">
<h2>Rename target</h2>
<pre class="python"><code>df1 = df1.rename(columns = {&#39;J1&#39;:&#39;Target&#39;})</code></pre>
</div>
<div id="na-enconding" class="section level2">
<h2>NA enconding</h2>
<p>The dictionary defined 99 as missing in multiple features</p>
<pre class="python"><code>df2 =  df1.copy()</code></pre>
<pre class="python"><code>df2[&#39;B1_1&#39;].replace([99], np.NaN,inplace = True)
df2[&#39;B1_2&#39;].replace([99], np.NaN,inplace = True)
df2[&#39;C1_1&#39;].replace([99], np.NaN,inplace = True)
df2[&#39;C1_2&#39;].replace([99], np.NaN,inplace = True)
df2[&#39;D2_1&#39;].replace([99], np.NaN,inplace = True)
df2[&#39;D2_2&#39;].replace([99], np.NaN,inplace = True)
df2[&#39;D2_3&#39;].replace([99], np.NaN,inplace = True)
df2[&#39;F5&#39;].replace([99], np.NaN,inplace = True)
df2[&#39;F4&#39;].replace([99], np.NaN,inplace = True)
df2[&#39;F2&#39;].replace([99], np.NaN,inplace = True)
df2[&#39;A5&#39;].replace([99], np.NaN,inplace = True)
df2[&#39;A4&#39;].replace([99], np.NaN,inplace = True)
df2[&#39;A3&#39;].replace([99], np.NaN,inplace = True)
df2[&#39;A2_1&#39;].replace([99], np.NaN,inplace = True)
df2[&#39;A2_2&#39;].replace([99], np.NaN,inplace = True)
df2[&#39;A2_3&#39;].replace([99], np.NaN,inplace = True)
df2[&#39;E1_1&#39;].replace([99], np.NaN,inplace = True)
df2[&#39;E1_2&#39;].replace([99], np.NaN,inplace = True)
df2[&#39;E1_3&#39;].replace([99], np.NaN,inplace = True)
df2[&#39;F4&#39;].replace([99], np.NaN,inplace = True)
df2[&#39;F5&#39;].replace([99], np.NaN,inplace = True)
df2[&#39;F6&#39;].replace([99], np.NaN,inplace = True)</code></pre>
<p>Sometimes variations of missing like didn’t want to answer were also enconded as numbers so we encoded those ase missing as well</p>
<pre class="python"><code>df2[&#39;Q8&#39;].replace([999999], np.NaN,inplace = True)
df2[&#39;H1&#39;].replace([99,99999], np.NaN,inplace = True)
df2[&#39;H2&#39;].replace([99997,99998,99999,100000,999998,999999], np.NaN,inplace = True)</code></pre>
</div>
<div id="feature-engeniring" class="section level2">
<h2>Feature Engeniring</h2>
<p>Droped H2a for now in order to code it as categories</p>
<pre class="python"><code>df2.drop([&quot;H2a&quot;],inplace = True,axis = 1)</code></pre>
<pre class="python"><code>df3 = df2.copy()</code></pre>
<pre class="python"><code>df3.loc[(df3[&quot;H2&quot;] &gt;=0) &amp; (df3[&quot;H2&quot;] &lt;1000), &quot;RIQUEZA&quot;]=1
df3.loc[(df3[&quot;H2&quot;] &gt;=1000) &amp; (df3[&quot;H2&quot;] &lt;3000), &quot;RIQUEZA&quot;]=2
df3.loc[(df3[&quot;H2&quot;] &gt;=3000) &amp; (df3[&quot;H2&quot;] &lt;6000), &quot;RIQUEZA&quot;]=3
df3.loc[(df3[&quot;H2&quot;] &gt;=6000) &amp; (df3[&quot;H2&quot;] &lt;10000), &quot;RIQUEZA&quot;]=4
df3.loc[(df3[&quot;H2&quot;] &gt;=10000) &amp; (df3[&quot;H2&quot;] &lt;15000), &quot;RIQUEZA&quot;]=5
df3.loc[(df3[&quot;H2&quot;] &gt;=15000) &amp; (df3[&quot;H2&quot;] &lt;20000), &quot;RIQUEZA&quot;]=6
df3.loc[(df3[&quot;H2&quot;] &gt;=20000), &quot;RIQUEZA&quot;]=7</code></pre>
<pre class="python"><code>df3.RIQUEZA.value_counts(dropna =False)</code></pre>
<pre><code>## 2.0    48387
## 1.0    33554
## NaN    29784
## 3.0    12543
## 4.0     2704
## 5.0      850
## 7.0      315
## 6.0      274
## Name: RIQUEZA, dtype: int64</code></pre>
</div>
<div id="target-variable" class="section level2">
<h2>Target Variable</h2>
<p>We decided with an nps system that scores above 8 were good scores, and encoded these cases as 1 and the rest as 0.</p>
<pre class="python"><code>df3[&#39;Target&#39;].replace([99], np.NaN,inplace = True)

df3.loc[(df3[&quot;Target&quot;] &lt;8) ,&quot;Target2&quot;]= 0
df3.loc[(df3[&quot;Target&quot;] &gt;=8 ) ,&quot;Target2&quot;]= 1


df3.dropna(subset=[&#39;Target&#39;],inplace = True)</code></pre>
<p>Variaveis Categoricas Moda
Estado<br />
Operadora<br />
RIQUEZA<br />
Q9<br />
I1
D1<br />
Q5<br />
F1
F3<br />
F5<br />
G1</p>
<p>Variaveis Categoricas Missing Explicito
A1_x</p>
</div>
<div id="na-imputing" class="section level2">
<h2>NA imputing</h2>
<p>We decided that these numeric features would be imputted with 0s a more robust approach could be taken but the main idea was for to create a simple model</p>
<pre class="python"><code>df3[&quot;A1_1&quot;].fillna(0,inplace = True)
df3[&quot;A1_2&quot;].fillna(0,inplace = True)
df3[&quot;A1_3&quot;].fillna(0,inplace = True)
df3[&quot;A1_4&quot;].fillna(0,inplace = True)
df3[&quot;F1&quot;].fillna(0,inplace = True)
df3[&quot;F3&quot;].fillna(0,inplace = True)
df3[&quot;F5&quot;].fillna(0,inplace = True)</code></pre>
</div>
<div id="feature-encoding" class="section level2">
<h2>Feature encoding</h2>
<p>We originally hand encoded all the features in python, this would help to automate the predictions latter down the pipe
unfortunally when replicating the code it seems I have a bug on reticulate so I will do that in r instead</p>
<pre class="python"><code># df3 = df3.astype({&#39;Q9&#39;: &#39;category&#39;})
# df3 = df3.astype({&#39;I1&#39;: &#39;category&#39;})
# df3 = df3.astype({&#39;D1&#39;: &#39;category&#39;})
# df3 = df3.astype({&#39;Q5&#39;: &#39;category&#39;})
# df3 = df3.astype({&#39;F1&#39;: &#39;category&#39;})
# df3 = df3.astype({&#39;F3&#39;: &#39;category&#39;})
# df3 = df3.astype({&#39;F5&#39;: &#39;category&#39;})
# df3 = df3.astype({&#39;G1&#39;: &#39;category&#39;})
# df3 = df3.astype({&#39;A1_1&#39;: &#39;category&#39;})
# df3 = df3.astype({&#39;A1_2&#39;: &#39;category&#39;})
# df3 = df3.astype({&#39;A1_3&#39;: &#39;category&#39;})
# df3 = df3.astype({&#39;A1_4&#39;: &#39;category&#39;})
# df3 = df3.astype({&#39;RIQUEZA&#39;: &#39;category&#39;})
# df3 = df3.astype({&#39;Target2&#39;: &#39;category&#39;})</code></pre>
<pre class="python"><code>df3.dtypes</code></pre>
<pre><code>## OPERADORA     object
## ESTADO        object
## ANO_BASE       int64
## Q5             int64
## Q8           float64
## Q8a            int64
## Q9             int64
## Target       float64
## B1_1         float64
## B1_2         float64
## C1_1         float64
## C1_2         float64
## D1             int64
## D2_1         float64
## D2_2         float64
## D2_3         float64
## E1_1         float64
## E1_2         float64
## E1_3         float64
## A1_1         float64
## A1_2         float64
## A1_3         float64
## A1_4         float64
## A2_1         float64
## A2_2         float64
## A2_3         float64
## A3           float64
## A4           float64
## A5           float64
## F1             int64
## F2           float64
## F3             int64
## F4           float64
## F5           float64
## F6           float64
## G1             int64
## H1           float64
## H2           float64
## I1             int64
## PESO         float64
## I2           float64
## RIQUEZA      float64
## Target2      float64
## dtype: object</code></pre>
</div>
<div id="prepare-df-to-export-to-r" class="section level2">
<h2>Prepare df to export to r</h2>
<pre class="python"><code>df4=df3.loc[:,[&#39;Q5&#39;,&#39;Q8&#39;,&#39;Q8a&#39;,&#39;Q9&#39;,&#39;B1_1&#39;,&#39;B1_2&#39;,&#39;C1_1&#39;,&#39;C1_2&#39;,&#39;D1&#39;,&#39;D2_1&#39;,&#39;D2_2&#39;,&#39;D2_3&#39;,&#39;E1_1&#39;,&#39;E1_2&#39;,&#39;E1_3&#39;,&#39;A1_1&#39;,&#39;A1_2&#39;,&#39;A1_3&#39;,&#39;A1_4&#39;,&#39;F1&#39;,&#39;F3&#39;,&#39;F5&#39;,&#39;G1&#39;,&#39;H1&#39;,&#39;I1&#39;,&#39;PESO&#39;,&#39;RIQUEZA&#39;,&quot;Target2&quot;]]</code></pre>
</div>
</div>
<div id="r" class="section level1">
<h1>R</h1>
<div id="import-df-from-python" class="section level2">
<h2>Import df from python</h2>
<pre class="r"><code>df_r &lt;- py$df4</code></pre>
</div>
<div id="import-libraries-1" class="section level2">
<h2>Import libraries</h2>
<pre class="r"><code>library(DataExplorer)
library(tidyverse)</code></pre>
<pre><code>## -- Attaching packages --------------------------------------- tidyverse 1.3.0 --</code></pre>
<pre><code>## v ggplot2 3.3.3     v purrr   0.3.4
## v tibble  3.1.0     v dplyr   1.0.4
## v tidyr   1.1.3     v stringr 1.4.0
## v readr   1.4.0     v forcats 0.5.1</code></pre>
<pre><code>## Warning: package &#39;tibble&#39; was built under R version 4.0.4</code></pre>
<pre><code>## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code>library(tidymodels)</code></pre>
<pre><code>## -- Attaching packages -------------------------------------- tidymodels 0.1.2 --</code></pre>
<pre><code>## v broom     0.7.5      v recipes   0.1.15
## v dials     0.0.9      v rsample   0.0.9 
## v infer     0.5.4      v tune      0.1.3 
## v modeldata 0.1.0      v workflows 0.2.1 
## v parsnip   0.1.5      v yardstick 0.0.7</code></pre>
<pre><code>## Warning: package &#39;broom&#39; was built under R version 4.0.4</code></pre>
<pre><code>## Warning: package &#39;rsample&#39; was built under R version 4.0.4</code></pre>
<pre><code>## Warning: package &#39;tune&#39; was built under R version 4.0.4</code></pre>
<pre><code>## -- Conflicts ----------------------------------------- tidymodels_conflicts() --
## x scales::discard() masks purrr::discard()
## x dplyr::filter()   masks stats::filter()
## x recipes::fixed()  masks stringr::fixed()
## x dplyr::lag()      masks stats::lag()
## x yardstick::spec() masks readr::spec()
## x recipes::step()   masks stats::step()</code></pre>
<pre class="r"><code>library(furrr)</code></pre>
<pre><code>## Loading required package: future</code></pre>
<pre class="r"><code>library(h2o)</code></pre>
<pre><code>## Warning: package &#39;h2o&#39; was built under R version 4.0.4</code></pre>
<pre><code>## 
## ----------------------------------------------------------------------
## 
## Your next step is to start H2O:
##     &gt; h2o.init()
## 
## For H2O package documentation, ask for help:
##     &gt; ??h2o
## 
## After starting H2O, you can use the Web UI at http://localhost:54321
## For more information visit https://docs.h2o.ai
## 
## ----------------------------------------------------------------------</code></pre>
<pre><code>## 
## Attaching package: &#39;h2o&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     cor, sd, var</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     %*%, %in%, &amp;&amp;, ||, apply, as.factor, as.numeric, colnames,
##     colnames&lt;-, ifelse, is.character, is.factor, is.numeric, log,
##     log10, log1p, log2, round, signif, trunc</code></pre>
<pre class="r"><code>library(DALEX)</code></pre>
<pre><code>## Warning: package &#39;DALEX&#39; was built under R version 4.0.4</code></pre>
<pre><code>## Welcome to DALEX (version: 2.1.1).
## Find examples and detailed introduction at: http://ema.drwhy.ai/</code></pre>
<pre><code>## 
## Attaching package: &#39;DALEX&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     explain</code></pre>
<pre class="r"><code>library(DALEXtra)</code></pre>
<pre><code>## Warning: package &#39;DALEXtra&#39; was built under R version 4.0.4</code></pre>
<pre class="r"><code>library(iBreakDown)</code></pre>
<pre><code>## Warning: package &#39;iBreakDown&#39; was built under R version 4.0.4</code></pre>
<pre class="r"><code>library(ingredients)</code></pre>
<pre><code>## Warning: package &#39;ingredients&#39; was built under R version 4.0.4</code></pre>
<pre><code>## 
## Attaching package: &#39;ingredients&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:iBreakDown&#39;:
## 
##     describe, plotD3</code></pre>
<pre><code>## The following object is masked from &#39;package:DALEX&#39;:
## 
##     feature_importance</code></pre>
<pre class="r"><code>library(probably)</code></pre>
<pre><code>## Warning: package &#39;probably&#39; was built under R version 4.0.4</code></pre>
<pre><code>## 
## Attaching package: &#39;probably&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:h2o&#39;:
## 
##     as.factor</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     as.factor, as.ordered</code></pre>
</div>
<div id="encode-types" class="section level2">
<h2>Encode types</h2>
<pre class="r"><code>df_r %&gt;% glimpse()</code></pre>
<pre><code>## Rows: 128,198
## Columns: 28
## $ Q5      &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,~
## $ Q8      &lt;dbl&gt; 44, 50, 37, 19, 39, 38, NaN, 19, 22, 27, 24, 47, 29, 21, 40, 1~
## $ Q8a     &lt;dbl&gt; 7, 7, 6, 3, 6, 6, 7, 3, 3, 4, 3, 7, 4, 3, 6, 3, 4, 8, 7, 6, 4,~
## $ Q9      &lt;dbl&gt; 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2,~
## $ B1_1    &lt;dbl&gt; 7, 4, 9, 5, 10, 10, 8, 8, 10, 4, 0, 8, 5, 5, 10, 5, 7, 10, 10,~
## $ B1_2    &lt;dbl&gt; 9, 3, 10, 6, NaN, 10, 8, 6, 9, 6, 5, 8, 5, 3, 10, 10, 5, 10, 1~
## $ C1_1    &lt;dbl&gt; 10, 3, 10, 8, 10, 8, 7, 10, 10, 8, 7, 10, 10, 8, 10, 2, 7, 10,~
## $ C1_2    &lt;dbl&gt; 10, 4, 10, 9, 10, 9, 6, 10, 5, 9, 0, 8, 10, 2, 10, 9, 8, 10, 8~
## $ D1      &lt;dbl&gt; 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 2, 2, 1, 2,~
## $ D2_1    &lt;dbl&gt; 8, NaN, 9, 4, 7, 10, NaN, 1, 10, 5, NaN, 6, NaN, 2, 8, 9, NaN,~
## $ D2_2    &lt;dbl&gt; 7, NaN, 7, 3, 5, 10, NaN, 1, 9, 7, NaN, 8, NaN, 0, 8, 7, NaN, ~
## $ D2_3    &lt;dbl&gt; 7, NaN, 7, 5, 5, 10, NaN, 1, 10, 6, NaN, 6, NaN, 0, 8, 8, NaN,~
## $ E1_1    &lt;dbl&gt; 8, 2, 9, 7, 8, 10, 7, 3, 9, 8, 0, 5, 7, 0, 10, 7, 7, 10, 10, 9~
## $ E1_2    &lt;dbl&gt; 8, 2, 9, 9, 10, 10, 7, 8, 9, 5, 0, 6, 5, 0, 10, 6, 7, 10, 10, ~
## $ E1_3    &lt;dbl&gt; 10, 5, 9, 10, 8, 10, 8, 10, 10, 8, 0, 8, 5, 5, 10, 6, 8, 10, 1~
## $ A1_1    &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,~
## $ A1_2    &lt;dbl&gt; 0, 2, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0,~
## $ A1_3    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0,~
## $ A1_4    &lt;dbl&gt; 97, 0, 0, 0, 97, 0, 0, 97, 0, 0, 97, 97, 97, 0, 0, 0, 0, 0, 97~
## $ F1      &lt;dbl&gt; 2, 2, 2, 1, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 1, 2,~
## $ F3      &lt;dbl&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 2, 2,~
## $ F5      &lt;dbl&gt; 2, 0, 2, 1, 2, 2, 0, 1, 2, 1, 0, 2, 0, 2, 1, 2, 0, 0, 0, 2, 0,~
## $ G1      &lt;dbl&gt; 1, 1, 2, 2, 1, 2, 3, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,~
## $ H1      &lt;dbl&gt; 3, NaN, 1, 3, 1, 5, 1, 2, 2, 1, 1, 1, 1, 4, 2, 2, 1, 2, 2, 2, ~
## $ I1      &lt;dbl&gt; 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1,~
## $ PESO    &lt;dbl&gt; 1.1654135, 1.9118774, 0.6954887, 0.0540541, 0.1111111, 0.11111~
## $ RIQUEZA &lt;dbl&gt; NaN, NaN, 2, NaN, NaN, 1, NaN, NaN, 2, 2, 1, NaN, 2, NaN, 2, 2~
## $ Target2 &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,~</code></pre>
<pre class="r"><code>category_pipe &lt;- . %&gt;% 
  as.character() %&gt;% 
  if_else(. == &quot;NaN&quot;,NA_character_,.) %&gt;% 
  as_factor()</code></pre>
<pre class="r"><code>df_r &lt;- df_r %&gt;% 
  mutate_at(vars(Q9,I1,D1,Q5,F1,F3,F5,G1,starts_with(&quot;A1&quot;),RIQUEZA,Target2),.funs = category_pipe)</code></pre>
</div>
<div id="explore-in-r-with-data-explorer" class="section level2">
<h2>Explore in r with data explorer</h2>
<pre class="r"><code>DataExplorer::introduce(df_r)</code></pre>
<pre><code>##     rows columns discrete_columns continuous_columns all_missing_columns
## 1 128198      28               14                 14                   0
##   total_missing_values complete_rows total_observations memory_usage
## 1               218989         51924            3589544     21551024</code></pre>
<pre class="r"><code>DataExplorer::plot_intro(df_r)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
<pre class="r"><code>plot_missing(df_r)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-27-1.png" width="672" />
## Drop features</p>
<pre class="r"><code>df_r &lt;- df_r %&gt;% 
  select(-starts_with(&quot;D2&quot;))</code></pre>
<pre class="r"><code>plot_missing(df_r)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-29-1.png" width="672" />
## Encode response in r</p>
<pre class="r"><code>  df_r &lt;- df_r %&gt;% 
  rename(response = Target2) %&gt;% 
  select(-PESO)</code></pre>
</div>
<div id="more-exploration" class="section level2">
<h2>More exploration</h2>
<pre class="r"><code>df_r %&gt;%
  mutate(response = response %&gt;% fct_recode(bad = &quot;0&quot;,good =&quot;1&quot;)) %&gt;% 
  count(response) %&gt;%
  ggplot(aes(response, n, fill = response)) + 
  geom_col(width = .5, show.legend = FALSE) + 
  scale_y_continuous(labels = scales::comma) +
  scale_fill_manual(values = c(&quot;red&quot;,&quot;blue&quot;)) +
  labs(
    x = NULL,
    y = NULL,
    title = &quot;Distribution of cases&quot;
  )</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-31-1.png" width="672" />
# Modeling</p>
</div>
<div id="train-test-split" class="section level2">
<h2>Train test split</h2>
<pre class="r"><code>telefone_initial_split &lt;- df_r %&gt;% rsample::initial_split(prop = 0.9)
telefone_initial_split</code></pre>
<pre><code>## &lt;Analysis/Assess/Total&gt;
## &lt;115379/12819/128198&gt;</code></pre>
<pre class="r"><code>train_data &lt;- training(telefone_initial_split)
test_data &lt;- testing(telefone_initial_split)</code></pre>
</div>
<div id="recipe-for-models" class="section level2">
<h2>Recipe for models</h2>
<pre class="r"><code>recipe_telefone &lt;- 
  recipe(response ~.,data = train_data) %&gt;%
  #step_upsample(response,skip = TRUE) %&gt;% 
  step_modeimpute(all_predictors(),-all_numeric()) %&gt;% 
  step_medianimpute(all_predictors(),-all_nominal()) %&gt;% 
  step_normalize(all_numeric()) %&gt;% 
  step_rm(RIQUEZA)
  #step_dummy(all_predictors(),-all_numeric())</code></pre>
</div>
<div id="prep-data" class="section level2">
<h2>Prep Data</h2>
<pre class="r"><code>simple_model_recipe &lt;- recipe_telefone %&gt;%
  prep(retain = TRUE)

simple_train &lt;- simple_model_recipe %&gt;% juice()

simple_test &lt;- simple_model_recipe %&gt;% bake(test_data)</code></pre>
</div>
<div id="logistic-regression" class="section level2">
<h2>Logistic Regression</h2>
<pre class="r"><code>logistic_regression &lt;- 
  logistic_reg(mode = &quot;classification&quot;,penalty = 0) %&gt;%
  set_engine(&quot;glmnet&quot;) %&gt;% 
  fit(response ~.,data = simple_train)

metrics_log_reg &lt;- logistic_regression %&gt;% 
  predict(simple_test) %&gt;% 
  bind_cols(simple_test %&gt;% select(response)) %&gt;% 
  metrics(truth = response,estimate = .pred_class)

metrics_roc_auc &lt;- logistic_regression %&gt;% 
  predict(simple_test,type = &quot;prob&quot;) %&gt;% 
  bind_cols(simple_test %&gt;% select(response)) %&gt;% 
  roc_auc(truth = response,predictor =.pred_0)</code></pre>
<div id="metrics-logistic" class="section level3">
<h3>Metrics Logistic</h3>
<pre class="r"><code>metrics_log_reg</code></pre>
<pre><code>## # A tibble: 2 x 3
##   .metric  .estimator .estimate
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;
## 1 accuracy binary         0.804
## 2 kap      binary         0.607</code></pre>
<pre class="r"><code>metrics_roc_auc</code></pre>
<pre><code>## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 roc_auc binary         0.115</code></pre>
<p>I am going to keep using roc from now on
## Lasso</p>
<pre class="r"><code>lasso_regression &lt;- logistic_reg(mode = &quot;classification&quot;,mixture = 0) %&gt;% 
  set_engine(&quot;glmnet&quot;) %&gt;% 
  fit(response~ .,data = simple_train)

lasso_roc_auc_cv &lt;- lasso_regression %&gt;% 
  multi_predict(new_data = simple_test,type = &quot;prob&quot;) %&gt;% 
  bind_cols(simple_test) %&gt;%
  unnest() %&gt;% 
  group_by(penalty) %&gt;% 
  do(ok = roc_auc(.,truth = response,predictor = .pred_0)) %&gt;% 
  unnest() %&gt;%
  spread(key = .metric,value = .estimate) %&gt;%
  arrange(roc_auc %&gt;% desc)</code></pre>
<pre><code>## Warning: `cols` is now required when using unnest().
## Please use `cols = c(.pred)`</code></pre>
<pre><code>## Warning: `cols` is now required when using unnest().
## Please use `cols = c(ok)`</code></pre>
</div>
<div id="metrics-lasso" class="section level3">
<h3>Metrics Lasso</h3>
<pre class="r"><code>lasso_roc_auc_cv</code></pre>
<pre><code>## # A tibble: 100 x 3
##    penalty .estimator roc_auc
##      &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;
##  1    273. binary       0.5  
##  2    249. binary       0.123
##  3    227. binary       0.123
##  4    206. binary       0.123
##  5    188. binary       0.123
##  6    171. binary       0.123
##  7    156. binary       0.123
##  8    142. binary       0.123
##  9    130. binary       0.123
## 10    118. binary       0.123
## # ... with 90 more rows</code></pre>
</div>
</div>
<div id="ridge" class="section level2">
<h2>Ridge</h2>
<pre class="r"><code>ridge_regression &lt;- logistic_reg(mode = &quot;classification&quot;,mixture = 1) %&gt;% 
  set_engine(&quot;glmnet&quot;) %&gt;% 
  fit(response~ .,data = simple_train)

ridge_results_cv &lt;- ridge_regression %&gt;% 
  multi_predict(new_data = simple_test,type = &quot;prob&quot;) %&gt;% 
  bind_cols(simple_test) %&gt;%
  unnest() %&gt;% 
  group_by(penalty) %&gt;% 
  do(ok = roc_auc(.,truth = response,predictor = .pred_0)) %&gt;% 
  unnest() %&gt;%
  spread(key = .metric,value = .estimate) %&gt;%
  arrange(roc_auc %&gt;% desc)</code></pre>
<pre><code>## Warning: `cols` is now required when using unnest().
## Please use `cols = c(.pred)`</code></pre>
<pre><code>## Warning: `cols` is now required when using unnest().
## Please use `cols = c(ok)`</code></pre>
<div id="metrics-ridge" class="section level3">
<h3>Metrics Ridge</h3>
<pre class="r"><code>ridge_results_cv</code></pre>
<pre><code>## # A tibble: 66 x 3
##    penalty .estimator roc_auc
##      &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt;
##  1   0.273 binary       0.5  
##  2   0.249 binary       0.171
##  3   0.227 binary       0.155
##  4   0.206 binary       0.152
##  5   0.188 binary       0.150
##  6   0.171 binary       0.141
##  7   0.156 binary       0.134
##  8   0.142 binary       0.130
##  9   0.130 binary       0.127
## 10   0.118 binary       0.125
## # ... with 56 more rows</code></pre>
</div>
</div>
<div id="random-forest" class="section level2">
<h2>Random Forest</h2>
<pre class="r"><code>  random_forest &lt;- rand_forest(mode = &quot;classification&quot;,trees = 100) %&gt;% 
  set_engine(&quot;ranger&quot;) %&gt;% 
  fit(response~ .,data = simple_train)</code></pre>
<div id="metrics-random-forest" class="section level3">
<h3>Metrics Random forest</h3>
<p>The best model currently</p>
<pre class="r"><code>random_forest %&gt;% 
  predict(simple_test,type = &quot;prob&quot;) %&gt;% 
  bind_cols(simple_test %&gt;% select(response)) %&gt;% 
  roc_auc(truth = response,predictor =.pred_0)</code></pre>
<pre><code>## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 roc_auc binary         0.110</code></pre>
</div>
</div>
<div id="h2o" class="section level2">
<h2>h2o</h2>
<p>h2o is usually very fast but not fast enough for this blogpost but here is the code for it</p>
<div id="start-cluster" class="section level3">
<h3>Start CLuster</h3>
</div>
<div id="upload-dfs" class="section level3">
<h3>Upload df’s</h3>
<pre class="r"><code># simple_train_hex &lt;-  as.h2o(simple_train)
# simple_test_hex = as.h2o(simple_test)
# simple_y_hex &lt;- simple_train %&gt;% select(response) %&gt;% pull %&gt;% as.numeric()
# simple_x_hex &lt;- simple_train %&gt;% select(-response)</code></pre>
</div>
<div id="fit-auto-ml" class="section level3">
<h3>Fit auto ml</h3>
<p>With a 2 minutes timer</p>
<pre class="r"><code># h2o.no_progress()
# 
# aml &lt;- h2o.automl(y = &quot;response&quot;,
#                   training_frame = simple_train_hex,
#                   max_runtime_secs = 120,
#                   seed = 1)
# </code></pre>
</div>
<div id="model-results" class="section level3">
<h3>Model results</h3>
<pre class="r"><code># pred &lt;- h2o.predict(aml, simple_test_hex)</code></pre>
<pre class="r"><code># aml@leaderboard</code></pre>
<pre class="r"><code># model_ids &lt;- as.data.frame(aml@leaderboard$model_id)[,1]
# model_ids</code></pre>
</div>
<div id="using-a-stacked-model" class="section level3">
<h3>Using a stacked model</h3>
<pre class="r"><code># best_h2o &lt;- h2o.getModel(model_ids[model_ids %&gt;% str_detect(&quot;StackedEnsemble_BestOfFamily_AutoML&quot;)])</code></pre>
</div>
<div id="performance" class="section level3">
<h3>Performance</h3>
<pre class="r"><code># result_predictions &lt;- predict(best_h2o,simple_test_hex)</code></pre>
<pre class="r"><code># result_predictions %&gt;% 
#   as_tibble() %&gt;% 
#   bind_cols(simple_test) %&gt;% 
#   roc_auc(truth = response,predictor = p0)</code></pre>
</div>
</div>
</div>
<div id="dalex---are-machinge-learning-models-black-boxes" class="section level1">
<h1>DALEX - Are machinge learning models Black Boxes?</h1>
<p>Code based from <a href="https://github.com/ModelOriented/DALEX">Dalex page</a></p>
<div id="dalex-x-e-y" class="section level2">
<h2>Dalex X e Y</h2>
<pre class="r"><code>x_dalex &lt;- simple_test %&gt;% select(-response)
y_dalex &lt;- simple_test %&gt;%
  transmute(response = response %&gt;%
              as.numeric()) %&gt;% 
  mutate(response = if_else(response == 1,
                            0,
                            1)) %&gt;% as.data.frame()
y_dalex &lt;- y_dalex[,1]</code></pre>
</div>
<div id="model-explainer" class="section level2">
<h2>Model Explainer</h2>
<pre class="r"><code>explainer_log_reg &lt;- DALEX::explain(logistic_regression, data=x_dalex, y=y_dalex, label=&quot;logistic_reg&quot;)
explainer_rf &lt;- explain(random_forest,x_dalex,y_dalex,label =&quot;random_forest&quot;)</code></pre>
</div>
<div id="feature-importance" class="section level2">
<h2>Feature Importance</h2>
<pre class="r"><code>mp_log_reg &lt;- model_parts(explainer_log_reg)
mp_rf &lt;- model_parts(explainer_rf)</code></pre>
<pre class="r"><code>plot(mp_log_reg,mp_rf)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-57-1.png" width="672" /></p>
</div>
<div id="variable-explanation" class="section level2">
<h2>Variable explanation</h2>
<div id="accumulated-local-effects-profiles-aka-aleplots" class="section level3">
<h3>Accumulated Local Effects Profiles aka ALEPlots</h3>
<p>B1_2: Note in regards to how well the company has delivered on its publicity.</p>
<pre class="r"><code>adp_log_reg &lt;- accumulated_dependence(explainer_log_reg,variables = &quot;B1_2&quot;)
adp_rf &lt;- accumulated_dependence(explainer_rf,variables = &quot;B1_2&quot;)</code></pre>
<pre class="r"><code>plot(adp_log_reg,adp_rf)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-59-1.png" width="672" /></p>
</div>
<div id="factor-explanation" class="section level3">
<h3>Factor explanation</h3>
<p>G1: Does another company exist that is serving the same area:</p>
<ol style="list-style-type: decimal">
<li>Yes</li>
<li>No</li>
<li>Don’t know</li>
</ol>
<pre class="r"><code>expl_log_reg &lt;- accumulated_dependence(explainer_log_reg,variables = &quot;G1&quot;, variable_type = &quot;categorical&quot;)
expl_rf&lt;- accumulated_dependence(explainer_rf,variables = &quot;G1&quot;, variable_type = &quot;categorical&quot;)</code></pre>
<pre class="r"><code>plot(expl_log_reg,expl_rf)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-61-1.png" width="672" /></p>
</div>
</div>
<div id="single-prediction-explanation" class="section level2">
<h2>Single prediction explanation</h2>
<p>Only the first case</p>
<pre class="r"><code>bd_log_reg &lt;- predict_parts(explainer_log_reg, x_dalex[1,])
bd_rf &lt;- predict_parts(explainer_rf, x_dalex[1,])</code></pre>
<p>Logistic Regression</p>
<pre class="r"><code>plot(bd_log_reg)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-63-1.png" width="672" />
Random Forest</p>
<pre class="r"><code>plot(bd_rf)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-64-1.png" width="672" /></p>
<p>Not the coolest graph since unfortunately we use a normalization process, maybe in the future with the workflows package we can see better graphs</p>
</div>
</div>
