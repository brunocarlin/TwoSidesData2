<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R Markdown on TwoSidesData</title>
    <link>/tags/r-markdown/</link>
    <description>Recent content in R Markdown on TwoSidesData</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 25 Jan 2020 00:00:00 +0000</lastBuildDate>
    <atom:link href="/tags/r-markdown/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>exploratory data analysis: basics Python part 2</title>
      <link>/2020/01/25/exploratory-data-analysis-basics-part2/</link>
      <pubDate>Sat, 25 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/01/25/exploratory-data-analysis-basics-part2/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#libraries&#34;&gt;Libraries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#second-post&#34;&gt;Second Post&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#objectives&#34;&gt;Objectives&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#define-the-variables-used-in-the-conclusion&#34;&gt;Define the variables used in the conclusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#using-masks-or-other-methods-to-filter-the-data&#34;&gt;Using masks or other methods to filter the data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#visualizing-the-hypothesis&#34;&gt;Visualizing the hypothesis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#conclusion&#34;&gt;Conclusion&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#before-we-start&#34;&gt;Before we start&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#reservations&#34;&gt;Reservations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-dictionary&#34;&gt;Data Dictionary&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#python&#34;&gt;Python&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#importing-the-dataset-from-part-1&#34;&gt;Importing the dataset from part 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#python_hypothesis_testing1&#34;&gt;Difference in means&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#linear-regression&#34;&gt;Linear Regression&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#masks&#34;&gt;Linearity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#random&#34;&gt;Random&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#non-collinearity&#34;&gt;Non-Collinearity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#exogeneity&#34;&gt;Exogeneity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#homoscedasticity-homogeneity-of-variance-assumption-of-equal-variance&#34;&gt;Homoscedasticity / Homogeneity of Variance/ Assumption of Equal Variance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#python_hypothesis_testing2&#34;&gt;Fitting the linear regression&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#linear-regression-plots&#34;&gt;Linear Regression plots&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#qq-plot&#34;&gt;QQ plot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#scale-location-plot&#34;&gt;Scale-Location Plot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#leverage-plot&#34;&gt;Leverage plot&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#final-remarks&#34;&gt;Final Remarks&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#next-post&#34;&gt;Next post&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;div id=&#34;libraries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Libraries&lt;/h1&gt;
&lt;p&gt;Let’s see what version of python this env is running.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;reticulate::py_config()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## python:         /home/bruno-carlin/Documents/GIthub/TwoSidesData2/.venv/bin/python
## libpython:      /opt/python/3.7/lib/libpython3.7m.so
## pythonhome:     /opt/python/3.7:/opt/python/3.7
## virtualenv:     /home/bruno-carlin/Documents/GIthub/TwoSidesData2/.venv/bin/activate_this.py
## version:        3.7.4 (default, Aug 13 2019, 20:35:49)  [GCC 7.3.0]
## numpy:          /home/bruno-carlin/Documents/GIthub/TwoSidesData2/.venv/lib/python3.7/site-packages/numpy
## numpy_version:  1.18.1
## 
## NOTE: Python version was forced by use_python function&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import scipy.stats as ss
import statsmodels.api as sm
import statsmodels.formula.api as smf
import os
from statsmodels.graphics.gofplots import ProbPlot&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;second-post&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Second Post&lt;/h1&gt;
&lt;div id=&#34;objectives&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Objectives&lt;/h2&gt;
&lt;/div&gt;
&lt;div id=&#34;define-the-variables-used-in-the-conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Define the variables used in the conclusion&lt;/h2&gt;
&lt;p&gt;In our case, we initially choose to use &lt;a href=&#34;#python_hypothesis_testing1&#34;&gt;salary ~ sex,region&lt;/a&gt; region was added to test whether &lt;a href=&#34;https://en.wikipedia.org/wiki/Simpson%27s_paradox&#34;&gt;Simpson’s paradox&lt;/a&gt; was at play.&lt;/p&gt;
&lt;p&gt;But then I augmented our analysis with a &lt;a href=&#34;#python_hypothesis_testing2&#34;&gt;simple linear regression&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-masks-or-other-methods-to-filter-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Using masks or other methods to filter the data&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;#masks&#34;&gt;We used it once&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;visualizing-the-hypothesis&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Visualizing the hypothesis&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;#python_plot_histograms&#34;&gt;We were advised to use two histograms combined to get a preview of our answer.&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Comment on our findings.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;before-we-start&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Before we start&lt;/h2&gt;
&lt;div id=&#34;reservations&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Reservations&lt;/h3&gt;
&lt;p&gt;This is an exercise where we were supposed to ask a relevant question using the data from the IBGE(Brazil’s main data collector) database of 1970.&lt;/p&gt;
&lt;p&gt;Our group decided to ask whether women received less than man, we expanded the analysis hoping to avoid the Simpson’s paradox.&lt;/p&gt;
&lt;p&gt;This is just an basic inference, and it’s results are therefore only used for studying purposes I don’t believe any finding would be relevant using just this approach but some basic operations can be used in a more impact full work.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-dictionary&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Data Dictionary&lt;/h3&gt;
&lt;p&gt;We got a Data Dictionary that will be very useful for our Analysis, it contains all the required information about the encoding of the columns and the intended format that the folks at STATA desired.&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;Portuguese&lt;/summary&gt;
&lt;p&gt;
&lt;p&gt;Descrição do Registro de Indivíduos nos EUA.&lt;/p&gt;
&lt;p&gt;Dataset do software STATA (pago), vamos abri-lo com o pandas e transforma-lo em DataFrame.&lt;/p&gt;
&lt;p&gt;Variável 1 – CHAVE DO INDIVÍDUO ? Formato N - Numérico ? Tamanho 11 dígitos (11 bytes) ? Descrição Sumária Identifica unicamente o indivíduo na amostra.&lt;/p&gt;
&lt;p&gt;Variável 2 - IDADE CALCULADA EM ANOS ? Formato N - Numérico ? Tamanho 3 dígitos (3 bytes) ? Descrição Sumária Identifica a idade do morador em anos completos.&lt;/p&gt;
&lt;p&gt;Variável 3 – SEXO ? Formato N - Numérico ? Tamanho 1 dígito (1 byte) ? Quantidade de Categorias 3 ? Descrição Sumária Identifica o sexo do morador. Categorias (1) homem, (2) mulher e (3) gestante.&lt;/p&gt;
&lt;p&gt;Variável 4 – ANOS DE ESTUDO ? Formato N - Numérico ? Tamanho 2 dígitos (2 bytes) ? Quantidade de Categorias 11 ? Descrição Sumária Identifica o número de anos de estudo do morador. Categorias (05) Cinco ou menos, (06) Seis, (07) Sete, (08) Oito, (09) Nove, (10) Dez, (11) Onze, (12) Doze, (13) Treze, (14) Quatorze, (15) Quinze ou mais.&lt;/p&gt;
&lt;p&gt;Variável 5 – COR OU RAÇA ? Formato N - Numérico ? Tamanho 2 dígitos (2 bytes) ? Quantidade de Categorias 6 ? Descrição Sumária Identifica a Cor ou Raça declarada pelo morador. Categorias (01) Branca, (02) Preta, (03) Amarela, (04) Parda, (05) Indígena e (09) Não Sabe.&lt;/p&gt;
&lt;p&gt;Variável 6 – VALOR DO SALÁRIO (ANUALIZADO) ? Formato N - Numérico ? Tamanho 8 dígitos (8 bytes) ? Quantidade de Decimais 2 ? Descrição Sumária Identifica o valor resultante do salário anual do indivíduo. Categorias especiais (-1) indivíduo ausente na data da pesquisa e (999999) indivíduo não quis responder.&lt;/p&gt;
&lt;p&gt;Variável 7 – ESTADO CIVIL ? Formato N - Numérico ? Tamanho 1 dígito (1 byte) ? Quantidade de Categorias 2 ? Descrição Sumária Dummy que identifica o estado civil declarado pelo morador. Categorias (1) Casado, (0) não casado.&lt;/p&gt;
&lt;p&gt;Variável 8 – REGIÃO GEOGRÁFICA ? Formato N - Numérico ? Tamanho 1 dígito (1 byte) ? Quantidade de Categorias 5 ? Descrição Sumária Identifica a região geográfica do morador. Categorias (1) Norte, (2) Nordeste, (3) Sudeste, (4) Sul e (5) Centro-oeste.&lt;/p&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;English&lt;/summary&gt;
&lt;p&gt;
&lt;p&gt;Description of the US Individual Registry.&lt;/p&gt;
&lt;p&gt;Dataset of the STATA software (paid), we will open it with pandas and turn it into DataFrame.&lt;/p&gt;
&lt;p&gt;Variable 1 - KEY OF THE INDIVIDUAL? Format N - Numeric? Size 11 digits (11 bytes)? Summary Description Uniquely identifies the individual in the sample.&lt;/p&gt;
&lt;p&gt;Variable 2 - AGE CALCULATED IN YEARS? Format N - Numeric? Size 3 digits (3 bytes)? Summary Description Identifies the age of the resident in full years.&lt;/p&gt;
&lt;p&gt;Variable 3 - SEX? Format N - Numeric? Size 1 digit (1 byte)? Number of Categories 3? Summary Description Identifies the gender of the resident. Categories (1) men, (2) women and (3) pregnant women.&lt;/p&gt;
&lt;p&gt;Variable 4 - YEARS OF STUDY? Format N - Numeric? Size 2 digits (2 bytes)? Number of Categories 11? Summary Description Identifies the number of years of study of the resident. Categories (05) Five or less, (06) Six, (07) Seven, (08) Eight, (09) Nine, (10) Dec, (11) Eleven, (12) Twelve, (13) Thirteen, (14 ) Fourteen, (15) Fifteen or more.&lt;/p&gt;
&lt;p&gt;Variable 5 - COLOR OR RACE? Format N - Numeric? Size 2 digits (2 bytes)? Number of Categories 6? Summary Description Identifies the Color or Race declared by the resident. Categories (01) White, (02) Black, (03) Yellow, (04) Brown, (05) Indigenous and (09) Don’t know.&lt;/p&gt;
&lt;p&gt;Variable 6 - WAGE VALUE (ANNUALIZED)? Format N - Numeric? Size 8 digits (8 bytes)? Number of decimals 2? Summary Description Identifies the amount resulting from the individual’s annual salary. Special categories (-1) individual absent on the survey date and (999999) individual did not want to answer.&lt;/p&gt;
&lt;p&gt;Variable 7 - CIVIL STATE? Format N - Numeric? Size 1 digit (1 byte)? Number of Categories 2? Summary Description Dummy that identifies the marital status declared by the resident. Categories (1) Married, (0) Not married.&lt;/p&gt;
&lt;p&gt;Variable 8 - GEOGRAPHICAL REGION? Format N - Numeric? Size 1 digit (1 byte)? Number of Categories 5? Summary Description Identifies the resident’s geographic region. Categories (1) North, (2) Northeast, (3) Southeast, (4) South and (5) Midwest.&lt;/p&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;python&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Python&lt;/h1&gt;
&lt;div id=&#34;importing-the-dataset-from-part-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Importing the dataset from part 1&lt;/h2&gt;
&lt;p&gt;You can also dowload it from the &lt;a href=&#34;https://github.com/brunocarlin/TwoSidesData2/tree/master/content/post/data&#34;&gt;github page from this blog&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df_sex_thesis =pd.read_feather(r.file_path_linux + &amp;#39;/sex_thesis_assignment.feather&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df_sex_thesis.info()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;
## RangeIndex: 65795 entries, 0 to 65794
## Data columns (total 9 columns):
## index           65795 non-null int64
## age             65795 non-null int64
## sex             65795 non-null object
## years_study     65795 non-null category
## color_race      65795 non-null object
## salary          65795 non-null float64
## civil_status    65795 non-null object
## region          65795 non-null object
## log_salary      65795 non-null float64
## dtypes: category(1), float64(2), int64(2), object(4)
## memory usage: 4.1+ MB&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s get going first define which variables to add to the hypothesis, to isolate the factor of salary ~ sex, if we consider that our sample of individuals is random in nature comparing the means of the individuals given their sex and seeing if there is a significant difference in their means.&lt;/p&gt;
&lt;p&gt;A good graphic to get an idea if these effects would be significant was the bar plots used in part 1.&lt;/p&gt;
&lt;p&gt;When working with Categorical variable it is possible to use a groupby approach to glimpse at the difference in means.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;python_hypothesis_testing1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Difference in means&lt;/h2&gt;
&lt;p&gt;Using the log salary feature from post 1.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df_agg1 = df_sex_thesis.groupby(&amp;#39;sex&amp;#39;).mean().log_salary
df_agg1&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## sex
## man      9.026607
## woman    8.607023
## Name: log_salary, dtype: float64&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Remember that in order to transform back our log variables you can do e^variable like this e ^ 9.03 is 8321.57 but the log of the mean is not the same as the mean of the log.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df_agg2 = df_sex_thesis.groupby(&amp;#39;sex&amp;#39;).mean().salary
df_agg2&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## sex
## man      14302.491879
## woman    10642.502734
## Name: salary, dtype: float64&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;9.03 is not the same as 9.57&lt;/p&gt;
&lt;p&gt;Therefore which one should be done first log or mean?&lt;/p&gt;
&lt;p&gt;The most common order is log then mean, because it is the order that reduces variance the most, you can read more about this &lt;a href=&#34;http://rpubs.com/hrlai/meanlog_logmean&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;Group by explanation&lt;/summary&gt;
&lt;p&gt;
&lt;p&gt;Group by in pandas is a method that accepts a list of elements in this case just ‘sex’ and applies consequent operation in each group, in this case the mean method from a pandas DataFrame, .salary returns just the mean for the salary variable.&lt;/p&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df_sex_thesis.groupby([&amp;#39;sex&amp;#39;,&amp;#39;region&amp;#39;]).mean().log_salary&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## sex    region   
## man    midwest      9.155421
##        north        8.678263
##        south        9.123554
##        southeast    9.113084
## woman  midwest      8.847172
##        north        8.291580
##        northeast    9.462870
##        south        8.345867
##        southeast    8.766985
## Name: log_salary, dtype: float64&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Adding standard deviations&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df_sex_thesis.groupby([&amp;#39;sex&amp;#39;]).std().log_salary&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## sex
## man      1.397496
## woman    2.009225
## Name: log_salary, dtype: float64&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These are really big Standard deviations! Remembering from stats that +2 SD’s gives about a 95% confidence interval we are not even close.&lt;/p&gt;
&lt;p&gt;Combining mean and std using pandas agg method.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df_agg =df_sex_thesis.groupby([&amp;#39;sex&amp;#39;]).agg([&amp;#39;mean&amp;#39;,&amp;#39;std&amp;#39;]).log_salary&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Calculating boundaries&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df_agg[&amp;#39;lower_bound&amp;#39;] = df_agg[&amp;#39;mean&amp;#39;] - df_agg[&amp;#39;std&amp;#39;] * 2
df_agg[&amp;#39;upper_bound&amp;#39;] = df_agg[&amp;#39;mean&amp;#39;] + df_agg[&amp;#39;std&amp;#39;] * 2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df_agg&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            mean       std  lower_bound  upper_bound
## sex                                                
## man    9.026607  1.397496     6.231615    11.821599
## woman  8.607023  2.009225     4.588573    12.625473&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Cool, but to verbose to be repeated multiple times, it is better to convert this series of operations into a function.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;def groupby_bound(df,groupby_variables,value_variables):
  df_agg =  df.groupby(groupby_variables).agg([&amp;#39;mean&amp;#39;,&amp;#39;std&amp;#39;])[value_variables]
  df_agg[&amp;#39;lower_bound&amp;#39;] = df_agg[&amp;#39;mean&amp;#39;] - df_agg[&amp;#39;std&amp;#39;] * 2
  df_agg[&amp;#39;upper_bound&amp;#39;] = df_agg[&amp;#39;mean&amp;#39;] + df_agg[&amp;#39;std&amp;#39;] * 2
  return df_agg&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;groupby_bound(df=df_sex_thesis,groupby_variables=&amp;#39;sex&amp;#39;,value_variables=&amp;#39;log_salary&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##            mean       std  lower_bound  upper_bound
## sex                                                
## man    9.026607  1.397496     6.231615    11.821599
## woman  8.607023  2.009225     4.588573    12.625473&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s try to find the difference in salary on some strata of the population.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;groupby_bound(df=df_sex_thesis,groupby_variables=[&amp;#39;sex&amp;#39;,&amp;#39;region&amp;#39;],value_variables=&amp;#39;log_salary&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                      mean       std  lower_bound  upper_bound
## sex   region                                                 
## man   midwest    9.155421  1.192631     6.770160    11.540683
##       north      8.678263  1.733378     5.211507    12.145019
##       south      9.123554  1.426591     6.270371    11.976736
##       southeast  9.113084  1.226845     6.659395    11.566773
## woman midwest    8.847172  1.575228     5.696717    11.997627
##       north      8.291580  2.470543     3.350495    13.232665
##       northeast  9.462870  1.172049     7.118773    11.806968
##       south      8.345867  2.461307     3.423253    13.268482
##       southeast  8.766985  1.639338     5.488309    12.045660&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;No.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;groupby_bound(df=df_sex_thesis,groupby_variables=[&amp;#39;sex&amp;#39;,&amp;#39;civil_status&amp;#39;],value_variables=&amp;#39;log_salary&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                         mean       std  lower_bound  upper_bound
## sex   civil_status                                              
## man   married       9.173335  1.247871     6.677593    11.669077
##       not_married   8.810261  1.567870     5.674521    11.946001
## woman married       8.487709  2.263061     3.961586    13.013831
##       not_married   8.771966  1.578347     5.615272    11.928659&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;No.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;groupby_bound(df=df_sex_thesis,groupby_variables=[&amp;#39;sex&amp;#39;,&amp;#39;civil_status&amp;#39;],value_variables=&amp;#39;log_salary&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                         mean       std  lower_bound  upper_bound
## sex   civil_status                                              
## man   married       9.173335  1.247871     6.677593    11.669077
##       not_married   8.810261  1.567870     5.674521    11.946001
## woman married       8.487709  2.263061     3.961586    13.013831
##       not_married   8.771966  1.578347     5.615272    11.928659&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;No.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;groupby_bound(df=df_sex_thesis,groupby_variables=[&amp;#39;sex&amp;#39;,&amp;#39;color_race&amp;#39;],value_variables=&amp;#39;log_salary&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                       mean       std  lower_bound  upper_bound
## sex   color_race                                              
## man   black       8.885541  1.215289     6.454962    11.316119
##       brown       8.878127  1.348974     6.180179    11.576076
##       indigenous  7.480596  3.328801     0.822994    14.138197
##       white       9.215328  1.369700     6.475927    11.954728
##       yellow      9.503222  1.398690     6.705843    12.300601
## woman black       8.617966  1.683712     5.250543    11.985389
##       brown       8.518060  2.025707     4.466647    12.569473
##       indigenous  7.623917  3.342682     0.938553    14.309282
##       white       8.696991  2.001864     4.693263    12.700718
##       yellow      8.904886  1.877233     5.150420    12.659351&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;No.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;groupby_bound(df=df_sex_thesis,groupby_variables=[&amp;#39;sex&amp;#39;,&amp;#39;years_study&amp;#39;],value_variables=&amp;#39;log_salary&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                         mean       std  lower_bound  upper_bound
## sex   years_study                                               
## man   5.0           8.702990  1.495661     5.711668    11.694312
##       6.0           8.836372  1.285517     6.265338    11.407407
##       7.0           8.883292  1.302857     6.277578    11.489006
##       8.0           8.939945  1.342110     6.255724    11.624166
##       9.0           8.873640  1.292672     6.288296    11.458984
##       10.0          9.064804  1.122187     6.820430    11.309177
##       11.0          9.182335  1.163925     6.854486    11.510184
##       12.0          9.274507  1.187977     6.898553    11.650462
##       13.0          9.308213  1.651300     6.005613    12.610812
##       14.0          9.563542  1.295638     6.972267    12.154817
##       15.0         10.083954  1.334792     7.414369    12.753538
## woman 5.0           8.150536  2.574328     3.001881    13.299191
##       6.0           8.577851  1.854171     4.869508    12.286194
##       7.0           8.572043  1.743439     5.085165    12.058921
##       8.0           8.480459  1.952266     4.575927    12.384991
##       9.0           8.609875  1.583736     5.442403    11.777346
##       10.0          8.735525  1.403048     5.929428    11.541622
##       11.0          8.755282  1.518318     5.718647    11.791918
##       12.0          8.906622  1.505541     5.895540    11.917705
##       13.0          8.963868  1.555327     5.853213    12.074523
##       14.0          9.146458  1.263748     6.618962    11.673954
##       15.0          9.572653  1.228241     7.116171    12.029134&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Also no.&lt;/p&gt;
&lt;p&gt;Does that mean that there were no Gender pay differences in Brazil in 1970?&lt;/p&gt;
&lt;p&gt;No, it just means that there were no signs of this difference when looking at the whole population combined with one extra factor, but what if we combine all factors and isolate each influence in the salary? This would be a way to analyse the Ceteris Paribus(all else equal) effect of each feature in the salary, here is where Linear Regression comes in.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;linear-regression&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Linear Regression&lt;/h2&gt;
&lt;p&gt;But what is Linear Regression? you might ask, wasn’t it just one method for prediction? Not really, Linear Regression coefficients are really useful for hypothesis testing, meaning that tossing everything at it and then interpreting the results that come out without having to individually compare each feature pair, while also capturing the effect that all features have simultaneously.&lt;/p&gt;
&lt;p&gt;Is Linear Regression always perfect? No. In fact most of the time the results are a little biased or a underestimate the variance or are just flat out wrong.&lt;/p&gt;
&lt;p&gt;To understand the kinds of errors we might face when doing a linear regression we can use the Gauss Markov Theorem.&lt;/p&gt;
&lt;p&gt;Terminology:&lt;/p&gt;
&lt;p&gt;Predictor/Independent Variable: Theses are the features e.g sex,years_study, region we can have p predictors where p = n -1 and n is the numbers of rows our dataset possesses in this case 65795 rows are present.&lt;/p&gt;
&lt;p&gt;Predicted/Dependent variable: This is the single “column” also called ‘target’ that we are modeling in this case we can use either log_salary or salary.&lt;/p&gt;
&lt;p&gt;for a more in depth read this great &lt;a href=&#34;https://www.statisticshowto.datasciencecentral.com/gauss-markov-theorem-assumptions/&#34;&gt;blog post&lt;/a&gt; and for a more &lt;a href=&#34;https://towardsdatascience.com/verifying-the-assumptions-of-linear-regression-in-python-and-r-f4cd2907d4c0&#34;&gt;in depth usage in R and Python&lt;/a&gt;&lt;/p&gt;
&lt;div id=&#34;masks&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Linearity&lt;/h3&gt;
&lt;p&gt;To get good results using Linear Regression the relationship of the Predictors and the Predicted variable has to be a linear relationship, to check for Linearity it is possible to use a simple line plot, and look for patterns like a parabola that would indicate that the Predictor has a quadratic relationship with the Dependent variable, there are ways of fixing non-linear relationships like we did with log_salary or by taking the power of the Predictor.&lt;/p&gt;
&lt;p&gt;Linearity can easily be tested for numerical Predictors, categorical predictors are harder to test, so in our case we only checked the age feature.&lt;/p&gt;
&lt;p&gt;Now it is time to flex these matplotlib graphs…&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;x = df_sex_thesis[&amp;#39;age&amp;#39;]
y = df_sex_thesis[&amp;#39;log_salary&amp;#39;]
plt.scatter(x, y)

z = np.polyfit(x, y, 1)
p = np.poly1d(z)
plt.plot(x,p(x),&amp;quot;r--&amp;quot;)

plt.show()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020/01/25/index_files/figure-html/unnamed-chunk-19-1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;It seems age is not a great fit let’s try to also log age as well.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;x = np.log(df_sex_thesis[&amp;#39;age&amp;#39;])
y = df_sex_thesis[&amp;#39;log_salary&amp;#39;]
plt.scatter(x, y)

z = np.polyfit(x, y, 1)
p = np.poly1d(z)
plt.plot(x,p(x),&amp;quot;r--&amp;quot;)

plt.show()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020/01/25/index_files/figure-html/unnamed-chunk-20-1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Better but still close to no impact, maybe if we filter our sample to just the earning population, we can improve on it, we can call theses filters ‘masks’ in pandas.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df_filter = df_sex_thesis[df_sex_thesis[&amp;#39;log_salary&amp;#39;]&amp;gt; 2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df_filter&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        index  age    sex  ... civil_status     region  log_salary
## 0          0   53    man  ...      married      north   11.060384
## 1          1   49  woman  ...      married      north    9.427336
## 2          2   22  woman  ...  not_married  northeast    8.378713
## 3          3   55    man  ...      married      north   11.478344
## 4          4   56  woman  ...      married      north   11.969090
## ...      ...  ...    ...  ...          ...        ...         ...
## 65790  66465   34  woman  ...      married    midwest    9.427336
## 65791  66466   40    man  ...      married    midwest    7.793999
## 65792  66467   36  woman  ...      married    midwest    7.793999
## 65793  66468   27  woman  ...      married    midwest    8.617075
## 65794  66469   37    man  ...      married    midwest    6.134157
## 
## [63973 rows x 9 columns]&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;x = df_filter[&amp;#39;age&amp;#39;]
y = df_filter[&amp;#39;log_salary&amp;#39;]
plt.scatter(x, y)

z = np.polyfit(x, y, 1)
p = np.poly1d(z)
plt.plot(x,p(x),&amp;quot;r--&amp;quot;)

plt.show()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020/01/25/index_files/figure-html/unnamed-chunk-23-1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;There is some slight improvement, it is a good question whether to filter otherwise sane values, the point is that the entire analysis would change, changing to salary ~ sex in the earning population in 1970 in Brazil instead of the salary ~ sex for the whole population in 1970 in Brazil.&lt;/p&gt;
&lt;p&gt;I think in both cases analyzing the Gender Pay Gap would be interesting it is even possible to split the hypothesis in two, analysing if Men and Women earn the same, and if Men and Women are have the same employment rate.&lt;/p&gt;
&lt;p&gt;So for here on out We are analyzing just the Gender Pay Difference of employed people.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;random&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Random&lt;/h3&gt;
&lt;p&gt;This is a vital hypotheses it means that the observations(rows) were chosen at random for the entire Brazilian population, in this case We choose to trust that IBGE did a good job, if IBGE failed to correctly sample the population or if we mess to much with our filters we risk invalidating the whole process, yes that is right, if you don’t respect this hypothesis everything you have analysed is worthless.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;non-collinearity&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Non-Collinearity&lt;/h3&gt;
&lt;p&gt;The effect of each Predictors is reduced when you introduce Colinear predictors, you are spliting the effect between the Predictors whenever a new predictor is added, meaning that you are in the worst case only calculating half of the coefficient, Collinearity always happens, Women live more so age is related to Sex, therefore age ‘steals’ part of the calculated effect from Sex, the more variables you introduce to your Linear Regression model the more that Collinearity plagues your estimations, everything is correlated.&lt;/p&gt;
&lt;p&gt;So be careful when doing Linear Regression for estimating Ceteris Paribus effects so that you don’t introduce too many features or features that are too correlated with you hypothesis, remember that our hypothesis is Salary ~ Sex.&lt;/p&gt;
&lt;p&gt;A good way too know if you are introducing too much Collinearity is looking at the heatmap.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;corr = pd.get_dummies(df_sex_thesis[[&amp;#39;sex&amp;#39;,&amp;#39;age&amp;#39;]]).corr()
sns.heatmap(corr)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020/01/25/index_files/figure-html/unnamed-chunk-24-1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;This is quite cloudy let’s get rid of the Sex interaction with itself.&lt;/p&gt;
&lt;p&gt;We are using a really cool pandas operation inspired this &lt;a href=&#34;https://stackoverflow.com/a/36567174&#34;&gt;stack overflow answer&lt;/a&gt;, and combining it with the negate operator ‘~’ effectively selecting just the columns that don’t start with sex.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;new_corr = corr.loc[:,~corr.columns.str.startswith(&amp;#39;sex&amp;#39;)]
sns.heatmap(new_corr)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020/01/25/index_files/figure-html/unnamed-chunk-25-1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Very little correlation, we are fine.&lt;/p&gt;
&lt;p&gt;Once again we don’t usually calculate the correlation between Categorical Variables.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;exogeneity&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Exogeneity&lt;/h3&gt;
&lt;p&gt;If violated this hypothesis blasts your study into oblivion, Exogeneity is a one way road, your Independent Variables influence your Dependent Variable, and that is it.&lt;/p&gt;
&lt;p&gt;Discussion on whether we are violating this assumption creates really cool intellectual pursuits, Nobel’s were won discovering if there was some violation to this assumption see &lt;a href=&#34;https://en.wikipedia.org/wiki/Trygve_Haavelmo&#34;&gt;Trygve_Haavelmo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In our case let’s hypothesize for all variables&lt;/p&gt;
&lt;p&gt;Sex ~ Salary - Maybe people that get richer/poorer change Sex, probably not.&lt;br /&gt;
Age ~ Salary - You can’t buy year with money .
Years Study ~ Salary - Possible but this probably only happen to the latter years of education, still worth considering.
Color/Race ~ Salary -
No. Civil Status ~ Salary - Yes I can see that, taking this feature out.&lt;br /&gt;
Region ~ Salary - Do richer people migrate to richer regions? I think so, taking this feature out.&lt;/p&gt;
&lt;p&gt;It is also nice to notice that this may be reason why we call the Predicted Variable the Independent Variable.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;homoscedasticity-homogeneity-of-variance-assumption-of-equal-variance&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Homoscedasticity / Homogeneity of Variance/ Assumption of Equal Variance&lt;/h3&gt;
&lt;p&gt;Assumption of Equal Variance of predicted values means that for any value for the whole distribution of the Dependent Variable the estimated values remain equally distributted, meaning that we are as sure on our predictions for 1000 moneys as for 100000 moneys this assumption is really hard to adhere.&lt;/p&gt;
&lt;p&gt;If broken the variance of the coefficients may be under or over estimated, meaning that we may fail to consider relevant features or consider wrongly irrelevant features, there are many formal statistical tests for this assumption let’s use scipy’s Bartlett’s test for homogeneity of variances where Ho is Homoscedasticity confirmation meaning we hope for p-values &amp;lt; 0.05.&lt;/p&gt;
&lt;p&gt;We used a significance level of 5% for this assignment.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;ss.bartlett(df_filter[&amp;#39;log_salary&amp;#39;],df_filter[&amp;#39;age&amp;#39;])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## BartlettResult(statistic=232468.57113475894, pvalue=0.0)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Don’t reject H0 -&amp;gt; ok&lt;/p&gt;
&lt;p&gt;Another way to check this assumption is using tests called Breusch-Pagan and Goldfeld-Quandt post fitting the linear model.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;python_hypothesis_testing2&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Fitting the linear regression&lt;/h2&gt;
&lt;p&gt;Fitting the linear regression using yet another library called statsmodels.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;mod = smf.ols(formula=&amp;#39;log_salary ~ sex + age + years_study + color_race&amp;#39;, data=df_filter)
model_fit = mod.fit()
print(model_fit.summary())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                             OLS Regression Results                            
## ==============================================================================
## Dep. Variable:             log_salary   R-squared:                       0.133
## Model:                            OLS   Adj. R-squared:                  0.133
## Method:                 Least Squares   F-statistic:                     613.6
## Date:                sáb, 25 jan 2020   Prob (F-statistic):               0.00
## Time:                        21:25:45   Log-Likelihood:                -81546.
## No. Observations:               63973   AIC:                         1.631e+05
## Df Residuals:                   63956   BIC:                         1.633e+05
## Df Model:                          16                                         
## Covariance Type:            nonrobust                                         
## ============================================================================================
##                                coef    std err          t      P&amp;gt;|t|      [0.025      0.975]
## --------------------------------------------------------------------------------------------
## Intercept                    8.3200      0.019    440.777      0.000       8.283       8.357
## sex[T.woman]                -0.2125      0.007    -30.970      0.000      -0.226      -0.199
## years_study[T.6.0]           0.1520      0.020      7.756      0.000       0.114       0.190
## years_study[T.7.0]           0.1728      0.018      9.441      0.000       0.137       0.209
## years_study[T.8.0]           0.1721      0.014     12.391      0.000       0.145       0.199
## years_study[T.9.0]           0.1395      0.019      7.449      0.000       0.103       0.176
## years_study[T.10.0]          0.2414      0.018     13.444      0.000       0.206       0.277
## years_study[T.11.0]          0.3314      0.009     35.414      0.000       0.313       0.350
## years_study[T.12.0]          0.3826      0.018     21.100      0.000       0.347       0.418
## years_study[T.13.0]          0.5989      0.025     24.032      0.000       0.550       0.648
## years_study[T.14.0]          0.6619      0.025     25.988      0.000       0.612       0.712
## years_study[T.15.0]          1.0396      0.013     78.438      0.000       1.014       1.066
## color_race[T.brown]          0.0487      0.013      3.696      0.000       0.023       0.075
## color_race[T.indigenous]     0.0587      0.040      1.451      0.147      -0.021       0.138
## color_race[T.white]          0.1805      0.013     13.736      0.000       0.155       0.206
## color_race[T.yellow]         0.2401      0.050      4.776      0.000       0.142       0.339
## age                          0.0129      0.000     40.197      0.000       0.012       0.014
## ==============================================================================
## Omnibus:                    14771.140   Durbin-Watson:                   1.806
## Prob(Omnibus):                  0.000   Jarque-Bera (JB):            45603.025
## Skew:                          -1.188   Prob(JB):                         0.00
## Kurtosis:                       6.386   Cond. No.                         584.
## ==============================================================================
## 
## Warnings:
## [1] Standard Errors assume that the covariance matrix of the errors is correctly specified.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Looking at the results, it is possible that there isGender Pay Gap, calculating the difference in estimated salaries done by&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;plus intercept + e ^ beta_variable = 5077,12&lt;/li&gt;
&lt;li&gt;minus intercept 4105,16&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;equals 971,96.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There is a 971,96 difference between men and women salaries in the earning population of Brazil in 1970 quite significant at 7,59% of the mean salary at the time.&lt;/p&gt;
&lt;div id=&#34;linear-regression-plots&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Linear Regression plots&lt;/h3&gt;
&lt;p&gt;Using the code from this excellent &lt;a href=&#34;https://medium.com/@emredjan/emulating-r-regression-plots-in-python-43741952c034&#34;&gt;post&lt;/a&gt; and combining it with the understanding from this &lt;a href=&#34;https://data.library.virginia.edu/diagnostic-plots/&#34;&gt;post&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# fitted values (need a constant term for intercept)
model_fitted_y = model_fit.fittedvalues

# model residuals
model_residuals = model_fit.resid

# normalized residuals
model_norm_residuals = model_fit.get_influence().resid_studentized_internal

# absolute squared normalized residuals
model_norm_residuals_abs_sqrt = np.sqrt(np.abs(model_norm_residuals))

# absolute residuals
model_abs_resid = np.abs(model_residuals)

# leverage, from statsmodels internals
model_leverage = model_fit.get_influence().hat_matrix_diag

# cook&amp;#39;s distance, from statsmodels internals
model_cooks = model_fit.get_influence().cooks_distance[0]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Initializing some variables.
### Residual plot&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plot_lm_1 = plt.figure(1)

plot_lm_1.axes[0] = sns.residplot(model_fitted_y, &amp;#39;log_salary&amp;#39;, data=df_filter,
                                  lowess=True,
                                  scatter_kws={&amp;#39;alpha&amp;#39;: 0.5},
                                  line_kws={&amp;#39;color&amp;#39;: &amp;#39;red&amp;#39;, &amp;#39;lw&amp;#39;: 1, &amp;#39;alpha&amp;#39;: 0.8})

plot_lm_1.axes[0].set_title(&amp;#39;Residuals vs Fitted&amp;#39;)
plot_lm_1.axes[0].set_xlabel(&amp;#39;Fitted values&amp;#39;)
plot_lm_1.axes[0].set_ylabel(&amp;#39;Residuals&amp;#39;)


# annotations
abs_resid = model_abs_resid.sort_values(ascending=False)
abs_resid_top_3 = abs_resid[:3]

for i in abs_resid_top_3.index:
    plot_lm_1.axes[0].annotate(i, 
                               xy=(model_fitted_y[i], 
                                   model_residuals[i]));&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020/01/25/index_files/figure-html/unnamed-chunk-29-1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Here we are looking for the red line to get as close to the doted black line meaning that our Predictors would have a perfectly linear relationship with our Dependent variable following the assumption of linearity.&lt;/p&gt;
&lt;p&gt;I think we are close enough.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;qq-plot&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;QQ plot&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;QQ = ProbPlot(model_norm_residuals)
plot_lm_2 = QQ.qqplot(line=&amp;#39;45&amp;#39;, alpha=0.5, color=&amp;#39;#4C72B0&amp;#39;, lw=1)

plot_lm_2.axes[0].set_title(&amp;#39;Normal Q-Q&amp;#39;)
plot_lm_2.axes[0].set_xlabel(&amp;#39;Theoretical Quantiles&amp;#39;)
plot_lm_2.axes[0].set_ylabel(&amp;#39;Standardized Residuals&amp;#39;);

# annotations
abs_norm_resid = np.flip(np.argsort(np.abs(model_norm_residuals)), 0)
abs_norm_resid_top_3 = abs_norm_resid[:3]

for r, i in enumerate(abs_norm_resid_top_3):
    plot_lm_2.axes[0].annotate(i, 
                               xy=(np.flip(QQ.theoretical_quantiles, 0)[r],
                                   model_norm_residuals[i]));&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020/01/25/index_files/figure-html/unnamed-chunk-30-1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Here we are looking for the circles to get as close to the red line as possible meaning that our variables follow a normal distribution and therefore our p-values are not biased.&lt;/p&gt;
&lt;p&gt;I think we have two problems the extremes may be a bit too distant and there are three concerning outliers.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;scale-location-plot&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Scale-Location Plot&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plot_lm_3 = plt.figure(3)

plt.scatter(model_fitted_y, model_norm_residuals_abs_sqrt, alpha=0.5)
sns.regplot(model_fitted_y, model_norm_residuals_abs_sqrt, 
            scatter=False, 
            ci=False, 
            lowess=True,
            line_kws={&amp;#39;color&amp;#39;: &amp;#39;red&amp;#39;, &amp;#39;lw&amp;#39;: 1, &amp;#39;alpha&amp;#39;: 0.8})

plot_lm_3.axes[0].set_title(&amp;#39;Scale-Location&amp;#39;)
plot_lm_3.axes[0].set_xlabel(&amp;#39;Fitted values&amp;#39;)
plot_lm_3.axes[0].set_ylabel(&amp;#39;$\sqrt{|Standardized Residuals|}$&amp;#39;);

# annotations
abs_sq_norm_resid = np.flip(np.argsort(model_norm_residuals_abs_sqrt), 0)
abs_sq_norm_resid_top_3 = abs_sq_norm_resid[:3]

for i in abs_norm_resid_top_3:
    plot_lm_3.axes[0].annotate(i, 
                               xy=(model_fitted_y[i], 
                                   model_norm_residuals_abs_sqrt[i]));&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020/01/25/index_files/figure-html/unnamed-chunk-31-1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;This is the graph where we check the homoscedasticity assumption, we want the red line to be as straight as possible meaning that our Predictor variance is constant among the Dependent Variable values.&lt;/p&gt;
&lt;p&gt;I think it is fine.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;leverage-plot&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Leverage plot&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plot_lm_4 = plt.figure(4)

plt.scatter(model_leverage, model_norm_residuals, alpha=0.5)
sns.regplot(model_leverage, model_norm_residuals, 
            scatter=False, 
            ci=False, 
            lowess=True,
            line_kws={&amp;#39;color&amp;#39;: &amp;#39;red&amp;#39;, &amp;#39;lw&amp;#39;: 1, &amp;#39;alpha&amp;#39;: 0.8})

plot_lm_4.axes[0].set_xlim(0, 0.005)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## (0, 0.005)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plot_lm_4.axes[0].set_ylim(-3, 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## (-3, 5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plot_lm_4.axes[0].set_title(&amp;#39;Residuals vs Leverage&amp;#39;)
plot_lm_4.axes[0].set_xlabel(&amp;#39;Leverage&amp;#39;)
plot_lm_4.axes[0].set_ylabel(&amp;#39;Standardized Residuals&amp;#39;)

# annotations
leverage_top_3 = np.flip(np.argsort(model_cooks), 0)[:3]

for i in leverage_top_3:
    plot_lm_4.axes[0].annotate(i, 
                               xy=(model_leverage[i], 
                                   model_norm_residuals[i]))
    
# shenanigans for cook&amp;#39;s distance contours
def graph(formula, x_range, label=None):
    x = x_range
    y = formula(x)
    plt.plot(x, y, label=label, lw=1, ls=&amp;#39;--&amp;#39;, color=&amp;#39;red&amp;#39;)

p = len(model_fit.params) # number of model parameters

graph(lambda x: np.sqrt((0.5 * p * (1 - x)) / x), 
      np.linspace(0.000, 0.005, 50), 
      &amp;#39;Cook\&amp;#39;s distance&amp;#39;) # 0.5 line&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## /home/bruno-carlin/Documents/GIthub/TwoSidesData2/.venv/bin/activate_this.py:1: RuntimeWarning: divide by zero encountered in true_divide
##   &amp;quot;&amp;quot;&amp;quot;Activate virtualenv for current interpreter:&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;graph(lambda x: np.sqrt((1 * p * (1 - x)) / x), 
      np.linspace(0.000, 0.005, 50)) # 1 line

plt.legend(loc=&amp;#39;upper right&amp;#39;);&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020/01/25/index_files/figure-html/unnamed-chunk-32-1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Finally in this plot we are looking for outliers, it failed on the Python version, but it should show if the outliers plague the betas enough to the point where it may be worth studying removing them.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020/01/25/index_files/figure-html/unnamed-chunk-33-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;We want the Red line to be as close as possible to the dotted line.&lt;/p&gt;
&lt;p&gt;Looking at the R plot We can say it is fine.&lt;/p&gt;
&lt;p&gt;At the end I am comfortable not denying our Hypothesis that Salary ~ Sex in 1970 Brazil working population.&lt;/p&gt;
&lt;p&gt;And that is it, Statistical analysis with almost no R! .&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;final-remarks&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Final Remarks&lt;/h1&gt;
&lt;p&gt;I guess my opinion is important in this post, this was really hard, Python may be an excellent Prediction based language but it lacks so much on my normal Economist features that I have easily available even when using Stata/E-Views/SAS, like look at how much code for a simple linear regression plot!&lt;/p&gt;
&lt;p&gt;I don’t have much hope that this will improve with time, normal statistics just doesn’t get as much hype as Deep Learning and stuff I feel sorry for whoever has to learn stats alongside Python, you guys deserve a Medal! Also I applaud the guys that Developed statsmodels.formula.api it really helps!&lt;/p&gt;
&lt;p&gt;Whoever develops with matplotlib deserves two medals, you guys make me feel dumber than when I read my first Time Series paper and that was a really low point in my self esteem, the graphs turned out great in my honest opinion.&lt;/p&gt;
&lt;p&gt;If you liked it please share it.&lt;/p&gt;
&lt;div id=&#34;next-post&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Next post&lt;/h2&gt;
&lt;p&gt;In the next part we repeat everything from part 1 with a few twists in R using the tidyverse!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>exploratory data analysis: basics Python part 1</title>
      <link>/2020/01/19/exploratory-data-analysis-basics-part1/</link>
      <pubDate>Sun, 19 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/2020/01/19/exploratory-data-analysis-basics-part1/</guid>
      <description>

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#libraries&#34;&gt;Libraries&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#the-exercise&#34;&gt;The Exercise&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#before-we-get-into-it&#34;&gt;Before we get into it&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#objectives&#34;&gt;Objectives&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#reservations&#34;&gt;Reservations&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-dictionary&#34;&gt;Data Dictionary&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#python&#34;&gt;Python&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#python_pre_processing&#34;&gt;Pre-processing&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#python_read_data&#34;&gt;Reading Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#analyzing-some-basic-stuff-about-our-data-frame&#34;&gt;Analyzing some basic stuff about our data frame&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#replacing-columns-names&#34;&gt;Replacing columns names&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cleaning-categorical-data&#34;&gt;Cleaning categorical data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#python_plots_categorical&#34;&gt;Seeing the effects of categorical Variables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#cleaning-numerical-data&#34;&gt;Cleaning numerical data&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#saving-our-work-for-later&#34;&gt;Saving our work for later&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#next-post&#34;&gt;Next post&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;I am currently doing exercises from &lt;a href=&#34;https://github.com/sn3fru/datascience_course&#34;&gt;digital house brasil&lt;/a&gt;&lt;/p&gt;
&lt;div id=&#34;libraries&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Libraries&lt;/h1&gt;
&lt;p&gt;Let’s see what version of python this env is running.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import platform
print(platform.python_version())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 3.7.4&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import os&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;the-exercise&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;The Exercise&lt;/h1&gt;
&lt;div id=&#34;before-we-get-into-it&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Before we get into it&lt;/h2&gt;
&lt;div id=&#34;objectives&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Objectives&lt;/h3&gt;
&lt;div id=&#34;open-and-read-a-dataframe-using-pandas&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Open and read a DataFrame using pandas&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;#python_read_data&#34;&gt;Simple stuff right?&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;basic-analysis-of-each-column-using-value-counts.&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Basic analysis of each column using value counts.&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;#python_custom_funtion_1&#34;&gt;I improved a bit on the base python capabilities&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-a-hypothesis-that-we-care-about&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Creating a hypothesis that we care about&lt;/h4&gt;
&lt;p&gt;In our case the hypothesis is simple do women earn on average less than men?&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-preprocessing&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Data preprocessing&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;#python_pre_processing&#34;&gt;We need to clean the data removing outliers, biases or any other factors that could in theory compromise our hypothesis testing.&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;visualize-all-the-variables&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Visualize all the variables&lt;/h4&gt;
&lt;p&gt;We were free to apply any technique.&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;#python_plots_categorical&#34;&gt;Categorical Data&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;to-do-in-the-second-post&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;To do in the second post&lt;/h4&gt;
&lt;/div&gt;
&lt;div id=&#34;define-the-variables-used-in-the-conclusion&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Define the variables used in the conclusion&lt;/h4&gt;
&lt;p&gt;In our case, we choose to use &lt;a href=&#34;#python_hypothesis_testing&#34;&gt;salary ~ sex,region&lt;/a&gt; region was added to test whether &lt;a href=&#34;https://en.wikipedia.org/wiki/Simpson%27s_paradox&#34;&gt;Simpson’s paradox&lt;/a&gt; was at play.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;using-masks-or-other-methods-to-filter-the-data&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Using masks or other methods to filter the data&lt;/h4&gt;
&lt;p&gt;This objective was mostly done using the groupby function.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;visualizing-the-hypothesis&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Visualizing the hypothesis&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;#python_plot_histograms&#34;&gt;We were advised to use two histograms combined to get a preview of our answer.&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Conclusion&lt;/h4&gt;
&lt;p&gt;Comment on our findings.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;reservations&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Reservations&lt;/h3&gt;
&lt;p&gt;This is an exercise where we were supposed to ask a relevant question using the data from the IBGE(Brazil’s main data collector) database of 1970.&lt;/p&gt;
&lt;p&gt;Our group decided to ask whether women received less than man, we expanded the analysis hoping to avoid the Simpson’s paradox.&lt;/p&gt;
&lt;p&gt;This is just an basic inference, and it’s results are therefore only used for studying purposes I don’t believe any finding would be relevant using just this approach but some basic operations can be used in a more impact full work.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-dictionary&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Data Dictionary&lt;/h3&gt;
&lt;p&gt;We got a Data Dictionary that will be very useful for our Analysis, it contains all the required information about the encoding of the columns and the intended format that the folks at STATA desired.&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;Portuguese&lt;/summary&gt;
&lt;p&gt;
&lt;p&gt;Descrição do Registro de Indivíduos nos EUA.&lt;/p&gt;
&lt;p&gt;Dataset do software STATA (pago), vamos abri-lo com o pandas e transforma-lo em DataFrame.&lt;/p&gt;
&lt;p&gt;Variável 1 – CHAVE DO INDIVÍDUO ? Formato N - Numérico ? Tamanho 11 dígitos (11 bytes) ? Descrição Sumária Identifica unicamente o indivíduo na amostra.&lt;/p&gt;
&lt;p&gt;Variável 2 - IDADE CALCULADA EM ANOS ? Formato N - Numérico ? Tamanho 3 dígitos (3 bytes) ? Descrição Sumária Identifica a idade do morador em anos completos.&lt;/p&gt;
&lt;p&gt;Variável 3 – SEXO ? Formato N - Numérico ? Tamanho 1 dígito (1 byte) ? Quantidade de Categorias 3 ? Descrição Sumária Identifica o sexo do morador. Categorias (1) homem, (2) mulher e (3) gestante.&lt;/p&gt;
&lt;p&gt;Variável 4 – ANOS DE ESTUDO ? Formato N - Numérico ? Tamanho 2 dígitos (2 bytes) ? Quantidade de Categorias 11 ? Descrição Sumária Identifica o número de anos de estudo do morador. Categorias (05) Cinco ou menos, (06) Seis, (07) Sete, (08) Oito, (09) Nove, (10) Dez, (11) Onze, (12) Doze, (13) Treze, (14) Quatorze, (15) Quinze ou mais.&lt;/p&gt;
&lt;p&gt;Variável 5 – COR OU RAÇA ? Formato N - Numérico ? Tamanho 2 dígitos (2 bytes) ? Quantidade de Categorias 6 ? Descrição Sumária Identifica a Cor ou Raça declarada pelo morador. Categorias (01) Branca, (02) Preta, (03) Amarela, (04) Parda, (05) Indígena e (09) Não Sabe.&lt;/p&gt;
&lt;p&gt;Variável 6 – VALOR DO SALÁRIO (ANUALIZADO) ? Formato N - Numérico ? Tamanho 8 dígitos (8 bytes) ? Quantidade de Decimais 2 ? Descrição Sumária Identifica o valor resultante do salário anual do indivíduo. Categorias especiais (-1) indivíduo ausente na data da pesquisa e (999999) indivíduo não quis responder.&lt;/p&gt;
&lt;p&gt;Variável 7 – ESTADO CIVIL ? Formato N - Numérico ? Tamanho 1 dígito (1 byte) ? Quantidade de Categorias 2 ? Descrição Sumária Dummy que identifica o estado civil declarado pelo morador. Categorias (1) Casado, (0) não casado.&lt;/p&gt;
&lt;p&gt;Variável 8 – REGIÃO GEOGRÁFICA ? Formato N - Numérico ? Tamanho 1 dígito (1 byte) ? Quantidade de Categorias 5 ? Descrição Sumária Identifica a região geográfica do morador. Categorias (1) Norte, (2) Nordeste, (3) Sudeste, (4) Sul e (5) Centro-oeste.&lt;/p&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;English&lt;/summary&gt;
&lt;p&gt;
&lt;p&gt;Description of the US Individual Registry.&lt;/p&gt;
&lt;p&gt;Dataset of the STATA software (paid), we will open it with pandas and turn it into DataFrame.&lt;/p&gt;
&lt;p&gt;Variable 1 - KEY OF THE INDIVIDUAL? Format N - Numeric? Size 11 digits (11 bytes)? Summary Description Uniquely identifies the individual in the sample.&lt;/p&gt;
&lt;p&gt;Variable 2 - AGE CALCULATED IN YEARS? Format N - Numeric? Size 3 digits (3 bytes)? Summary Description Identifies the age of the resident in full years.&lt;/p&gt;
&lt;p&gt;Variable 3 - SEX? Format N - Numeric? Size 1 digit (1 byte)? Number of Categories 3? Summary Description Identifies the gender of the resident. Categories (1) men, (2) women and (3) pregnant women.&lt;/p&gt;
&lt;p&gt;Variable 4 - YEARS OF STUDY? Format N - Numeric? Size 2 digits (2 bytes)? Number of Categories 11? Summary Description Identifies the number of years of study of the resident. Categories (05) Five or less, (06) Six, (07) Seven, (08) Eight, (09) Nine, (10) Dec, (11) Eleven, (12) Twelve, (13) Thirteen, (14 ) Fourteen, (15) Fifteen or more.&lt;/p&gt;
&lt;p&gt;Variable 5 - COLOR OR RACE? Format N - Numeric? Size 2 digits (2 bytes)? Number of Categories 6? Summary Description Identifies the Color or Race declared by the resident. Categories (01) White, (02) Black, (03) Yellow, (04) Brown, (05) Indigenous and (09) Don’t know.&lt;/p&gt;
&lt;p&gt;Variable 6 - WAGE VALUE (ANNUALIZED)? Format N - Numeric? Size 8 digits (8 bytes)? Number of decimals 2? Summary Description Identifies the amount resulting from the individual’s annual salary. Special categories (-1) individual absent on the survey date and (999999) individual did not want to answer.&lt;/p&gt;
&lt;p&gt;Variable 7 - CIVIL STATE? Format N - Numeric? Size 1 digit (1 byte)? Number of Categories 2? Summary Description Dummy that identifies the marital status declared by the resident. Categories (1) Married, (0) Not married.&lt;/p&gt;
&lt;p&gt;Variable 8 - GEOGRAPHICAL REGION? Format N - Numeric? Size 1 digit (1 byte)? Number of Categories 5? Summary Description Identifies the resident’s geographic region. Categories (1) North, (2) Northeast, (3) Southeast, (4) South and (5) Midwest.&lt;/p&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;python&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Python&lt;/h1&gt;
&lt;div id=&#34;python_pre_processing&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Pre-processing&lt;/h2&gt;
&lt;div id=&#34;python_read_data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Reading Data&lt;/h3&gt;
&lt;p&gt;The path is specific for my computer but it is easy to adapt&lt;/p&gt;
&lt;p&gt;You can also dowload it from the &lt;a href=&#34;https://github.com/brunocarlin/TwoSidesData2/tree/master/content/post/data&#34;&gt;github page from this blog&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# Abertura e leitura dos dados em um DeteFrame em Pandas
path = r.file_path_linux
df = pd.read_csv(path + &amp;#39;/stata_data_1970.csv&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;analyzing-some-basic-stuff-about-our-data-frame&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Analyzing some basic stuff about our data frame&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;#Análise básica dos conteúdos de cada coluna com contagem de valores
df.info()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;
## RangeIndex: 66470 entries, 0 to 66469
## Data columns (total 9 columns):
## Unnamed: 0      66470 non-null int64
## id              66470 non-null float64
## idade           66470 non-null int64
## sexo            66470 non-null object
## anos_estudo     66036 non-null float64
## cor/raca        66228 non-null object
## salario         47878 non-null float64
## estado_civil    66470 non-null float64
## regiao          66470 non-null object
## dtypes: float64(4), int64(2), object(3)
## memory usage: 4.6+ MB&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I do enjoy python’s base value_counts but when used in a loop it can create some ugly outputs, in order to fix I created a function that adds some flavor text to the print output and generates new information about the accumulated percentage of the data being displayed.&lt;/p&gt;
&lt;div id=&#34;custom-count_values&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Custom count_values()&lt;/h4&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;def pretty_value_counts(data_frame,
                        number_of_rows = 5,
                        cum_perc = True):
  
  for col in data_frame:
    counts = data_frame[col].value_counts(dropna=False)
    percentages = data_frame[col].value_counts(dropna=False, normalize=True)
    
    if cum_perc == True:
      cum_percentages = percentages.cumsum()
      tb = pd.concat([counts,
                      percentages,
                      cum_percentages],
                     axis=1,
                     keys=[&amp;#39;counts&amp;#39;,
                           &amp;#39;percentages&amp;#39;,
                           &amp;quot;cum_percentages&amp;quot;]
                    ).head(number_of_rows)
      
    else:
      tb = pd.concat([counts,
                      percentages],
                     axis=1,
                     keys=[&amp;#39;counts&amp;#39;,
                           &amp;#39;percentages&amp;#39;]).head(number_of_rows)
      
    print(&amp;quot;Column %s with %s data type&amp;quot; % (col,data_frame[col].dtype),
          &amp;quot;\n&amp;quot;,
          tb,
          &amp;quot;\n&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can apply our new function.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;python_custom_function_1&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Using a custom function&lt;/h4&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;pretty_value_counts(df)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Column Unnamed: 0 with int64 data type 
##         counts  percentages  cum_percentages
## 2047        1     0.000015         0.000015
## 41601       1     0.000015         0.000030
## 21151       1     0.000015         0.000045
## 23198       1     0.000015         0.000060
## 17053       1     0.000015         0.000075 
## 
## Column id with float64 data type 
##                counts  percentages  cum_percentages
## 1.100351e+10       2     0.000030         0.000030
## 3.132701e+10       1     0.000015         0.000045
## 1.501501e+10       1     0.000015         0.000060
## 3.230631e+10       1     0.000015         0.000075
## 5.003991e+10       1     0.000015         0.000090 
## 
## Column idade with int64 data type 
##      counts  percentages  cum_percentages
## 20    2104     0.031653         0.031653
## 28    2056     0.030931         0.062585
## 26    2040     0.030691         0.093275
## 22    2034     0.030600         0.123875
## 27    2017     0.030345         0.154220 
## 
## Column sexo with object data type 
##            counts  percentages  cum_percentages
## mulher     33607     0.505597         0.505597
## homem      32791     0.493320         0.998917
## gestante      72     0.001083         1.000000 
## 
## Column anos_estudo with float64 data type 
##        counts  percentages  cum_percentages
## 5.0    23349     0.351271         0.351271
## 11.0   16790     0.252595         0.603866
## 15.0    5636     0.084790         0.688657
## 8.0     5017     0.075478         0.764134
## 10.0    2704     0.040680         0.804814 
## 
## Column cor/raca with object data type 
##            counts  percentages  cum_percentages
## Branca     31689     0.476741         0.476741
## Parda      28370     0.426809         0.903550
## Preta       5249     0.078968         0.982518
## Indigena     597     0.008981         0.991500
## Amarela      323     0.004859         0.996359 
## 
## Column salario with float64 data type 
##             counts  percentages  cum_percentages
##  NaN        18592     0.279705         0.279705
##  0.0         1841     0.027697         0.307402
## -1.0         1101     0.016564         0.323966
##  999999.0     367     0.005521         0.329487
##  5229.0       277     0.004167         0.333654 
## 
## Column estado_civil with float64 data type 
##       counts  percentages  cum_percentages
## 1.0   39066     0.587724         0.587724
## 0.0   27404     0.412276         1.000000 
## 
## Column regiao with object data type 
##                counts  percentages  cum_percentages
## sudeste        25220     0.379419         0.379419
## centro-oeste   14702     0.221182         0.600602
## norte          14653     0.220445         0.821047
## sul            11890     0.178878         0.999925
## nordeste           5     0.000075         1.000000&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Just for comparison lets look how we could do the same thing without the function.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;
for col in df:
  df[col].value_counts(dropna=False).head(5)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 2047     1
## 41601    1
## 21151    1
## 23198    1
## 17053    1
## Name: Unnamed: 0, dtype: int64
## 1.100351e+10    2
## 3.132701e+10    1
## 1.501501e+10    1
## 3.230631e+10    1
## 5.003991e+10    1
## Name: id, dtype: int64
## 20    2104
## 28    2056
## 26    2040
## 22    2034
## 27    2017
## Name: idade, dtype: int64
## mulher      33607
## homem       32791
## gestante       72
## Name: sexo, dtype: int64
## 5.0     23349
## 11.0    16790
## 15.0     5636
## 8.0      5017
## 10.0     2704
## Name: anos_estudo, dtype: int64
## Branca      31689
## Parda       28370
## Preta        5249
## Indigena      597
## Amarela       323
## Name: cor/raca, dtype: int64
##  NaN         18592
##  0.0          1841
## -1.0          1101
##  999999.0      367
##  5229.0        277
## Name: salario, dtype: int64
## 1.0    39066
## 0.0    27404
## Name: estado_civil, dtype: int64
## sudeste         25220
## centro-oeste    14702
## norte           14653
## sul             11890
## nordeste            5
## Name: regiao, dtype: int64&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;replacing-columns-names&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Replacing columns names&lt;/h3&gt;
&lt;p&gt;The columns are named in Portuguese we can replace their names for English equivalents in a lot of different ways&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.columns&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Index([&amp;#39;Unnamed: 0&amp;#39;, &amp;#39;id&amp;#39;, &amp;#39;idade&amp;#39;, &amp;#39;sexo&amp;#39;, &amp;#39;anos_estudo&amp;#39;, &amp;#39;cor/raca&amp;#39;,
##        &amp;#39;salario&amp;#39;, &amp;#39;estado_civil&amp;#39;, &amp;#39;regiao&amp;#39;],
##       dtype=&amp;#39;object&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;My favorite way of doing this sort of trades is using a dictionary defined outside the replace method, the cool thing about replace is that if we liked some of the column names previously defined we can simply omit them, for example, both “Unnamed: 0” and “id” are useless but since their names are already in English I don’t need to mess with them right now&lt;/p&gt;
&lt;details&gt;
&lt;summary&gt;Translation discussion on race&lt;/summary&gt;
&lt;p&gt;
&lt;p&gt;There is some valid discussion on whether to translate “cor/raca” into ethnic_group or color_race, but I am personally on the opinion that the ones making this data frame in 1970 were probably under other standards of naming conventions and racism accusations so I will keep their naming scheme, I apologize if anyone feels offended by the use of these terms&lt;/p&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;dict_cols = {&amp;quot;idade&amp;quot; : &amp;quot;age&amp;quot;,
                &amp;quot;sexo&amp;quot; : &amp;quot;sex&amp;quot;,
                &amp;quot;anos_estudo&amp;quot; : &amp;quot;years_study&amp;quot;,
                &amp;quot;cor/raca&amp;quot; : &amp;quot;color_race&amp;quot;,
                &amp;quot;salario&amp;quot; : &amp;quot;salary&amp;quot;,
                &amp;quot;estado_civil&amp;quot; : &amp;quot;civil_status&amp;quot;,
                &amp;quot;regiao&amp;quot; : &amp;quot;region&amp;quot;
                }&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.rename(columns = dict_cols, inplace = True)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see what changed&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.columns&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Index([&amp;#39;Unnamed: 0&amp;#39;, &amp;#39;id&amp;#39;, &amp;#39;age&amp;#39;, &amp;#39;sex&amp;#39;, &amp;#39;years_study&amp;#39;, &amp;#39;color_race&amp;#39;, &amp;#39;salary&amp;#39;,
##        &amp;#39;civil_status&amp;#39;, &amp;#39;region&amp;#39;],
##       dtype=&amp;#39;object&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It look fine now we can translate some of our main features&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cleaning-categorical-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Cleaning categorical data&lt;/h3&gt;
&lt;p&gt;First we need to know the categories present in each of our columns a simple loop would fails us when we reached a numeric variable, the simplest way to solve that would be using an if statement, another alternative is using conditional execution, I personally don’t know a simple way of doing that in python but I will show it in the R post&lt;/p&gt;
&lt;p&gt;To discover the numeric and “categorical” variables, know that sometimes you will have to change some elements of these lists but looking at my outputs I think I got all the relevant ones&lt;/p&gt;
&lt;div id=&#34;finding-which-columns-are-categorical&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Finding which columns are categorical&lt;/h4&gt;
&lt;p&gt;These are the numerical variables&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.select_dtypes(include=[np.number]).columns&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Index([&amp;#39;Unnamed: 0&amp;#39;, &amp;#39;id&amp;#39;, &amp;#39;age&amp;#39;, &amp;#39;years_study&amp;#39;, &amp;#39;salary&amp;#39;, &amp;#39;civil_status&amp;#39;], dtype=&amp;#39;object&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And these are the Categorical variables&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;list_cat = df.select_dtypes(exclude=[np.number]).columns&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now we can run a simple loop&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;for col in list_cat:
    df[col].unique()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## array([&amp;#39;homem&amp;#39;, &amp;#39;mulher&amp;#39;, &amp;#39;gestante&amp;#39;], dtype=object)
## array([&amp;#39;Parda&amp;#39;, &amp;#39;Amarela&amp;#39;, &amp;#39;Indigena&amp;#39;, &amp;#39;Branca&amp;#39;, &amp;#39;Preta&amp;#39;, nan],
##       dtype=object)
## array([&amp;#39;norte&amp;#39;, &amp;#39;nordeste&amp;#39;, &amp;#39;sudeste&amp;#39;, &amp;#39;sul&amp;#39;, &amp;#39;centro-oeste&amp;#39;],
##       dtype=object)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The simpler method is comparing the dtype in each column to the desired output, but this would be harder if we needed the np.numeric&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;for col in df:
  if df[col].dtype == &amp;quot;O&amp;quot;:
    df[col].unique()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## array([&amp;#39;homem&amp;#39;, &amp;#39;mulher&amp;#39;, &amp;#39;gestante&amp;#39;], dtype=object)
## array([&amp;#39;Parda&amp;#39;, &amp;#39;Amarela&amp;#39;, &amp;#39;Indigena&amp;#39;, &amp;#39;Branca&amp;#39;, &amp;#39;Preta&amp;#39;, nan],
##       dtype=object)
## array([&amp;#39;norte&amp;#39;, &amp;#39;nordeste&amp;#39;, &amp;#39;sudeste&amp;#39;, &amp;#39;sul&amp;#39;, &amp;#39;centro-oeste&amp;#39;],
##       dtype=object)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The problem with the simpler approach is that sometimes you have columns that are categories and not objects so the simpler approach would fail when the more complex one would not, let’s convert sex to a category to prove my point&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.sex =df.sex.astype(&amp;quot;category&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.dtypes&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Unnamed: 0         int64
## id               float64
## age                int64
## sex             category
## years_study      float64
## color_race        object
## salary           float64
## civil_status     float64
## region            object
## dtype: object&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;for col in df:
  if df[col].dtype == &amp;quot;O&amp;quot;:
    df[col].unique()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## array([&amp;#39;Parda&amp;#39;, &amp;#39;Amarela&amp;#39;, &amp;#39;Indigena&amp;#39;, &amp;#39;Branca&amp;#39;, &amp;#39;Preta&amp;#39;, nan],
##       dtype=object)
## array([&amp;#39;norte&amp;#39;, &amp;#39;nordeste&amp;#39;, &amp;#39;sudeste&amp;#39;, &amp;#39;sul&amp;#39;, &amp;#39;centro-oeste&amp;#39;],
##       dtype=object)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It does not work anymore, of course you can still solve this “problem” with the simpler approach by including a “and” clause on your if statement but at that point you might as well use the more extensible appoach&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;replacing-values-with-an-dictionary-1-column&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Replacing values with an dictionary: 1 column&lt;/h4&gt;
&lt;p&gt;After looking into the categories I can create a dictionary for each column if I want to be safe on repeating terms or I can pass a master dictionary for the whole data frame, I think the column by column approach is tidier but for each their own&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;dict_sex = {&amp;quot;mulher&amp;quot;   : &amp;quot;woman&amp;quot;,
            &amp;quot;homem&amp;quot;    : &amp;quot;man&amp;quot;,
            &amp;quot;gestante&amp;quot; : &amp;quot;woman&amp;quot;} # pregnant&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is one strange data frame, it probably made sense to split women into pregnant and not pregnant but I think it will only complicate the otherwise simple analyses so I will group both into “woman”&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.sex.replace(dict_sex,inplace = True)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Showing the new amounts of women/mean&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.sex.value_counts()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## woman    33679
## man      32791
## Name: sex, dtype: int64&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.sex.unique()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## array([&amp;#39;man&amp;#39;, &amp;#39;woman&amp;#39;], dtype=object)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This fails&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;pretty_value_counts(df.sex)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Error in py_call_impl(callable, dots$args, dots$keywords): KeyError: &amp;#39;man&amp;#39;
## 
## Detailed traceback: 
##   File &amp;quot;&amp;lt;string&amp;gt;&amp;quot;, line 1, in &amp;lt;module&amp;gt;
##   File &amp;quot;&amp;lt;string&amp;gt;&amp;quot;, line 6, in pretty_value_counts
##   File &amp;quot;/home/bruno-carlin/Documents/GIthub/TwoSidesData2/.venv/lib/python3.7/site-packages/pandas/core/series.py&amp;quot;, line 1071, in __getitem__
##     result = self.index.get_value(self, key)
##   File &amp;quot;/home/bruno-carlin/Documents/GIthub/TwoSidesData2/.venv/lib/python3.7/site-packages/pandas/core/indexes/base.py&amp;quot;, line 4730, in get_value
##     return self._engine.get_value(s, k, tz=getattr(series.dtype, &amp;quot;tz&amp;quot;, None))
##   File &amp;quot;pandas/_libs/index.pyx&amp;quot;, line 80, in pandas._libs.index.IndexEngine.get_value
##   File &amp;quot;pandas/_libs/index.pyx&amp;quot;, line 88, in pandas._libs.index.IndexEngine.get_value
##   File &amp;quot;pandas/_libs/index.pyx&amp;quot;, line 128, in pandas._libs.index.IndexEngine.get_loc
##   File &amp;quot;pandas/_libs/index_class_helper.pxi&amp;quot;, line 91, in pandas._libs.index.Int64Engine._check_type&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here is actually a example on why I don’t personally enjoy Pandas conversion of data, the function that we created pretty_value_counts is not gonna work in this example because Pandas converts a single column to an Series object, so we would have to write a pretty_value_counts for Series as well or we would have to mess with the Pandas method or we could convert the series back into a DataFrame like this&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;pretty_value_counts(pd.DataFrame(data=  df.sex))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Column sex with object data type 
##         counts  percentages  cum_percentages
## woman   33679      0.50668          0.50668
## man     32791      0.49332          1.00000&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;replacing-values-with-an-dictionary-multiple-columns&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Replacing values with an dictionary: multiple columns&lt;/h4&gt;
&lt;details&gt;
&lt;summary&gt;Translation discussion on race part 2&lt;/summary&gt;
&lt;p&gt;
&lt;p&gt;Again there is relevant discussion on whether I should translate “Parda” as brown but basically Brazil’s population sometimes answers that their skin color is “Parda” = brown when asked about for many reasons I will propose two, “Preta” black can be used as an racist term so some people prefer to be called “brown”, the second explanation is that most of the population is actually pretty well integrated meaning that there a lot of biracial couples in this case we see something like “Preta” parent + “Branca” parent = “Parda” = in English “brown”.&lt;/p&gt;
&lt;p&gt;There is also the case for the English equivalent of brown skin we simply use “Indiano” = “Indian”.&lt;/p&gt;
&lt;p&gt;Curiously the term “Negra” =~ &amp;quot;N*gger&amp;quot; is often preferred in Brazil, that may cause some confusion between Portuguese and English speakers.&lt;/p&gt;
&lt;p&gt;I will use brown but do notice that there were multiple sensible approaches here.&lt;/p&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;p&gt;This is a good opportunity to show failures in the master dictionary approach, realize that if I were to replace “nan” as no_answer or something like that python could thrown me an error because there are “nan” in some numerical columns such as salary but instead I get silence conversion of a numerical columns into object columns a dangerous feature.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;for col in list_cat:
  df[col].unique()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## array([&amp;#39;man&amp;#39;, &amp;#39;woman&amp;#39;], dtype=object)
## array([&amp;#39;Parda&amp;#39;, &amp;#39;Amarela&amp;#39;, &amp;#39;Indigena&amp;#39;, &amp;#39;Branca&amp;#39;, &amp;#39;Preta&amp;#39;, nan],
##       dtype=object)
## array([&amp;#39;norte&amp;#39;, &amp;#39;nordeste&amp;#39;, &amp;#39;sudeste&amp;#39;, &amp;#39;sul&amp;#39;, &amp;#39;centro-oeste&amp;#39;],
##       dtype=object)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;dict_all = {&amp;quot;Parda&amp;quot;    : &amp;quot;brown&amp;quot;,
            &amp;quot;Amarela&amp;quot;  : &amp;quot;yellow&amp;quot;,
            &amp;quot;Indigena&amp;quot; : &amp;quot;indigenous&amp;quot;,
            &amp;quot;Branca&amp;quot;   : &amp;quot;white&amp;quot;,
            &amp;quot;Preta&amp;quot;    : &amp;quot;black&amp;quot;,
            np.nan      : &amp;quot;no_answer&amp;quot;}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.replace(dict_all).salary.dtype&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## dtype(&amp;#39;O&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;dict_all = {&amp;quot;Parda&amp;quot;    : &amp;quot;brown&amp;quot;, #col color_race
            &amp;quot;Amarela&amp;quot;  : &amp;quot;yellow&amp;quot;,
            &amp;quot;Indigena&amp;quot; : &amp;quot;indigenous&amp;quot;,
            &amp;quot;Branca&amp;quot;   : &amp;quot;white&amp;quot;,
            &amp;quot;Preta&amp;quot;    : &amp;quot;black&amp;quot;,
            &amp;quot;norte&amp;quot;    : &amp;quot;north&amp;quot;, # col region 
            &amp;quot;nordeste&amp;quot; : &amp;quot;northeast&amp;quot;,
            &amp;quot;sudeste&amp;quot;  : &amp;quot;southeast&amp;quot;,
            &amp;quot;sul&amp;quot;      : &amp;quot;south&amp;quot;,
        &amp;quot;centro-oeste&amp;quot; : &amp;quot;midwest&amp;quot;}&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s pray that we don’t have this problem and use this shared dictionary&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.replace(dict_all, inplace = True)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;did-we-correctly-clean-the-categorical-variables&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Did we correctly clean the Categorical Variables?&lt;/h4&gt;
&lt;div id=&#34;conversion-of-types&#34; class=&#34;section level5&#34;&gt;
&lt;h5&gt;Conversion of types&lt;/h5&gt;
&lt;p&gt;Well not really I would argue that year_study is an categorical variable as well
so let’s convert it.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.years_study = df.years_study.astype(&amp;#39;category&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.years_study.unique()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [5.0, 8.0, 11.0, 15.0, 13.0, ..., 9.0, 10.0, 14.0, 12.0, NaN]
## Length: 12
## Categories (11, float64): [5.0, 8.0, 11.0, 15.0, ..., 9.0, 10.0, 14.0, 12.0]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Some nan but otherwise this is could be a useful feature, I will convert it back into a numerical column so that if we can easily impute the NaN’s based on a mathematical method such as the mean of the column.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.years_study = df.years_study.astype(&amp;#39;interger&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Error in py_call_impl(callable, dots$args, dots$keywords): TypeError: data type &amp;#39;interger&amp;#39; not understood
## 
## Detailed traceback: 
##   File &amp;quot;&amp;lt;string&amp;gt;&amp;quot;, line 1, in &amp;lt;module&amp;gt;
##   File &amp;quot;/home/bruno-carlin/Documents/GIthub/TwoSidesData2/.venv/lib/python3.7/site-packages/pandas/core/generic.py&amp;quot;, line 5882, in astype
##     dtype=dtype, copy=copy, errors=errors, **kwargs
##   File &amp;quot;/home/bruno-carlin/Documents/GIthub/TwoSidesData2/.venv/lib/python3.7/site-packages/pandas/core/internals/managers.py&amp;quot;, line 581, in astype
##     return self.apply(&amp;quot;astype&amp;quot;, dtype=dtype, **kwargs)
##   File &amp;quot;/home/bruno-carlin/Documents/GIthub/TwoSidesData2/.venv/lib/python3.7/site-packages/pandas/core/internals/managers.py&amp;quot;, line 438, in apply
##     applied = getattr(b, f)(**kwargs)
##   File &amp;quot;/home/bruno-carlin/Documents/GIthub/TwoSidesData2/.venv/lib/python3.7/site-packages/pandas/core/internals/blocks.py&amp;quot;, line 559, in astype
##     return self._astype(dtype, copy=copy, errors=errors, values=values, **kwargs)
##   File &amp;quot;/home/bruno-carlin/Documents/GIthub/TwoSidesData2/.venv/lib/python3.7/site-packages/pandas/core/internals/blocks.py&amp;quot;, line 614, in _astype
##     dtype = pandas_dtype(dtype)
##   File &amp;quot;/home/bruno-carlin/Documents/GIthub/TwoSidesData2/.venv/lib/python3.7/site-packages/pandas/core/dtypes/common.py&amp;quot;, line 2055, in pandas_dtype
##     raise TypeError(&amp;quot;data type &amp;#39;{}&amp;#39; not understood&amp;quot;.format(dtype))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another numpy quirk you can’t use integers because there are NaN values.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.years_study = df.years_study.astype(&amp;#39;float&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Converting civil_status into a category.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.civil_status.unique()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## array([1., 0.])&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To know what 1 or 0 mean, so we need to check the dictionary&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;dict_civil_status = { 0. : &amp;quot;not_married&amp;quot;,
                      1. : &amp;quot;married&amp;quot;}&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.civil_status = df.civil_status.replace(dict_civil_status)
df.civil_status.head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 0        married
## 1        married
## 2    not_married
## 3        married
## 4        married
## Name: civil_status, dtype: object&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Before we deal with numerical variables I will get rid of ‘Unnamed: 0’ and ‘id’ features because they are useless in this case.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.drop(columns=[&amp;#39;Unnamed: 0&amp;#39;, &amp;#39;id&amp;#39;],inplace=True)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;python_plots_categorical&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Seeing the effects of categorical Variables&lt;/h3&gt;
&lt;p&gt;We can use a colored barplot to see the interaction of these Categorical Variables with our Hypothesis.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sns_plot = sns.catplot(x=&amp;quot;sex&amp;quot;, y=&amp;quot;salary&amp;quot;, hue=&amp;quot;region&amp;quot;, kind=&amp;quot;bar&amp;quot;, data=df)
plt.show(sns_plot)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020/01/19/index_files/figure-html/unnamed-chunk-32-1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sns_plot = sns.catplot(x=&amp;quot;sex&amp;quot;, y=&amp;quot;salary&amp;quot;, hue=&amp;quot;civil_status&amp;quot;, kind=&amp;quot;bar&amp;quot;, data=df)
plt.show(sns_plot)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020/01/19/index_files/figure-html/unnamed-chunk-33-1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sns_plot = sns.catplot(x=&amp;quot;sex&amp;quot;, y=&amp;quot;salary&amp;quot;, hue=&amp;quot;color_race&amp;quot;, kind=&amp;quot;bar&amp;quot;, data=df)
plt.show(sns_plot)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020/01/19/index_files/figure-html/unnamed-chunk-34-1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;cleaning-numerical-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;Cleaning numerical data&lt;/h3&gt;
&lt;p&gt;If we pull back the code that we used here are the numerical features of this dataset&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.select_dtypes(include=[np.number]).columns&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Index([&amp;#39;age&amp;#39;, &amp;#39;years_study&amp;#39;, &amp;#39;salary&amp;#39;], dtype=&amp;#39;object&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It is very common to reuse these kind of codes in Data Science scripts, so you shouldn’t fell as bad about repeating yourself as you do in other endeavors such in normal software engendering and you call always clean your analysis latter.&lt;/p&gt;
&lt;p&gt;In order to know what to “clean” in numerical data I like to use plot such as a histogram&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.salary.hist(bins = 10)
plt.show()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020/01/19/index_files/figure-html/unnamed-chunk-36-1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Here we can see that the data may have a few outliers at 1000000 and that most of the salary data has a large Positive skew meaning that most data point are left to the mean of the dataset we can see that better using an density plot instead&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plot_density = df.salary.plot.kde()
plot_density.set_xlim(0,100000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## (0, 100000)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plot_density&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020/01/19/index_files/figure-html/unnamed-chunk-37-1.png&#34; /&gt;&lt;!-- --&gt;
#### Replacing variables {#python_custom_function_2}&lt;/p&gt;
&lt;p&gt;If we go back to our &lt;a href=&#34;#python_custom_function_1&#34;&gt;custom function&lt;/a&gt; we can find that the values -1 and 999999 are unusually common after consulting the dictionary we decided to replace these values with the mean of the group.&lt;/p&gt;
&lt;p&gt;This operation would be wrong for machine learning purposes since the mean of our train group would leak information from the test set as well but here in exploratory data analysis it is mostly fine also you need to replace the values with the numpy nan or else this operation doesn’t work as expected.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df_copy = df.copy()
df_copy.salary.replace({-1: &amp;quot;NaN&amp;quot;,999999:&amp;#39;NaN&amp;#39;},inplace = True)
df_copy.salary.fillna(df.salary.mean(),inplace= True)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;pretty_value_counts(pd.DataFrame(df_copy.salary))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Column salary with object data type 
##                      counts  percentages  cum_percentages
## 19706.790323432902   18592     0.279705         0.279705
## 0.0                   1841     0.027697         0.307402
## NaN                   1468     0.022085         0.329487
## 5229.0                 277     0.004167         0.333654
## 7200.0                 260     0.003912         0.337566&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;# Create the new na values



df.salary.replace({-1:np.nan,999999:np.nan},inplace = True)

df.salary.fillna(df.salary.mean(),inplace= True)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;pretty_value_counts(pd.DataFrame(df.salary))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Column salary with float64 data type 
##               counts  percentages  cum_percentages
## 12422.39119   20060     0.301790         0.301790
## 0.00000        1841     0.027697         0.329487
## 5229.00000      277     0.004167         0.333654
## 7200.00000      260     0.003912         0.337566
## 7560.00000      244     0.003671         0.341237&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And that is the magic of mutable Data Structures no extra assignments are required, quite useful, but be careful there is no going back if you haven’t saved a copy of your data.&lt;/p&gt;
&lt;div id=&#34;log-of-numerical-data&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Log of numerical data&lt;/h4&gt;
&lt;p&gt;There is also a statisticall solution for the Positive skew in our Data we can take the log of the salary column, but we will have to add one to all values since log of 0 goes to -Inf&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.log_salary = np.log1p(df.salary)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## /home/bruno-carlin/Documents/GIthub/TwoSidesData2/.venv/bin/activate_this.py:1: UserWarning: Pandas doesn&amp;#39;t allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access
##   &amp;quot;&amp;quot;&amp;quot;Activate virtualenv for current interpreter:&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But be carefull you can’t assign in pandas using the . you need to use the “[” operator&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.log_salary&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 0        11.060384
## 1         9.427336
## 2         8.378713
## 3        11.478344
## 4        11.969090
##            ...    
## 66465     9.427336
## 66466     7.793999
## 66467     7.793999
## 66468     8.617075
## 66469     6.134157
## Name: salary, Length: 66470, dtype: float64&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.info()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;
## RangeIndex: 66470 entries, 0 to 66469
## Data columns (total 7 columns):
## age             66470 non-null int64
## sex             66470 non-null object
## years_study     66036 non-null float64
## color_race      66228 non-null object
## salary          66470 non-null float64
## civil_status    66470 non-null object
## region          66470 non-null object
## dtypes: float64(2), int64(1), object(4)
## memory usage: 3.6+ MB&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It simply is gone&lt;/p&gt;
&lt;p&gt;The right way&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df[&amp;#39;log_salary&amp;#39;] = np.log1p(df.salary)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;pretty_value_counts(pd.DataFrame(df.log_salary))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Column salary with float64 data type 
##            counts  percentages  cum_percentages
## 9.427336   20060     0.301790         0.301790
## 0.000000    1841     0.027697         0.329487
## 8.562167     277     0.004167         0.333654
## 8.881975     260     0.003912         0.337566
## 8.930759     244     0.003671         0.341237&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plot_density = df.log_salary.plot.kde(bw_method= 0.5)
plot_density.set_xlim(0,15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## (0, 15)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plot_density&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020/01/19/index_files/figure-html/unnamed-chunk-47-1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;It is now a usefull feature for most simple linear models&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;other-numerical-columns&#34; class=&#34;section level4&#34;&gt;
&lt;h4&gt;Other numerical columns&lt;/h4&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.age.hist(bins = 20)
plt.show()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020/01/19/index_files/figure-html/unnamed-chunk-48-1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;plot_density = df.age.plot.kde()
plot_density&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020/01/19/index_files/figure-html/unnamed-chunk-49-1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;pretty_value_counts(pd.DataFrame(df.age))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Column age with int64 data type 
##      counts  percentages  cum_percentages
## 20    2104     0.031653         0.031653
## 28    2056     0.030931         0.062585
## 26    2040     0.030691         0.093275
## 22    2034     0.030600         0.123875
## 27    2017     0.030345         0.154220&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Age seems fine&lt;/p&gt;
&lt;p&gt;Remember from the the categorical variables we passed years_study here so that we could impute its missing values&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.info()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;
## RangeIndex: 66470 entries, 0 to 66469
## Data columns (total 8 columns):
## age             66470 non-null int64
## sex             66470 non-null object
## years_study     66036 non-null float64
## color_race      66228 non-null object
## salary          66470 non-null float64
## civil_status    66470 non-null object
## region          66470 non-null object
## log_salary      66470 non-null float64
## dtypes: float64(3), int64(1), object(4)
## memory usage: 4.1+ MB&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We are missing 66470 - 66036 = 434 observation, this is a small enough number that we decided to drop these rows&lt;/p&gt;
&lt;p&gt;While we are droping missing values lets drop the color_race missing observations as well&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.dropna(subset = [&amp;quot;years_study&amp;quot;,&amp;quot;color_race&amp;quot;],inplace= True)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.info()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;
## Int64Index: 65795 entries, 0 to 66469
## Data columns (total 8 columns):
## age             65795 non-null int64
## sex             65795 non-null object
## years_study     65795 non-null float64
## color_race      65795 non-null object
## salary          65795 non-null float64
## civil_status    65795 non-null object
## region          65795 non-null object
## log_salary      65795 non-null float64
## dtypes: float64(3), int64(1), object(4)
## memory usage: 4.5+ MB&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Checking on year_study&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.years_study.hist(bins = 20)
plt.show()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2020/01/19/index_files/figure-html/unnamed-chunk-54-1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
&lt;p&gt;Let’s convert it back into a Category&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.years_study = df.years_study.astype(&amp;#39;category&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;saving-our-work-for-later&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Saving our work for later&lt;/h1&gt;
&lt;p&gt;Here we have many options we can for example run this script later or save this modified df as a csv, both options are okay but I will promote the usage of an Data format that keeps the mindful choices of encoding that we made into consideration, there are many alternatives in this case as well but I will use feather.&lt;/p&gt;
&lt;p&gt;It is also always a good idea to separate the Data from the script if you want reproducible work, that is where Excel mostly fails for me.&lt;/p&gt;
&lt;p&gt;So showing our Data Types&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.dtypes&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## age                int64
## sex               object
## years_study     category
## color_race        object
## salary           float64
## civil_status      object
## region            object
## log_salary       float64
## dtype: object&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using csv will may lose some Data Types&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.to_csv(r.file_path_linux + &amp;#39;/finished_work.csv&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;pd.read_csv(r.file_path_linux + &amp;#39;/finished_work.csv&amp;#39;).dtypes&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Unnamed: 0        int64
## age               int64
## sex              object
## years_study     float64
## color_race       object
## salary          float64
## civil_status     object
## region           object
## log_salary      float64
## dtype: object&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We lost our encoding of years_study and when writing a csv we made this useless to us Unnamed: 0 column&lt;/p&gt;
&lt;p&gt;a better way is using the feather file format, you need to pip install pyarrow beforehand&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;r.file_path_linux&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;/home/bruno-carlin/Documents/GIthub/TwoSidesData2/content/post/data&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;df.reset_index().to_feather(r.file_path_linux + &amp;#39;/sex_thesis_assignment.feather&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;file_path_linux&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;/home/bruno-carlin/Documents/GIthub/TwoSidesData2/content/post/data&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;pd.read_feather(r.file_path_linux + &amp;#39;/sex_thesis_assignment.feather&amp;#39;).dtypes&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## index              int64
## age                int64
## sex               object
## years_study     category
## color_race        object
## salary           float64
## civil_status      object
## region            object
## log_salary       float64
## dtype: object&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Feather does keep the years study dtype, but feather is still in a experimental phase so be carefull with it, parquet unfortunally fails to keep the dtypes I don’t know why.&lt;/p&gt;
&lt;p&gt;It is also a good idea to keep good file names so that you can easily identify your datasets and scripts.&lt;/p&gt;
&lt;p&gt;If you then need to delete these files you can do it inside python&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;os.remove(r.file_path_linux + &amp;#39;/finished_work.csv&amp;#39;)
#os.remove(r.file_path_linux + &amp;#39;/sex_thesis_assignment.feather&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;next-post&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Next post&lt;/h1&gt;
&lt;p&gt;In the next post I will show the end of the analysis and the “answer” to our hypothesis.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>exploratory data analysis: basic statistical inference</title>
      <link>/2019/04/05/exploratory-data-analysis-basic-statistical-inference/</link>
      <pubDate>Fri, 05 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/04/05/exploratory-data-analysis-basic-statistical-inference/</guid>
      <description>



</description>
    </item>
    
    <item>
      <title>exploratory data analysis: basic pandas and dplyr</title>
      <link>/2019/03/23/exploratory-data-analysis-basic-pandas-and-dplyr/</link>
      <pubDate>Sat, 23 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/2019/03/23/exploratory-data-analysis-basic-pandas-and-dplyr/</guid>
      <description>
This is an basic example of how you can use either R or Python to accomplish the same goals, I really enjoy using the tidyverse but as you will see sometimes Python is just the more intuitive option. If you find yourself confused on whether a code chunk is an R or Python code please ask me or check my github page for this project. &lt;br&gt; &lt;br&gt;

&lt;div id=&#34;TOC&#34;&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#getting-started-we-will-use-multiple-functions-from-both-languages&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;1&lt;/span&gt; Getting Started, we will use multiple functions from both languages&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#how-to-set-up-reticulate&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;1.1&lt;/span&gt; How to set up reticulate?&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#setting-root-folder&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;1.1.1&lt;/span&gt; Setting root folder&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#anchor&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;1.1.2&lt;/span&gt; Libraries&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#python&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2&lt;/span&gt; Python&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#knowing-data-frames&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.1&lt;/span&gt; Knowing data frames&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#defining-pandas-series&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.1.1&lt;/span&gt; Defining pandas series&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#indexing&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.1.2&lt;/span&gt; Indexing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#combining-two-pd-series&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.2&lt;/span&gt; Combining two pd series&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#create-pd-series-from-dictionary-1&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.2.1&lt;/span&gt; Create pd series from dictionary 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#combining-the-pd-series-into-a-data-frame&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.2.2&lt;/span&gt; Combining the pd series into a data frame&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#data-frame-properties&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.2.3&lt;/span&gt; Data frame properties&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#creating-some-new-columns&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.2.4&lt;/span&gt; Creating some new columns&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ordering-a-data-frame&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.2.5&lt;/span&gt; Ordering a data frame&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#subsetting&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.2.6&lt;/span&gt; Subsetting&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#real-data&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.3&lt;/span&gt; Real data&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#reading-data&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.3.1&lt;/span&gt; Reading data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#py_types_columns&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.3.2&lt;/span&gt; Variable types&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#basic-description&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.3.3&lt;/span&gt; Basic Description&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#subsetting-data&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.3.4&lt;/span&gt; Subsetting data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#creating-new-columns-with-real-data&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.3.5&lt;/span&gt; Creating new columns with real data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#creating-a-new-smaller-data-frame&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.3.6&lt;/span&gt; Creating a new smaller data frame&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#plotting-an-line-plot&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.3.7&lt;/span&gt; Plotting an line plot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#filtering_py&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.3.8&lt;/span&gt; Filtering and replace data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#groupby-example&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.3.9&lt;/span&gt; Groupby example&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ploting-an-histogram&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.3.10&lt;/span&gt; Ploting an histogram&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#missing_values_py&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.3.11&lt;/span&gt; Handling Missing values&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#replacing-names-with-an-dictionary&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.3.12&lt;/span&gt; Replacing names with an dictionary&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#passing-objects&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.4&lt;/span&gt; Passing Objects&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#python-to-r&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;2.4.1&lt;/span&gt; Python to R&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#r&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3&lt;/span&gt; R&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#knowing-data-frames-1&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.1&lt;/span&gt; Knowing data frames&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#defining-an-data-frame&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.1.1&lt;/span&gt; Defining an data frame&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#index-search&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.1.2&lt;/span&gt; Index search&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#creating-an-data-frame-from-two-r-series&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.2&lt;/span&gt; Creating an data frame from two R series&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#create-a-date-frame-using-an-list&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.2.1&lt;/span&gt; Create a date frame using an list&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#create-a-date-frame-using-an-list-2&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.2.2&lt;/span&gt; Create a date frame using an list 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#subsetting-an-data-frame-using-join-or-cbind&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.2.3&lt;/span&gt; Subsetting an data frame using join or cbind&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#some-info-on-our-data-frame&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.2.4&lt;/span&gt; Some info on our data frame&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#creating-new-columns-using-mutate-and-basic-r&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.2.5&lt;/span&gt; Creating new columns using mutate and basic R&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ordering-an-data-frame-using-the-tidy-way-arrange-or-order.&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.2.6&lt;/span&gt; Ordering an data frame using the tidy way arrange or order.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#filtering-rows-using-standard-r-code-or-filter.&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.2.7&lt;/span&gt; Filtering rows using standard R code or filter.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#real-case&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.3&lt;/span&gt; Real Case&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#two-way-of-importing-an-csv&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.3.1&lt;/span&gt; Two way of importing an csv&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#lets-look-at-our-data&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.3.2&lt;/span&gt; Let’s look at our data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#r_types_columns&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.3.3&lt;/span&gt; Types of columns r&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#basic-description-real-data-using-glimpse-and-str&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.3.4&lt;/span&gt; Basic Description real data using Glimpse and str&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#subsetting-data-with-select-or-base-r&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.3.5&lt;/span&gt; Subsetting Data with select or base R&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#creating-a-new-smaller-data-frame-using-transmute-and-base&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.3.6&lt;/span&gt; Creating a new smaller data frame using transmute and base&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ploting-with-ggplot&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.3.7&lt;/span&gt; Ploting with ggplot&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#filtering_r&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.3.8&lt;/span&gt; Filtering and replace data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#groupby-example-in-tidyverse&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.3.9&lt;/span&gt; Groupby example in tidyverse&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#ploting-an-histogram-using-ggplot2&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.3.10&lt;/span&gt; Ploting an histogram using ggplot2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#missing_values_r&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.3.11&lt;/span&gt; Handling Missing values in R&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#replacing-names-with-an-case-when-aproach&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.3.12&lt;/span&gt; Replacing names with an case when aproach&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#passing-objects-to-python&#34;&gt;&lt;span class=&#34;toc-section-number&#34;&gt;3.4&lt;/span&gt; Passing Objects to Python&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;

&lt;p&gt;I am currently doing exercises from &lt;a href=&#34;https://github.com/sn3fru/datascience_course&#34;&gt;digital house brasil&lt;/a&gt;&lt;/p&gt;
&lt;div id=&#34;getting-started-we-will-use-multiple-functions-from-both-languages&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;1&lt;/span&gt; Getting Started, we will use multiple functions from both languages&lt;/h1&gt;
&lt;div id=&#34;how-to-set-up-reticulate&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;1.1&lt;/span&gt; How to set up reticulate?&lt;/h2&gt;
&lt;div id=&#34;setting-root-folder&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;1.1.1&lt;/span&gt; Setting root folder&lt;/h3&gt;
&lt;p&gt;I recommend using the Files tab to find the your system path to the folder containig all the data.&lt;/p&gt;
&lt;p&gt;Use opts_knit to guarantee that your markdown functions will search for files
in the folder specified, it is better that setwd() because it works on
all languages.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;knitr::opts_knit$set(root.dir = normalizePath(
  &amp;quot;~/R/Blog/content/post/data&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;anchor&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;1.1.2&lt;/span&gt; Libraries&lt;/h3&gt;
&lt;img src=&#34;https://media.giphy.com/media/8YZEKuDRHPtgZTx7Rv/giphy.gif&#34; /&gt;
&lt;details&gt;
&lt;summary&gt;R part&lt;/summary&gt;
&lt;p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;library(reticulate)
library(caTools)
library(roperators)
library(tidyverse)
set.seed(123)&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;Python part&lt;/summary&gt;
&lt;p&gt;
&lt;p&gt;I am using my second virtual conda if you have just the root
switch to conda_list()[[1]][1].&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conda_list()[[1]][2] %&amp;gt;% 
  use_condaenv(required = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Let’s see what version of python this env is running.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import platform
print(platform.python_version())&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 3.7.2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Some basic Data Science Libraries.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import os&lt;/code&gt;&lt;/pre&gt;
&lt;/p&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;python&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;2&lt;/span&gt; Python&lt;/h1&gt;
&lt;div id=&#34;knowing-data-frames&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.1&lt;/span&gt; Knowing data frames&lt;/h2&gt;
&lt;div id=&#34;defining-pandas-series&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.1.1&lt;/span&gt; Defining pandas series&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/EPcvhM28ER9XW/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;data = pd.Series([0.25, 0.5, 0.75, 1.0])
data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 0    0.25
## 1    0.50
## 2    0.75
## 3    1.00
## dtype: float64&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;data.values&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## array([0.25, 0.5 , 0.75, 1.  ])&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;data.index&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## RangeIndex(start=0, stop=4, step=1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;data[1]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 0.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;data[1:3]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 1    0.50
## 2    0.75
## dtype: float64&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;indexing&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.1.2&lt;/span&gt; Indexing&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;data = pd.Series([0.25, 0.5, 0.75, 1.0],
                 index=[&amp;#39;a&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;c&amp;#39;, &amp;#39;d&amp;#39;])
data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## a    0.25
## b    0.50
## c    0.75
## d    1.00
## dtype: float64&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;data[&amp;#39;b&amp;#39;]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 0.5&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;combining-two-pd-series&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.2&lt;/span&gt; Combining two pd series&lt;/h2&gt;
&lt;div id=&#34;create-pd-series-from-dictionary-1&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.2.1&lt;/span&gt; Create pd series from dictionary 1&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;population_dict = {&amp;#39;California&amp;#39;: 38332521,
                   &amp;#39;Florida&amp;#39;: 19552860,
                   &amp;#39;Illinois&amp;#39;: 12882135,
                   &amp;#39;New York&amp;#39;: 19651127,  
                   &amp;#39;Texas&amp;#39;: 26448193,}
population = pd.Series(population_dict)

population&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## California    38332521
## Florida       19552860
## Illinois      12882135
## New York      19651127
## Texas         26448193
## dtype: int64&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;population[&amp;#39;California&amp;#39;]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 38332521&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;population[&amp;#39;California&amp;#39;:&amp;#39;Illinois&amp;#39;]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## California    38332521
## Florida       19552860
## Illinois      12882135
## dtype: int64&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;one more example.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;area_dict = {&amp;#39;California&amp;#39;: 423967, 
             &amp;#39;Florida&amp;#39;: 170312,
             &amp;#39;Illinois&amp;#39;: 149995,
             &amp;#39;New York&amp;#39;: 141297,
             &amp;#39;Texas&amp;#39;: 695662}
             
area = pd.Series(area_dict)

area&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## California    423967
## Florida       170312
## Illinois      149995
## New York      141297
## Texas         695662
## dtype: int64&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;combining-the-pd-series-into-a-data-frame&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.2.2&lt;/span&gt; Combining the pd series into a data frame&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;states = pd.DataFrame({&amp;#39;population&amp;#39;: population,
                       &amp;#39;area&amp;#39;: area})
states&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             population    area
## California    38332521  423967
## Florida       19552860  170312
## Illinois      12882135  149995
## New York      19651127  141297
## Texas         26448193  695662&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;type(states)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;type(states[&amp;quot;population&amp;quot;])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;class &amp;#39;pandas.core.series.Series&amp;#39;&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;type([states[&amp;quot;population&amp;quot;]])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;class &amp;#39;list&amp;#39;&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;data-frame-properties&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.2.3&lt;/span&gt; Data frame properties&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;states.shape&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## (5, 2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;states.info()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;
## Index: 5 entries, California to Texas
## Data columns (total 2 columns):
## population    5 non-null int64
## area          5 non-null int64
## dtypes: int64(2)
## memory usage: 280.0+ bytes&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;states.index&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Index([&amp;#39;California&amp;#39;, &amp;#39;Florida&amp;#39;, &amp;#39;Illinois&amp;#39;, &amp;#39;New York&amp;#39;, &amp;#39;Texas&amp;#39;], dtype=&amp;#39;object&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;states.columns&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Index([&amp;#39;population&amp;#39;, &amp;#39;area&amp;#39;], dtype=&amp;#39;object&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;states[&amp;#39;area&amp;#39;]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## California    423967
## Florida       170312
## Illinois      149995
## New York      141297
## Texas         695662
## Name: area, dtype: int64&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-some-new-columns&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.2.4&lt;/span&gt; Creating some new columns&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;states[&amp;#39;density&amp;#39;] = states[&amp;#39;population&amp;#39;] / states[&amp;#39;area&amp;#39;]
states&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             population    area     density
## California    38332521  423967   90.413926
## Florida       19552860  170312  114.806121
## Illinois      12882135  149995   85.883763
## New York      19651127  141297  139.076746
## Texas         26448193  695662   38.018740&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;ordering-a-data-frame&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.2.5&lt;/span&gt; Ordering a data frame&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;states.sort_values([&amp;#39;population&amp;#39;], ascending = True)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             population    area     density
## Illinois      12882135  149995   85.883763
## Florida       19552860  170312  114.806121
## New York      19651127  141297  139.076746
## Texas         26448193  695662   38.018740
## California    38332521  423967   90.413926&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;states.sort_values([&amp;#39;area&amp;#39;], ascending = True)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             population    area     density
## New York      19651127  141297  139.076746
## Illinois      12882135  149995   85.883763
## Florida       19552860  170312  114.806121
## California    38332521  423967   90.413926
## Texas         26448193  695662   38.018740&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;states.sort_values([&amp;#39;density&amp;#39;], ascending = True)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             population    area     density
## Texas         26448193  695662   38.018740
## Illinois      12882135  149995   85.883763
## California    38332521  423967   90.413926
## Florida       19552860  170312  114.806121
## New York      19651127  141297  139.076746&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;subsetting&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.2.6&lt;/span&gt; Subsetting&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;states[&amp;#39;Florida&amp;#39;:&amp;#39;Illinois&amp;#39;]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           population    area     density
## Florida     19552860  170312  114.806121
## Illinois    12882135  149995   85.883763&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;states[1:3]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           population    area     density
## Florida     19552860  170312  114.806121
## Illinois    12882135  149995   85.883763&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;data_pop = (states[&amp;#39;population&amp;#39;] &amp;gt; 19552860) &amp;amp; (states[&amp;#39;area&amp;#39;]&amp;gt;423967)

data_pop&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## California    False
## Florida       False
## Illinois      False
## New York      False
## Texas          True
## dtype: bool&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;states[(states[&amp;#39;population&amp;#39;] &amp;gt; 19552860) &amp;amp; (states[&amp;#39;area&amp;#39;]&amp;gt;423967)]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        population    area   density
## Texas    26448193  695662  38.01874&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;states[[&amp;#39;area&amp;#39;,&amp;#39;density&amp;#39;]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##               area     density
## California  423967   90.413926
## Florida     170312  114.806121
## Illinois    149995   85.883763
## New York    141297  139.076746
## Texas       695662   38.018740&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;states[states.density &amp;gt; 100]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           population    area     density
## Florida     19552860  170312  114.806121
## New York    19651127  141297  139.076746&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;states.loc[states.density &amp;gt; 100, [&amp;#39;population&amp;#39;, &amp;#39;density&amp;#39;]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           population     density
## Florida     19552860  114.806121
## New York    19651127  139.076746&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;states.loc[states.density &amp;gt; 100][[&amp;#39;population&amp;#39;, &amp;#39;density&amp;#39;]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##           population     density
## Florida     19552860  114.806121
## New York    19651127  139.076746&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;states.loc[&amp;#39;California&amp;#39;, &amp;#39;density&amp;#39;]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 90.41392608386974&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;states.loc[&amp;#39;California&amp;#39;][[&amp;#39;density&amp;#39;]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## density    90.413926
## Name: California, dtype: float64&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;states.iloc[0, 2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 90.41392608386974&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;real-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.3&lt;/span&gt; Real data&lt;/h2&gt;
&lt;div id=&#34;reading-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.3.1&lt;/span&gt; Reading data&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales = pd.DataFrame(pd.read_csv(&amp;#39;2019-03-23-exploratory-data-analysis-basic-pandas-and-dplyr/UKretail.csv&amp;#39;,encoding=&amp;#39;latin&amp;#39;))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales.head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   InvoiceNo StockCode  ... CustomerID         Country
## 0    536365     22752  ...    17850.0  United Kingdom
## 1    536365     71053  ...    17850.0  United Kingdom
## 2    536365    84029G  ...    17850.0  United Kingdom
## 3    536365    85123A  ...    17850.0  United Kingdom
## 4    536366     22633  ...    17850.0  United Kingdom
## 
## [5 rows x 8 columns]&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales.tail(3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        InvoiceNo StockCode  ... CustomerID  Country
## 325142    581587     22899  ...    12680.0   France
## 325143    581587     23254  ...    12680.0   France
## 325144    581587     23256  ...    12680.0   France
## 
## [3 rows x 8 columns]&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales.index&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## RangeIndex(start=0, stop=325145, step=1)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;py_types_columns&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.3.2&lt;/span&gt; Variable types&lt;/h3&gt;
&lt;p&gt;If you need to &lt;a href=&#34;#r_types_columns&#34;&gt;return&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;type(sales)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;type(sales[&amp;quot;CustomerID&amp;quot;])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;class &amp;#39;pandas.core.series.Series&amp;#39;&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;type([sales[&amp;quot;CustomerID&amp;quot;]])
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;class &amp;#39;list&amp;#39;&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;basic-description&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.3.3&lt;/span&gt; Basic Description&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales.shape
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## (325145, 8)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales.columns.values
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## array([&amp;#39;InvoiceNo&amp;#39;, &amp;#39;StockCode&amp;#39;, &amp;#39;Description&amp;#39;, &amp;#39;Quantity&amp;#39;, &amp;#39;InvoiceDate&amp;#39;,
##        &amp;#39;UnitPrice&amp;#39;, &amp;#39;CustomerID&amp;#39;, &amp;#39;Country&amp;#39;], dtype=object)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales.info()
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;
## RangeIndex: 325145 entries, 0 to 325144
## Data columns (total 8 columns):
## InvoiceNo      325145 non-null object
## StockCode      325145 non-null object
## Description    324275 non-null object
## Quantity       325145 non-null int64
## InvoiceDate    325145 non-null object
## UnitPrice      325145 non-null float64
## CustomerID     244154 non-null float64
## Country        325145 non-null object
## dtypes: float64(2), int64(1), object(5)
## memory usage: 19.8+ MB&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales.describe()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##             Quantity      UnitPrice     CustomerID
## count  325145.000000  325145.000000  244154.000000
## mean        9.273340       4.845239   15288.823120
## std       154.394112     116.830451    1713.496816
## min    -80995.000000  -11062.060000   12347.000000
## 25%         1.000000       1.250000   13959.000000
## 50%         3.000000       2.080000   15150.000000
## 75%        10.000000       4.130000   16792.750000
## max     12540.000000   38970.000000   18287.000000&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;subsetting-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.3.4&lt;/span&gt; Subsetting data&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales[:4]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   InvoiceNo StockCode  ... CustomerID         Country
## 0    536365     22752  ...    17850.0  United Kingdom
## 1    536365     71053  ...    17850.0  United Kingdom
## 2    536365    84029G  ...    17850.0  United Kingdom
## 3    536365    85123A  ...    17850.0  United Kingdom
## 
## [4 rows x 8 columns]&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales[&amp;quot;CustomerID&amp;quot;].head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 0    17850.0
## 1    17850.0
## 2    17850.0
## 3    17850.0
## 4    17850.0
## Name: CustomerID, dtype: float64&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales.loc[:,[&amp;#39;Quantity&amp;#39;]].head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Quantity
## 0         2
## 1         6
## 2         6
## 3         6
## 4         6&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales.iloc[:,[3]].head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Quantity
## 0         2
## 1         6
## 2         6
## 3         6
## 4         6&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales.iloc[0:6,2:3]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                            Description
## 0         SET 7 BABUSHKA NESTING BOXES
## 1                  WHITE METAL LANTERN
## 2  KNITTED UNION FLAG HOT WATER BOTTLE
## 3   WHITE HANGING HEART T-LIGHT HOLDER
## 4               HAND WARMER UNION JACK
## 5             HOME BUILDING BLOCK WORD&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-new-columns-with-real-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.3.5&lt;/span&gt; Creating new columns with real data&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales[&amp;quot;Revenue&amp;quot;] = sales.Quantity * sales.UnitPrice&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales.head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   InvoiceNo StockCode  ...         Country  Revenue
## 0    536365     22752  ...  United Kingdom    15.30
## 1    536365     71053  ...  United Kingdom    20.34
## 2    536365    84029G  ...  United Kingdom    20.34
## 3    536365    85123A  ...  United Kingdom    15.30
## 4    536366     22633  ...  United Kingdom    11.10
## 
## [5 rows x 9 columns]&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-a-new-smaller-data-frame&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.3.6&lt;/span&gt; Creating a new smaller data frame&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;raw_sales = sales[[&amp;quot;Quantity&amp;quot;,&amp;quot;UnitPrice&amp;quot;, &amp;quot;Revenue&amp;quot;]]

raw_sales.head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    Quantity  UnitPrice  Revenue
## 0         2       7.65    15.30
## 1         6       3.39    20.34
## 2         6       3.39    20.34
## 3         6       2.55    15.30
## 4         6       1.85    11.10&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;raw_sales.info()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;
## RangeIndex: 325145 entries, 0 to 325144
## Data columns (total 3 columns):
## Quantity     325145 non-null int64
## UnitPrice    325145 non-null float64
## Revenue      325145 non-null float64
## dtypes: float64(2), int64(1)
## memory usage: 7.4 MB&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;plotting-an-line-plot&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.3.7&lt;/span&gt; Plotting an line plot&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;import matplotlib as plt
from pylab import *

sales.plot(x=&amp;quot;InvoiceDate&amp;quot;, y=&amp;quot;Revenue&amp;quot;, kind=&amp;quot;line&amp;quot;)

plt.show()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019/2019-03/2019-03-23/1/index_files/figure-html/exploratory_data1-34-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;filtering_py&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.3.8&lt;/span&gt; Filtering and replace data&lt;/h3&gt;
&lt;p&gt;To &lt;a href=&#34;#filtering_r&#34;&gt;return&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;cancels = sales[sales[&amp;quot;Revenue&amp;quot;]&amp;lt;0]
cancels.shape&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## (5588, 9)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales.drop(cancels.index, inplace=True)
sales.shape&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## (319557, 9)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;groupby-example&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.3.9&lt;/span&gt; Groupby example&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;CountryGroups = sales.groupby([&amp;quot;Country&amp;quot;])[&amp;quot;Revenue&amp;quot;].sum().reset_index()
CountryGroups.sort_values(by= &amp;quot;Revenue&amp;quot;, ascending=False)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##                  Country      Revenue
## 36        United Kingdom  5311080.101
## 10                  EIRE   176304.590
## 24           Netherlands   165582.790
## 14               Germany   138778.440
## 13                France   127193.680
## 0              Australia    79197.590
## 31                 Spain    36116.710
## 33           Switzerland    34315.240
## 3                Belgium    24014.970
## 25                Norway    23182.220
## 32                Sweden    21762.450
## 20                 Japan    21072.590
## 27              Portugal    20109.410
## 30             Singapore    13383.590
## 6        Channel Islands    12556.740
## 12               Finland    12362.880
## 9                Denmark    11739.370
## 19                 Italy    10837.890
## 16             Hong Kong     8227.020
## 7                 Cyprus     7781.900
## 1                Austria     6100.960
## 18                Israel     4225.780
## 26                Poland     3974.080
## 37           Unspecified     2898.650
## 15                Greece     2677.570
## 17               Iceland     2461.230
## 34                   USA     2388.740
## 5                 Canada     2093.390
## 23                 Malta     1318.990
## 35  United Arab Emirates     1277.500
## 21               Lebanon     1120.530
## 22             Lithuania     1038.560
## 11    European Community      876.550
## 4                 Brazil      602.310
## 28                   RSA      573.180
## 8         Czech Republic      488.580
## 2                Bahrain      343.400
## 29          Saudi Arabia       90.720&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;ploting-an-histogram&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.3.10&lt;/span&gt; Ploting an histogram&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales[sales[&amp;quot;CustomerID&amp;quot;] == 17850.0][&amp;quot;Revenue&amp;quot;].plot(kind=&amp;quot;hist&amp;quot;)
plt.show()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019/2019-03/2019-03-23/1/index_files/figure-html/exploratory_data1-37-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;another example.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales[sales[&amp;quot;StockCode&amp;quot;] == &amp;#39;71053&amp;#39;][&amp;quot;Quantity&amp;quot;].hist()
plt.show()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019/2019-03/2019-03-23/1/index_files/figure-html/exploratory_data1-38-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;missing_values_py&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.3.11&lt;/span&gt; Handling Missing values&lt;/h3&gt;
&lt;p&gt;to &lt;a href=&#34;#missing_values_r&#34;&gt;return&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales.info()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;
## Int64Index: 319557 entries, 0 to 325144
## Data columns (total 9 columns):
## InvoiceNo      319557 non-null object
## StockCode      319557 non-null object
## Description    318687 non-null object
## Quantity       319557 non-null int64
## InvoiceDate    319557 non-null object
## UnitPrice      319557 non-null float64
## CustomerID     238801 non-null float64
## Country        319557 non-null object
## Revenue        319557 non-null float64
## dtypes: float64(3), int64(1), object(5)
## memory usage: 24.4+ MB&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales.CustomerID.value_counts(dropna=False).nlargest(3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NaN        80756
## 17841.0     4702
## 14911.0     3449
## Name: CustomerID, dtype: int64&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales.CustomerID.fillna(0, inplace=True)

sales[sales.CustomerID.isnull()]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Empty DataFrame
## Columns: [InvoiceNo, StockCode, Description, Quantity, InvoiceDate, UnitPrice, CustomerID, Country, Revenue]
## Index: []&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales.info()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;
## Int64Index: 319557 entries, 0 to 325144
## Data columns (total 9 columns):
## InvoiceNo      319557 non-null object
## StockCode      319557 non-null object
## Description    318687 non-null object
## Quantity       319557 non-null int64
## InvoiceDate    319557 non-null object
## UnitPrice      319557 non-null float64
## CustomerID     319557 non-null float64
## Country        319557 non-null object
## Revenue        319557 non-null float64
## dtypes: float64(3), int64(1), object(5)
## memory usage: 24.4+ MB&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;replacing-names-with-an-dictionary&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.3.12&lt;/span&gt; Replacing names with an dictionary&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;mymap = {&amp;#39;United Kingdom&amp;#39;:1, &amp;#39;Netherlands&amp;#39;:2, &amp;#39;Germany&amp;#39;:3, &amp;#39;France&amp;#39;:4, &amp;#39;USA&amp;#39;:5}       

sales = sales.applymap(lambda s: mymap.get(s) if s in mymap else s)

sales.head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   InvoiceNo StockCode  ... Country  Revenue
## 0    536365     22752  ...       1    15.30
## 1    536365     71053  ...       1    20.34
## 2    536365    84029G  ...       1    20.34
## 3    536365    85123A  ...       1    15.30
## 4    536366     22633  ...       1    11.10
## 
## [5 rows x 9 columns]&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales.Country.value_counts().nlargest(7)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## 1          292640
## 3            5466
## 4            5026
## EIRE         4789
## Spain        1420
## 2            1393
## Belgium      1191
## Name: Country, dtype: int64&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;passing-objects&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.4&lt;/span&gt; Passing Objects&lt;/h2&gt;
&lt;div id=&#34;python-to-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;2.4.1&lt;/span&gt; Python to R&lt;/h3&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;data2 = pd.Series([0.25, 0.5, 0.75, 1.0])&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_t = py$data2&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_t&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##    0    1    2    3 
## 0.25 0.50 0.75 1.00&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;r&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;&lt;span class=&#34;header-section-number&#34;&gt;3&lt;/span&gt; R&lt;/h1&gt;
&lt;div id=&#34;knowing-data-frames-1&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.1&lt;/span&gt; Knowing data frames&lt;/h2&gt;
&lt;div id=&#34;defining-an-data-frame&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.1.1&lt;/span&gt; Defining an data frame&lt;/h3&gt;
&lt;p&gt;tidy way &lt;img src=&#34;https://media.giphy.com/media/kKLr7rlj0KwjFfCxHJ/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;-  tibble(0.25, 0.5, 0.75, 1.0)
data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 4
##   `0.25` `0.5` `0.75`   `1`
##    &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1   0.25   0.5   0.75     1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data[2]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   `0.5`
##   &amp;lt;dbl&amp;gt;
## 1   0.5&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data[2:3]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 2
##   `0.5` `0.75`
##   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1   0.5   0.75&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Not using tidyverse.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;-  data.frame(c(0.25, 0.5, 0.75, 1.0))
rownames(data) &amp;lt;- 1:nrow(data)
colnames(data) &amp;lt;- &amp;quot;nope&amp;quot;
data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   nope
## 1 0.25
## 2 0.50
## 3 0.75
## 4 1.00&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;index-search&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.1.2&lt;/span&gt; Index search&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data &amp;lt;-  data.frame(c(0.25, 0.5, 0.75, 1.0),row.names = c(&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;,&amp;quot;c&amp;quot;,&amp;quot;d&amp;quot;))
data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   c.0.25..0.5..0.75..1.
## a                  0.25
## b                  0.50
## c                  0.75
## d                  1.00&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data[&amp;quot;b&amp;quot;,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 0.5&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-an-data-frame-from-two-r-series&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.2&lt;/span&gt; Creating an data frame from two R series&lt;/h2&gt;
&lt;div id=&#34;create-a-date-frame-using-an-list&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.2.1&lt;/span&gt; Create a date frame using an list&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;population_dict &amp;lt;- list(
  &amp;#39;California&amp;#39; = 38332521,
  &amp;#39;Florida&amp;#39; = 19552860,
  &amp;#39;Illinois&amp;#39; = 12882135,
  &amp;#39;New York&amp;#39; = 19651127,
  &amp;#39;Texas&amp;#39; = 26448193
  )
population &amp;lt;- population_dict %&amp;gt;% as_tibble()

population[&amp;#39;California&amp;#39;]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 1
##   California
##        &amp;lt;dbl&amp;gt;
## 1   38332521&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;population %&amp;gt;% select(California:Illinois)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 3
##   California  Florida Illinois
##        &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;
## 1   38332521 19552860 12882135&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;create-a-date-frame-using-an-list-2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.2.2&lt;/span&gt; Create a date frame using an list 2&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;area_dict = list(
  &amp;#39;California&amp;#39; = 423967, 
  &amp;#39;Florida&amp;#39; = 170312,
  &amp;#39;Illinois&amp;#39; = 149995,
  &amp;#39;New York&amp;#39; = 141297,
  &amp;#39;Texas&amp;#39; = 695662
  )
area_dict %&amp;gt;% as_tibble() -&amp;gt; area

area&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 1 x 5
##   California Florida Illinois `New York`  Texas
##        &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
## 1     423967  170312   149995     141297 695662&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;subsetting-an-data-frame-using-join-or-cbind&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.2.3&lt;/span&gt; Subsetting an data frame using join or cbind&lt;/h3&gt;
&lt;p&gt;The tidy way doesn`t support indexes so we can tidy our data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy_area &amp;lt;- area %&amp;gt;% gather(key = &amp;quot;state&amp;quot;, value = &amp;quot;area&amp;quot;)
tidy_state &amp;lt;- population %&amp;gt;% gather(key = &amp;quot;state&amp;quot;, value = &amp;quot;population&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy_area&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 2
##   state        area
##   &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;
## 1 California 423967
## 2 Florida    170312
## 3 Illinois   149995
## 4 New York   141297
## 5 Texas      695662&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy_state&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 2
##   state      population
##   &amp;lt;chr&amp;gt;           &amp;lt;dbl&amp;gt;
## 1 California   38332521
## 2 Florida      19552860
## 3 Illinois     12882135
## 4 New York     19651127
## 5 Texas        26448193&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy_area %&amp;gt;% left_join(tidy_state)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Joining, by = &amp;quot;state&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 3
##   state        area population
##   &amp;lt;chr&amp;gt;       &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;
## 1 California 423967   38332521
## 2 Florida    170312   19552860
## 3 Illinois   149995   12882135
## 4 New York   141297   19651127
## 5 Texas      695662   26448193&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;tidy_merge &amp;lt;- cbind(tidy_area,tidy_state[,-1])

states &amp;lt;- tidy_merge&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;some-info-on-our-data-frame&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.2.4&lt;/span&gt; Some info on our data frame&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(tidy_merge)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;data.frame&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(tidy_merge$population)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;class(list(tidy_merge[&amp;quot;population&amp;quot;]))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;list&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;states %&amp;gt;% dim()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 5 3&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;states %&amp;gt;% str()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;#39;data.frame&amp;#39;:    5 obs. of  3 variables:
##  $ state     : chr  &amp;quot;California&amp;quot; &amp;quot;Florida&amp;quot; &amp;quot;Illinois&amp;quot; &amp;quot;New York&amp;quot; ...
##  $ area      : num  423967 170312 149995 141297 695662
##  $ population: num  38332521 19552860 12882135 19651127 26448193&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;states %&amp;gt;% glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 5
## Variables: 3
## $ state      &amp;lt;chr&amp;gt; &amp;quot;California&amp;quot;, &amp;quot;Florida&amp;quot;, &amp;quot;Illinois&amp;quot;, &amp;quot;New York&amp;quot;, &amp;quot;T...
## $ area       &amp;lt;dbl&amp;gt; 423967, 170312, 149995, 141297, 695662
## $ population &amp;lt;dbl&amp;gt; 38332521, 19552860, 12882135, 19651127, 26448193&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;states[[&amp;quot;Estado&amp;quot;]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NULL&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;states %&amp;gt;% colnames() %&amp;gt;% tail(-1)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;area&amp;quot;       &amp;quot;population&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;states$area&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 423967 170312 149995 141297 695662&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-new-columns-using-mutate-and-basic-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.2.5&lt;/span&gt; Creating new columns using mutate and basic R&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;states$density &amp;lt;-  states$population / states$area
states&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        state   area population   density
## 1 California 423967   38332521  90.41393
## 2    Florida 170312   19552860 114.80612
## 3   Illinois 149995   12882135  85.88376
## 4   New York 141297   19651127 139.07675
## 5      Texas 695662   26448193  38.01874&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# or
states$density &amp;lt;-  states[[&amp;quot;population&amp;quot;]] / states[[&amp;quot;area&amp;quot;]]
states&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        state   area population   density
## 1 California 423967   38332521  90.41393
## 2    Florida 170312   19552860 114.80612
## 3   Illinois 149995   12882135  85.88376
## 4   New York 141297   19651127 139.07675
## 5      Texas 695662   26448193  38.01874&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#or
states %&amp;gt;% 
  mutate(density = population / area)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        state   area population   density
## 1 California 423967   38332521  90.41393
## 2    Florida 170312   19552860 114.80612
## 3   Illinois 149995   12882135  85.88376
## 4   New York 141297   19651127 139.07675
## 5      Texas 695662   26448193  38.01874&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;ordering-an-data-frame-using-the-tidy-way-arrange-or-order.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.2.6&lt;/span&gt; Ordering an data frame using the tidy way arrange or order.&lt;/h3&gt;
&lt;p&gt;You can also use -c() or desc() sometimes -c() can give strange results.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;states %&amp;gt;% arrange(desc(population))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        state   area population   density
## 1 California 423967   38332521  90.41393
## 2      Texas 695662   26448193  38.01874
## 3   New York 141297   19651127 139.07675
## 4    Florida 170312   19552860 114.80612
## 5   Illinois 149995   12882135  85.88376&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;states[order(states$area),]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        state   area population   density
## 4   New York 141297   19651127 139.07675
## 3   Illinois 149995   12882135  85.88376
## 2    Florida 170312   19552860 114.80612
## 1 California 423967   38332521  90.41393
## 5      Texas 695662   26448193  38.01874&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Mix and match all three formas
states %&amp;gt;% arrange(-c(density),desc(population,area),state)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        state   area population   density
## 1   New York 141297   19651127 139.07675
## 2    Florida 170312   19552860 114.80612
## 3 California 423967   38332521  90.41393
## 4   Illinois 149995   12882135  85.88376
## 5      Texas 695662   26448193  38.01874&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;filtering-rows-using-standard-r-code-or-filter.&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.2.7&lt;/span&gt; Filtering rows using standard R code or filter.&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;states[1:3,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##        state   area population   density
## 1 California 423967   38332521  90.41393
## 2    Florida 170312   19552860 114.80612
## 3   Illinois 149995   12882135  85.88376&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;data_pop &amp;lt;- states[states$population &amp;gt; 19552860 &amp;amp; states$area &amp;gt; 423967,]
data_pop&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   state   area population  density
## 5 Texas 695662   26448193 38.01874&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;states %&amp;gt;% 
  filter(population &amp;gt; 19552860 &amp;amp; area &amp;gt; 423967)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   state   area population  density
## 1 Texas 695662   26448193 38.01874&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;you can mix and match filter for rows and select for columns.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;states %&amp;gt;% 
  filter(density &amp;gt; 100)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##      state   area population  density
## 1  Florida 170312   19552860 114.8061
## 2 New York 141297   19651127 139.0767&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;states %&amp;gt;%
  filter(density &amp;gt; 100) %&amp;gt;% 
  select(population,density)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   population  density
## 1   19552860 114.8061
## 2   19651127 139.0767&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;states[1,4]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 90.41393&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;real-case&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3&lt;/span&gt; Real Case&lt;/h2&gt;
&lt;div id=&#34;two-way-of-importing-an-csv&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3.1&lt;/span&gt; Two way of importing an csv&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales &amp;lt;- read_csv(&amp;#39;2019-03-23-exploratory-data-analysis-basic-pandas-and-dplyr/UKretail.csv&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   InvoiceNo = col_character(),
##   StockCode = col_character(),
##   Description = col_character(),
##   Quantity = col_double(),
##   InvoiceDate = col_datetime(format = &amp;quot;&amp;quot;),
##   UnitPrice = col_double(),
##   CustomerID = col_double(),
##   Country = col_character()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales &amp;lt;- read.csv(&amp;#39;2019-03-23-exploratory-data-analysis-basic-pandas-and-dplyr/UKretail.csv&amp;#39;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you think this looks like an ugly path and a was of space I would agree we
can fix this by using one of my favorite thinks from python the &#34;&#34;key I avoided.&lt;br /&gt;
I am now using it on the python part to show the power of neat line.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;path_file = &amp;#39;\
2019-03-23-exploratory-data-analysis-basic-pandas-and-dplyr/\
UKretail.csv&amp;#39; &lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales &amp;lt;- read_csv(py$path_file)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Parsed with column specification:
## cols(
##   InvoiceNo = col_character(),
##   StockCode = col_character(),
##   Description = col_character(),
##   Quantity = col_double(),
##   InvoiceDate = col_datetime(format = &amp;quot;&amp;quot;),
##   UnitPrice = col_double(),
##   CustomerID = col_double(),
##   Country = col_character()
## )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally our first usefull python to r functionality!&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;lets-look-at-our-data&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3.2&lt;/span&gt; Let’s look at our data&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 8
##   InvoiceNo StockCode Description Quantity InvoiceDate         UnitPrice
##   &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt; &amp;lt;dttm&amp;gt;                  &amp;lt;dbl&amp;gt;
## 1 536365    22752     SET 7 BABU~        2 2010-12-01 08:26:02      7.65
## 2 536365    71053     WHITE META~        6 2010-12-01 08:26:02      3.39
## 3 536365    84029G    KNITTED UN~        6 2010-12-01 08:26:02      3.39
## 4 536365    85123A    WHITE HANG~        6 2010-12-01 08:26:02      2.55
## 5 536366    22633     HAND WARME~        6 2010-12-01 08:28:02      1.85
## 6 536367    21754     HOME BUILD~        3 2010-12-01 08:33:59      5.95
## # ... with 2 more variables: CustomerID &amp;lt;dbl&amp;gt;, Country &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales %&amp;gt;% tail(3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 3 x 8
##   InvoiceNo StockCode Description Quantity InvoiceDate         UnitPrice
##   &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt; &amp;lt;dttm&amp;gt;                  &amp;lt;dbl&amp;gt;
## 1 581587    22899     CHILDREN&amp;#39;S~        6 2011-12-09 12:49:59      2.1 
## 2 581587    23254     CHILDRENS ~        4 2011-12-09 12:49:59      4.15
## 3 581587    23256     CHILDRENS ~        4 2011-12-09 12:49:59      4.15
## # ... with 2 more variables: CustomerID &amp;lt;dbl&amp;gt;, Country &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;r_types_columns&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3.3&lt;/span&gt; Types of columns r&lt;/h3&gt;
&lt;p&gt;If you payed attention read_ tries to inform what conversion was used in each column that is specially cool because base R tends to create unesceassary factor whne in fact you are working with strings, but know you can choose between three different implementation of the read command.&lt;/p&gt;
&lt;p&gt;A cool thing about tibbles is that they are in fact still data.frame.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales %&amp;gt;% class()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;spec_tbl_df&amp;quot; &amp;quot;tbl_df&amp;quot;      &amp;quot;tbl&amp;quot;         &amp;quot;data.frame&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Pay attention to the R difference between “[[” and “[” if you recall this is the “opposite” of the python behavior.&lt;br /&gt;
Jump to &lt;a href=&#34;#py_types_columns&#34;&gt;python implementation&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales[[&amp;quot;CustomerID&amp;quot;]] %&amp;gt;% class()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;numeric&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales[&amp;quot;CustomerID&amp;quot;] %&amp;gt;% class()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;tbl_df&amp;quot;     &amp;quot;tbl&amp;quot;        &amp;quot;data.frame&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;basic-description-real-data-using-glimpse-and-str&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3.4&lt;/span&gt; Basic Description real data using Glimpse and str&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales %&amp;gt;% dim()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 325145      8&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales %&amp;gt;% colnames()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] &amp;quot;InvoiceNo&amp;quot;   &amp;quot;StockCode&amp;quot;   &amp;quot;Description&amp;quot; &amp;quot;Quantity&amp;quot;    &amp;quot;InvoiceDate&amp;quot;
## [6] &amp;quot;UnitPrice&amp;quot;   &amp;quot;CustomerID&amp;quot;  &amp;quot;Country&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales %&amp;gt;% glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 325,145
## Variables: 8
## $ InvoiceNo   &amp;lt;chr&amp;gt; &amp;quot;536365&amp;quot;, &amp;quot;536365&amp;quot;, &amp;quot;536365&amp;quot;, &amp;quot;536365&amp;quot;, &amp;quot;536366&amp;quot;, ...
## $ StockCode   &amp;lt;chr&amp;gt; &amp;quot;22752&amp;quot;, &amp;quot;71053&amp;quot;, &amp;quot;84029G&amp;quot;, &amp;quot;85123A&amp;quot;, &amp;quot;22633&amp;quot;, &amp;quot;21...
## $ Description &amp;lt;chr&amp;gt; &amp;quot;SET 7 BABUSHKA NESTING BOXES&amp;quot;, &amp;quot;WHITE METAL LANTE...
## $ Quantity    &amp;lt;dbl&amp;gt; 2, 6, 6, 6, 6, 3, 3, 4, 6, 6, 6, 8, 4, 3, 3, 48, 2...
## $ InvoiceDate &amp;lt;dttm&amp;gt; 2010-12-01 08:26:02, 2010-12-01 08:26:02, 2010-12...
## $ UnitPrice   &amp;lt;dbl&amp;gt; 7.65, 3.39, 3.39, 2.55, 1.85, 5.95, 5.95, 7.95, 1....
## $ CustomerID  &amp;lt;dbl&amp;gt; 17850, 17850, 17850, 17850, 17850, 13047, 13047, 1...
## $ Country     &amp;lt;chr&amp;gt; &amp;quot;United Kingdom&amp;quot;, &amp;quot;United Kingdom&amp;quot;, &amp;quot;United Kingdo...&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales %&amp;gt;% str()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Classes &amp;#39;spec_tbl_df&amp;#39;, &amp;#39;tbl_df&amp;#39;, &amp;#39;tbl&amp;#39; and &amp;#39;data.frame&amp;#39;: 325145 obs. of  8 variables:
##  $ InvoiceNo  : chr  &amp;quot;536365&amp;quot; &amp;quot;536365&amp;quot; &amp;quot;536365&amp;quot; &amp;quot;536365&amp;quot; ...
##  $ StockCode  : chr  &amp;quot;22752&amp;quot; &amp;quot;71053&amp;quot; &amp;quot;84029G&amp;quot; &amp;quot;85123A&amp;quot; ...
##  $ Description: chr  &amp;quot;SET 7 BABUSHKA NESTING BOXES&amp;quot; &amp;quot;WHITE METAL LANTERN&amp;quot; &amp;quot;KNITTED UNION FLAG HOT WATER BOTTLE&amp;quot; &amp;quot;WHITE HANGING HEART T-LIGHT HOLDER&amp;quot; ...
##  $ Quantity   : num  2 6 6 6 6 3 3 4 6 6 ...
##  $ InvoiceDate: POSIXct, format: &amp;quot;2010-12-01 08:26:02&amp;quot; &amp;quot;2010-12-01 08:26:02&amp;quot; ...
##  $ UnitPrice  : num  7.65 3.39 3.39 2.55 1.85 5.95 5.95 7.95 1.65 2.1 ...
##  $ CustomerID : num  17850 17850 17850 17850 17850 ...
##  $ Country    : chr  &amp;quot;United Kingdom&amp;quot; &amp;quot;United Kingdom&amp;quot; &amp;quot;United Kingdom&amp;quot; &amp;quot;United Kingdom&amp;quot; ...
##  - attr(*, &amp;quot;spec&amp;quot;)=
##   .. cols(
##   ..   InvoiceNo = col_character(),
##   ..   StockCode = col_character(),
##   ..   Description = col_character(),
##   ..   Quantity = col_double(),
##   ..   InvoiceDate = col_datetime(format = &amp;quot;&amp;quot;),
##   ..   UnitPrice = col_double(),
##   ..   CustomerID = col_double(),
##   ..   Country = col_character()
##   .. )&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales %&amp;gt;% summary()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   InvoiceNo          StockCode         Description       
##  Length:325145      Length:325145      Length:325145     
##  Class :character   Class :character   Class :character  
##  Mode  :character   Mode  :character   Mode  :character  
##                                                          
##                                                          
##                                                          
##                                                          
##     Quantity          InvoiceDate                    UnitPrice        
##  Min.   :-80995.00   Min.   :2010-12-01 08:26:02   Min.   :-11062.06  
##  1st Qu.:     1.00   1st Qu.:2011-03-28 12:13:02   1st Qu.:     1.25  
##  Median :     3.00   Median :2011-07-20 10:50:59   Median :     2.08  
##  Mean   :     9.27   Mean   :2011-07-04 14:11:43   Mean   :     4.85  
##  3rd Qu.:    10.00   3rd Qu.:2011-10-19 10:47:59   3rd Qu.:     4.13  
##  Max.   : 12540.00   Max.   :2011-12-09 12:49:59   Max.   : 38970.00  
##                                                                       
##    CustomerID      Country         
##  Min.   :12347   Length:325145     
##  1st Qu.:13959   Class :character  
##  Median :15150   Mode  :character  
##  Mean   :15289                     
##  3rd Qu.:16793                     
##  Max.   :18287                     
##  NA&amp;#39;s   :80991&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you agree with me that summary sucks on a data.frame object I am glad to show skimr, also if you don’t like summary behaviour on model outputs &lt;a href=&#34;https://cran.r-project.org/web/packages/broom/index.html&#34;&gt;broom&lt;/a&gt; is there to save you, I will talk more about when I make an &lt;a href=&#34;https://scikit-learn.org/stable/&#34;&gt;scikit-learn&lt;/a&gt; and &lt;a href=&#34;https://topepo.github.io/caret/&#34;&gt;caret&lt;/a&gt; + &lt;a href=&#34;https://www.tidyverse.org/articles/2018/08/tidymodels-0-0-1/&#34;&gt;tidymodels&lt;/a&gt; post.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;subsetting-data-with-select-or-base-r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3.5&lt;/span&gt; Subsetting Data with select or base R&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales[1:4,]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 4 x 8
##   InvoiceNo StockCode Description Quantity InvoiceDate         UnitPrice
##   &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt; &amp;lt;dttm&amp;gt;                  &amp;lt;dbl&amp;gt;
## 1 536365    22752     SET 7 BABU~        2 2010-12-01 08:26:02      7.65
## 2 536365    71053     WHITE META~        6 2010-12-01 08:26:02      3.39
## 3 536365    84029G    KNITTED UN~        6 2010-12-01 08:26:02      3.39
## 4 536365    85123A    WHITE HANG~        6 2010-12-01 08:26:02      2.55
## # ... with 2 more variables: CustomerID &amp;lt;dbl&amp;gt;, Country &amp;lt;chr&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales$CustomerID %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 17850 17850 17850 17850 17850 13047&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales[[&amp;quot;CustomerID&amp;quot;]] %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 17850 17850 17850 17850 17850 13047&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales[,3] %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 1
##   Description                        
##   &amp;lt;chr&amp;gt;                              
## 1 SET 7 BABUSHKA NESTING BOXES       
## 2 WHITE METAL LANTERN                
## 3 KNITTED UNION FLAG HOT WATER BOTTLE
## 4 WHITE HANGING HEART T-LIGHT HOLDER 
## 5 HAND WARMER UNION JACK             
## 6 HOME BUILDING BLOCK WORD&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales[1:5,3]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 5 x 1
##   Description                        
##   &amp;lt;chr&amp;gt;                              
## 1 SET 7 BABUSHKA NESTING BOXES       
## 2 WHITE METAL LANTERN                
## 3 KNITTED UNION FLAG HOT WATER BOTTLE
## 4 WHITE HANGING HEART T-LIGHT HOLDER 
## 5 HAND WARMER UNION JACK&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales$Revenue2 &amp;lt;- sales$Quantity * sales$UnitPrice

sales[[&amp;quot;Revenue3&amp;quot;]] &amp;lt;- sales[[&amp;quot;Quantity&amp;quot;]] * sales[[&amp;quot;UnitPrice&amp;quot;]]

# () show created objects 
# Strange behavior right here 6 rowns on head()
(sales &amp;lt;- sales %&amp;gt;% mutate(Revenue = Quantity * UnitPrice)) %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 11
##   InvoiceNo StockCode Description Quantity InvoiceDate         UnitPrice
##   &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt; &amp;lt;dttm&amp;gt;                  &amp;lt;dbl&amp;gt;
## 1 536365    22752     SET 7 BABU~        2 2010-12-01 08:26:02      7.65
## 2 536365    71053     WHITE META~        6 2010-12-01 08:26:02      3.39
## 3 536365    84029G    KNITTED UN~        6 2010-12-01 08:26:02      3.39
## 4 536365    85123A    WHITE HANG~        6 2010-12-01 08:26:02      2.55
## 5 536366    22633     HAND WARME~        6 2010-12-01 08:28:02      1.85
## 6 536367    21754     HOME BUILD~        3 2010-12-01 08:33:59      5.95
## # ... with 5 more variables: CustomerID &amp;lt;dbl&amp;gt;, Country &amp;lt;chr&amp;gt;,
## #   Revenue2 &amp;lt;dbl&amp;gt;, Revenue3 &amp;lt;dbl&amp;gt;, Revenue &amp;lt;dbl&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(sales$Revenue == sales$Revenue2)/nrow(sales)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(sales$Revenue == sales$Revenue3)/nrow(sales)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sum(sales$Revenue2 == sales$Revenue3)/nrow(sales)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# If there were any differences between our columns the sum would return &amp;lt;1    &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;creating-a-new-smaller-data-frame-using-transmute-and-base&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3.6&lt;/span&gt; Creating a new smaller data frame using transmute and base&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;raw_sales &amp;lt;- sales %&amp;gt;% select(Quantity, UnitPrice, Revenue)

raw_sales %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 3
##   Quantity UnitPrice Revenue
##      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1        2      7.65    15.3
## 2        6      3.39    20.3
## 3        6      3.39    20.3
## 4        6      2.55    15.3
## 5        6      1.85    11.1
## 6        3      5.95    17.8&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;raw_sales %&amp;gt;% glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Observations: 325,145
## Variables: 3
## $ Quantity  &amp;lt;dbl&amp;gt; 2, 6, 6, 6, 6, 3, 3, 4, 6, 6, 6, 8, 4, 3, 3, 48, 24,...
## $ UnitPrice &amp;lt;dbl&amp;gt; 7.65, 3.39, 3.39, 2.55, 1.85, 5.95, 5.95, 7.95, 1.65...
## $ Revenue   &amp;lt;dbl&amp;gt; 15.30, 20.34, 20.34, 15.30, 11.10, 17.85, 17.85, 31....&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;raw_sales %&amp;gt;% skimr::skim()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Skim summary statistics
##  n obs: 325145 
##  n variables: 3 
## 
## -- Variable type:numeric ------------------------------------------------
##   variable missing complete      n  mean     sd         p0  p25  p50   p75
##   Quantity       0   325145 325145  9.27 154.39  -80995    1    3    10   
##    Revenue       0   325145 325145 17.43 331.85 -168469.6  3.4  9.48 17.4 
##  UnitPrice       0   325145 325145  4.85 116.83  -11062.06 1.25 2.08  4.13
##   p100     hist
##  12540 &amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2587&amp;gt;&amp;lt;U+2581&amp;gt;
##  38970 &amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2587&amp;gt;&amp;lt;U+2581&amp;gt;
##  38970 &amp;lt;U+2581&amp;gt;&amp;lt;U+2587&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;ploting-with-ggplot&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3.7&lt;/span&gt; Ploting with ggplot&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales %&amp;gt;% ggplot() +
  aes(x = InvoiceDate, y = Revenue) +
  geom_line()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019/2019-03/2019-03-23/1/index_files/figure-html/exploratory_data1-68-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;filtering_r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3.8&lt;/span&gt; Filtering and replace data&lt;/h3&gt;
&lt;p&gt;Here I really couldn`t figure out an easy way to filter using this
cancel tricky that works in &lt;a href=&#34;#filtering_py&#34;&gt;python&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;cancels = sales$Revenue &amp;lt; 0
cancels %&amp;gt;% nrow()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## NULL&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;invert_func &amp;lt;- function(cancel){
  ifelse(cancel == 1,
         0,
         1)
  }


sales2 = sales[invert_func(cancels),]

sales2 %&amp;gt;% dim()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## [1] 319557     11&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I really prefer the tidy way also.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales &amp;lt;- sales %&amp;gt;% filter(Revenue &amp;gt; 0)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;groupby-example-in-tidyverse&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3.9&lt;/span&gt; Groupby example in tidyverse&lt;/h3&gt;
&lt;p&gt;I prefer the tidy way here as well.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;CountryGroups &amp;lt;- sales %&amp;gt;% 
  group_by(Country) %&amp;gt;% 
  summarise(sum_revenue = sum(Revenue),
            number_cases = n()) %&amp;gt;% 
  arrange(-sum_revenue)

CountryGroups&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 38 x 3
##    Country        sum_revenue number_cases
##    &amp;lt;chr&amp;gt;                &amp;lt;dbl&amp;gt;        &amp;lt;int&amp;gt;
##  1 United Kingdom    5311080.       291129
##  2 EIRE               176305.         4788
##  3 Netherlands        165583.         1391
##  4 Germany            138778.         5465
##  5 France             127194.         5025
##  6 Australia           79198.          726
##  7 Spain               36117.         1420
##  8 Switzerland         34315.         1169
##  9 Belgium             24015.         1191
## 10 Norway              23182.          658
## # ... with 28 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;skimr::skim(sales)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## Skim summary statistics
##  n obs: 318036 
##  n variables: 11 
## 
## -- Variable type:character ----------------------------------------------
##     variable missing complete      n min max empty n_unique
##      Country       0   318036 318036   3  20     0       38
##  Description       0   318036 318036   6  35     0     3926
##    InvoiceNo       0   318036 318036   6   7     0    19107
##    StockCode       0   318036 318036   1  12     0     3835
## 
## -- Variable type:numeric ------------------------------------------------
##    variable missing complete      n     mean      sd        p0      p25
##  CustomerID   79261   238775 318036 15295.34 1713.1  12347     13969   
##    Quantity       0   318036 318036    10.25   38.3      1         1   
##     Revenue       0   318036 318036    19.78  104.17     0.001     3.75
##    Revenue2       0   318036 318036    19.78  104.17     0.001     3.75
##    Revenue3       0   318036 318036    19.78  104.17     0.001     3.75
##   UnitPrice       0   318036 318036     3.96   42.53     0.001     1.25
##       p50      p75     p100     hist
##  15157    16800    18287    &amp;lt;U+2587&amp;gt;&amp;lt;U+2586&amp;gt;&amp;lt;U+2587&amp;gt;&amp;lt;U+2587&amp;gt;&amp;lt;U+2586&amp;gt;&amp;lt;U+2586&amp;gt;&amp;lt;U+2586&amp;gt;&amp;lt;U+2587&amp;gt;
##      3       10     4800    &amp;lt;U+2587&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;
##      9.9     17.7  38970    &amp;lt;U+2587&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;
##      9.9     17.7  38970    &amp;lt;U+2587&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;
##      9.9     17.7  38970    &amp;lt;U+2587&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;
##      2.08     4.13 13541.33 &amp;lt;U+2587&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;&amp;lt;U+2581&amp;gt;
## 
## -- Variable type:POSIXct ------------------------------------------------
##     variable missing complete      n        min        max     median
##  InvoiceDate       0   318036 318036 2010-12-01 2011-12-09 2011-07-20
##  n_unique
##     17750&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;ploting-an-histogram-using-ggplot2&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3.10&lt;/span&gt; Ploting an histogram using ggplot2&lt;/h3&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales %&amp;gt;%
  filter(CustomerID == 17850) %&amp;gt;% 
  ggplot() +
  aes(Revenue) +
  geom_histogram(bins = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019/2019-03/2019-03-23/1/index_files/figure-html/exploratory_data1-73-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;Another example.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales %&amp;gt;%
  filter(StockCode == 71053) %&amp;gt;% 
  ggplot() +
  aes(Revenue) +
  geom_histogram(bins = 20)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/2019/2019-03/2019-03-23/1/index_files/figure-html/exploratory_data1-74-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;missing_values_r&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3.11&lt;/span&gt; Handling Missing values in R&lt;/h3&gt;
&lt;p&gt;Ok I got hand this one to &lt;a href=&#34;#missing_values_py&#34;&gt;python&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales2$CustomerID %&amp;gt;% 
  table(useNA = &amp;#39;always&amp;#39;) %&amp;gt;%
  sort(decreasing = TRUE) %&amp;gt;%
  head(3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## .
##  17850   &amp;lt;NA&amp;gt; 
## 319557      0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is just not simple enough luckly we can create functions for our afflictions, plus this is replacement as an side effect which sucks.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;#sales[sales[[&amp;quot;CustomerID&amp;quot;]] %&amp;gt;% is.na(),&amp;quot;CustomerID&amp;quot;] &amp;lt;- 0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is an way better tidy way.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# sales %&amp;gt;% mutate_if(is.numeric, funs(replace(., is.na(.), 0)))
sales2 &amp;lt;- sales %&amp;gt;% mutate_at(vars(CustomerID),
                    list(
                      ~replace(.,
                              is.na(.), # function that check condition (na)
                              0) # value to replace could be mean(.,na.rm = T)
                      )
                    )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Using an stronger method like mice even with an &lt;a href=&#34;https://cran.r-project.org/web/packages/micemd/index.html&#34;&gt;amazing multicore package&lt;/a&gt; takes too long for an blogpost, plus I really don’t think there should be an model for CustomerID here is some workflow if you need to split your data.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;non_character_sales &amp;lt;- sales %&amp;gt;%
  select_if(function(col)
    is.numeric(col) |
      is.factor(col))

# or my favorite
select_cases &amp;lt;- function(col) {
  is.numeric(col) |
  is.factor(col)
}

non_character_sales &amp;lt;- sales %&amp;gt;% select_if(select_cases)

non_character_sales %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 6
##   Quantity UnitPrice CustomerID Revenue2 Revenue3 Revenue
##      &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
## 1        2      7.65      17850     15.3     15.3    15.3
## 2        6      3.39      17850     20.3     20.3    20.3
## 3        6      3.39      17850     20.3     20.3    20.3
## 4        6      2.55      17850     15.3     15.3    15.3
## 5        6      1.85      17850     11.1     11.1    11.1
## 6        3      5.95      13047     17.8     17.8    17.8&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;character_sales &amp;lt;- sales %&amp;gt;% select_if(negate(is.numeric))

character_sales %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 5
##   InvoiceNo StockCode Description            InvoiceDate         Country   
##   &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;     &amp;lt;chr&amp;gt;                  &amp;lt;dttm&amp;gt;              &amp;lt;chr&amp;gt;     
## 1 536365    22752     SET 7 BABUSHKA NESTIN~ 2010-12-01 08:26:02 United Ki~
## 2 536365    71053     WHITE METAL LANTERN    2010-12-01 08:26:02 United Ki~
## 3 536365    84029G    KNITTED UNION FLAG HO~ 2010-12-01 08:26:02 United Ki~
## 4 536365    85123A    WHITE HANGING HEART T~ 2010-12-01 08:26:02 United Ki~
## 5 536366    22633     HAND WARMER UNION JACK 2010-12-01 08:28:02 United Ki~
## 6 536367    21754     HOME BUILDING BLOCK W~ 2010-12-01 08:33:59 United Ki~&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales3 &amp;lt;- cbind(character_sales,non_character_sales)

# if you need the same order

sales3 &amp;lt;- sales3 %&amp;gt;% select(names(sales)) &lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;replacing-names-with-an-case-when-aproach&#34; class=&#34;section level3&#34;&gt;
&lt;h3&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.3.12&lt;/span&gt; Replacing names with an case when aproach&lt;/h3&gt;
&lt;p&gt;Don’t mix and match numbers and characters else this will cause an error.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;replace_function &amp;lt;-  function(country) {
  case_when(
  country == &amp;#39;United Kingdom&amp;#39; ~ &amp;quot;1&amp;quot;,
  country == &amp;#39;Netherlands&amp;#39; ~ &amp;quot;2&amp;quot;,
  country == &amp;#39;Germany&amp;#39; ~ &amp;quot;3&amp;quot;,
  country == &amp;#39;France&amp;#39; ~ &amp;quot;4&amp;quot;,
  country == &amp;#39;USA&amp;#39; ~ &amp;quot;5&amp;quot;,
  TRUE    ~ country
)
  }&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales3 &amp;lt;- sales3 %&amp;gt;% mutate(new = replace_function(Country))

sales3 %&amp;gt;% head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##   InvoiceNo StockCode                         Description Quantity
## 1    536365     22752        SET 7 BABUSHKA NESTING BOXES        2
## 2    536365     71053                 WHITE METAL LANTERN        6
## 3    536365    84029G KNITTED UNION FLAG HOT WATER BOTTLE        6
## 4    536365    85123A  WHITE HANGING HEART T-LIGHT HOLDER        6
## 5    536366     22633              HAND WARMER UNION JACK        6
## 6    536367     21754            HOME BUILDING BLOCK WORD        3
##           InvoiceDate UnitPrice CustomerID        Country Revenue2
## 1 2010-12-01 08:26:02      7.65      17850 United Kingdom    15.30
## 2 2010-12-01 08:26:02      3.39      17850 United Kingdom    20.34
## 3 2010-12-01 08:26:02      3.39      17850 United Kingdom    20.34
## 4 2010-12-01 08:26:02      2.55      17850 United Kingdom    15.30
## 5 2010-12-01 08:28:02      1.85      17850 United Kingdom    11.10
## 6 2010-12-01 08:33:59      5.95      13047 United Kingdom    17.85
##   Revenue3 Revenue new
## 1    15.30   15.30   1
## 2    20.34   20.34   1
## 3    20.34   20.34   1
## 4    15.30   15.30   1
## 5    11.10   11.10   1
## 6    17.85   17.85   1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Two ways of solving our case_count deficiency.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;value_counts &amp;lt;- function(column, useNA = &amp;#39;always&amp;#39;, decreasing = TRUE) {
  column %&amp;gt;% 
  table(useNA = useNA) %&amp;gt;%
  sort(decreasing = decreasing)
}

sales3[[&amp;quot;new&amp;quot;]] %&amp;gt;% value_counts() %&amp;gt;% head(7)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## .
##       1       3       4    EIRE   Spain       2 Belgium 
##  291129    5465    5025    4788    1420    1391    1191&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;passing-objects-to-python&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;&lt;span class=&#34;header-section-number&#34;&gt;3.4&lt;/span&gt; Passing Objects to Python&lt;/h2&gt;
&lt;p&gt;Simple example.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales2 = r.sales2
type(sales2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## &amp;lt;class &amp;#39;pandas.core.frame.DataFrame&amp;#39;&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We can solve our value_counts problem by simply stealing from python then returning the results to r.&lt;/p&gt;
&lt;pre class=&#34;python&#34;&gt;&lt;code&gt;sales3_solution = \
r.\
sales3.\
new.\
value_counts().\
nlargest(7)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If we want to continue working in r after the steal.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;sales3_solution = py$sales3_solution
sales3_solution&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;##       1       3       4    EIRE   Spain       2 Belgium 
##  291129    5465    5025    4788    1420    1391    1191&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://media.giphy.com/media/7zW0iLn9SKYao6f8sE/giphy.gif&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
