
<div id="TOC">
<ul>
<li><a href="#libraries">Libraries</a></li>
<li><a href="#the-exercise">The Exercise</a><ul>
<li><a href="#before-we-get-into-it">Before we get into it</a><ul>
<li><a href="#objectives">Objectives</a></li>
<li><a href="#reservations">Reservations</a></li>
<li><a href="#data-dictionary">Data Dictionary</a></li>
</ul></li>
</ul></li>
<li><a href="#python">Python</a><ul>
<li><a href="#python_pre_processing">Pre-processing</a><ul>
<li><a href="#python_read_data">Reading Data</a></li>
<li><a href="#analyzing-some-basic-stuff-about-our-data-frame">Analyzing some basic stuff about our data frame</a></li>
<li><a href="#replacing-columns-names">Replacing columns names</a></li>
<li><a href="#cleaning-categorical-data">Cleaning categorical data</a></li>
<li><a href="#python_plots_categorical">Seeing the effects of categorical Variables</a></li>
<li><a href="#cleaning-numerical-data">Cleaning numerical data</a></li>
</ul></li>
</ul></li>
<li><a href="#saving-our-work-for-later">Saving our work for later</a></li>
<li><a href="#next-post">Next post</a></li>
</ul>
</div>

<p>I am currently doing exercises from <a href="https://github.com/sn3fru/datascience_course">digital house brasil</a></p>
<div id="libraries" class="section level1">
<h1>Libraries</h1>
<p>Let’s see what version of python this env is running.</p>
<pre class="python"><code>import platform
print(platform.python_version())</code></pre>
<pre><code>## 3.7.4</code></pre>
<pre class="python"><code>import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import os</code></pre>
</div>
<div id="the-exercise" class="section level1">
<h1>The Exercise</h1>
<div id="before-we-get-into-it" class="section level2">
<h2>Before we get into it</h2>
<div id="objectives" class="section level3">
<h3>Objectives</h3>
<div id="open-and-read-a-dataframe-using-pandas" class="section level4">
<h4>Open and read a DataFrame using pandas</h4>
<p><a href="#python_read_data">Simple stuff right?</a></p>
</div>
<div id="basic-analysis-of-each-column-using-value-counts." class="section level4">
<h4>Basic analysis of each column using value counts.</h4>
<p><a href="#python_custom_funtion_1">I improved a bit on the base python capabilities</a></p>
</div>
<div id="creating-a-hypothesis-that-we-care-about" class="section level4">
<h4>Creating a hypothesis that we care about</h4>
<p>In our case the hypothesis is simple do women earn on average less than men?</p>
</div>
<div id="data-preprocessing" class="section level4">
<h4>Data preprocessing</h4>
<p><a href="#python_pre_processing">We need to clean the data removing outliers, biases or any other factors that could in theory compromise our hypothesis testing.</a></p>
</div>
<div id="visualize-all-the-variables" class="section level4">
<h4>Visualize all the variables</h4>
<p>We were free to apply any technique.</p>
<p><a href="#python_plots_categorical">Categorical Data</a></p>
</div>
<div id="to-do-in-the-second-post" class="section level4">
<h4>To do in the second post</h4>
</div>
<div id="define-the-variables-used-in-the-conclusion" class="section level4">
<h4>Define the variables used in the conclusion</h4>
<p>In our case, we choose to use <a href="#python_hypothesis_testing">salary ~ sex,region</a> region was added to test whether <a href="https://en.wikipedia.org/wiki/Simpson%27s_paradox">Simpson’s paradox</a> was at play.</p>
</div>
<div id="using-masks-or-other-methods-to-filter-the-data" class="section level4">
<h4>Using masks or other methods to filter the data</h4>
<p>This objective was mostly done using the groupby function.</p>
</div>
<div id="visualizing-the-hypothesis" class="section level4">
<h4>Visualizing the hypothesis</h4>
<p><a href="#python_plot_histograms">We were advised to use two histograms combined to get a preview of our answer.</a></p>
</div>
<div id="conclusion" class="section level4">
<h4>Conclusion</h4>
<p>Comment on our findings.</p>
</div>
</div>
<div id="reservations" class="section level3">
<h3>Reservations</h3>
<p>This is an exercise where we were supposed to ask a relevant question using the data from the IBGE(Brazil’s main data collector) database of 1970.</p>
<p>Our group decided to ask whether women received less than man, we expanded the analysis hoping to avoid the Simpson’s paradox.</p>
<p>This is just an basic inference, and it’s results are therefore only used for studying purposes I don’t believe any finding would be relevant using just this approach but some basic operations can be used in a more impact full work.</p>
</div>
<div id="data-dictionary" class="section level3">
<h3>Data Dictionary</h3>
<p>We got a Data Dictionary that will be very useful for our Analysis, it contains all the required information about the encoding of the columns and the intended format that the folks at STATA desired.</p>
<details>
<summary>Portuguese</summary>
<p>
<p>Descrição do Registro de Indivíduos nos EUA.</p>
<p>Dataset do software STATA (pago), vamos abri-lo com o pandas e transforma-lo em DataFrame.</p>
<p>Variável 1 – CHAVE DO INDIVÍDUO ? Formato N - Numérico ? Tamanho 11 dígitos (11 bytes) ? Descrição Sumária Identifica unicamente o indivíduo na amostra.</p>
<p>Variável 2 - IDADE CALCULADA EM ANOS ? Formato N - Numérico ? Tamanho 3 dígitos (3 bytes) ? Descrição Sumária Identifica a idade do morador em anos completos.</p>
<p>Variável 3 – SEXO ? Formato N - Numérico ? Tamanho 1 dígito (1 byte) ? Quantidade de Categorias 3 ? Descrição Sumária Identifica o sexo do morador. Categorias (1) homem, (2) mulher e (3) gestante.</p>
<p>Variável 4 – ANOS DE ESTUDO ? Formato N - Numérico ? Tamanho 2 dígitos (2 bytes) ? Quantidade de Categorias 11 ? Descrição Sumária Identifica o número de anos de estudo do morador. Categorias (05) Cinco ou menos, (06) Seis, (07) Sete, (08) Oito, (09) Nove, (10) Dez, (11) Onze, (12) Doze, (13) Treze, (14) Quatorze, (15) Quinze ou mais.</p>
<p>Variável 5 – COR OU RAÇA ? Formato N - Numérico ? Tamanho 2 dígitos (2 bytes) ? Quantidade de Categorias 6 ? Descrição Sumária Identifica a Cor ou Raça declarada pelo morador. Categorias (01) Branca, (02) Preta, (03) Amarela, (04) Parda, (05) Indígena e (09) Não Sabe.</p>
<p>Variável 6 – VALOR DO SALÁRIO (ANUALIZADO) ? Formato N - Numérico ? Tamanho 8 dígitos (8 bytes) ? Quantidade de Decimais 2 ? Descrição Sumária Identifica o valor resultante do salário anual do indivíduo. Categorias especiais (-1) indivíduo ausente na data da pesquisa e (999999) indivíduo não quis responder.</p>
<p>Variável 7 – ESTADO CIVIL ? Formato N - Numérico ? Tamanho 1 dígito (1 byte) ? Quantidade de Categorias 2 ? Descrição Sumária Dummy que identifica o estado civil declarado pelo morador. Categorias (1) Casado, (0) não casado.</p>
<p>Variável 8 – REGIÃO GEOGRÁFICA ? Formato N - Numérico ? Tamanho 1 dígito (1 byte) ? Quantidade de Categorias 5 ? Descrição Sumária Identifica a região geográfica do morador. Categorias (1) Norte, (2) Nordeste, (3) Sudeste, (4) Sul e (5) Centro-oeste.</p>
</p>
</details>
<details>
<summary>English</summary>
<p>
<p>Description of the US Individual Registry.</p>
<p>Dataset of the STATA software (paid), we will open it with pandas and turn it into DataFrame.</p>
<p>Variable 1 - KEY OF THE INDIVIDUAL? Format N - Numeric? Size 11 digits (11 bytes)? Summary Description Uniquely identifies the individual in the sample.</p>
<p>Variable 2 - AGE CALCULATED IN YEARS? Format N - Numeric? Size 3 digits (3 bytes)? Summary Description Identifies the age of the resident in full years.</p>
<p>Variable 3 - SEX? Format N - Numeric? Size 1 digit (1 byte)? Number of Categories 3? Summary Description Identifies the gender of the resident. Categories (1) men, (2) women and (3) pregnant women.</p>
<p>Variable 4 - YEARS OF STUDY? Format N - Numeric? Size 2 digits (2 bytes)? Number of Categories 11? Summary Description Identifies the number of years of study of the resident. Categories (05) Five or less, (06) Six, (07) Seven, (08) Eight, (09) Nine, (10) Dec, (11) Eleven, (12) Twelve, (13) Thirteen, (14 ) Fourteen, (15) Fifteen or more.</p>
<p>Variable 5 - COLOR OR RACE? Format N - Numeric? Size 2 digits (2 bytes)? Number of Categories 6? Summary Description Identifies the Color or Race declared by the resident. Categories (01) White, (02) Black, (03) Yellow, (04) Brown, (05) Indigenous and (09) Don’t know.</p>
<p>Variable 6 - WAGE VALUE (ANNUALIZED)? Format N - Numeric? Size 8 digits (8 bytes)? Number of decimals 2? Summary Description Identifies the amount resulting from the individual’s annual salary. Special categories (-1) individual absent on the survey date and (999999) individual did not want to answer.</p>
<p>Variable 7 - CIVIL STATE? Format N - Numeric? Size 1 digit (1 byte)? Number of Categories 2? Summary Description Dummy that identifies the marital status declared by the resident. Categories (1) Married, (0) Not married.</p>
<p>Variable 8 - GEOGRAPHICAL REGION? Format N - Numeric? Size 1 digit (1 byte)? Number of Categories 5? Summary Description Identifies the resident’s geographic region. Categories (1) North, (2) Northeast, (3) Southeast, (4) South and (5) Midwest.</p>
</p>
</details>
</div>
</div>
</div>
<div id="python" class="section level1">
<h1>Python</h1>
<div id="python_pre_processing" class="section level2">
<h2>Pre-processing</h2>
<div id="python_read_data" class="section level3">
<h3>Reading Data</h3>
<p>The path is specific for my computer but it is easy to adapt</p>
<pre class="python"><code># Abertura e leitura dos dados em um DeteFrame em Pandas
path = r.file_path_linux
df = pd.read_csv(path + &#39;/stata_data_1970.csv&#39;)</code></pre>
</div>
<div id="analyzing-some-basic-stuff-about-our-data-frame" class="section level3">
<h3>Analyzing some basic stuff about our data frame</h3>
<pre class="python"><code>#Análise básica dos conteúdos de cada coluna com contagem de valores
df.info()</code></pre>
<pre><code>## &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
## RangeIndex: 66470 entries, 0 to 66469
## Data columns (total 9 columns):
## Unnamed: 0      66470 non-null int64
## id              66470 non-null float64
## idade           66470 non-null int64
## sexo            66470 non-null object
## anos_estudo     66036 non-null float64
## cor/raca        66228 non-null object
## salario         47878 non-null float64
## estado_civil    66470 non-null float64
## regiao          66470 non-null object
## dtypes: float64(4), int64(2), object(3)
## memory usage: 4.6+ MB</code></pre>
<p>I do enjoy python’s base value_counts but when used in a loop it can create some ugly outputs, in order to fix I created a function that adds some flavor text to the print output and generates new information about the accumulated percentage of the data being displayed.</p>
<div id="custom-count_values" class="section level4">
<h4>Custom count_values()</h4>
<pre class="python"><code>def pretty_value_counts(data_frame,
                        number_of_rows = 5,
                        cum_perc = True):
  
  for col in data_frame:
    counts = data_frame[col].value_counts(dropna=False)
    percentages = data_frame[col].value_counts(dropna=False, normalize=True)
    
    if cum_perc == True:
      cum_percentages = percentages.cumsum()
      tb = pd.concat([counts,
                      percentages,
                      cum_percentages],
                     axis=1,
                     keys=[&#39;counts&#39;,
                           &#39;percentages&#39;,
                           &quot;cum_percentages&quot;]
                    ).head(number_of_rows)
      
    else:
      tb = pd.concat([counts,
                      percentages],
                     axis=1,
                     keys=[&#39;counts&#39;,
                           &#39;percentages&#39;]).head(number_of_rows)
      
    print(&quot;Column %s with %s data type&quot; % (col,data_frame[col].dtype),
          &quot;\n&quot;,
          tb,
          &quot;\n&quot;)</code></pre>
<p>Now we can apply our new function.</p>
</div>
<div id="python_custom_function_1" class="section level4">
<h4>Using a custom function</h4>
<pre class="python"><code>pretty_value_counts(df)</code></pre>
<pre><code>## Column Unnamed: 0 with int64 data type 
##         counts  percentages  cum_percentages
## 2047        1     0.000015         0.000015
## 41601       1     0.000015         0.000030
## 21151       1     0.000015         0.000045
## 23198       1     0.000015         0.000060
## 17053       1     0.000015         0.000075 
## 
## Column id with float64 data type 
##                counts  percentages  cum_percentages
## 1.100351e+10       2     0.000030         0.000030
## 3.132701e+10       1     0.000015         0.000045
## 1.501501e+10       1     0.000015         0.000060
## 3.230631e+10       1     0.000015         0.000075
## 5.003991e+10       1     0.000015         0.000090 
## 
## Column idade with int64 data type 
##      counts  percentages  cum_percentages
## 20    2104     0.031653         0.031653
## 28    2056     0.030931         0.062585
## 26    2040     0.030691         0.093275
## 22    2034     0.030600         0.123875
## 27    2017     0.030345         0.154220 
## 
## Column sexo with object data type 
##            counts  percentages  cum_percentages
## mulher     33607     0.505597         0.505597
## homem      32791     0.493320         0.998917
## gestante      72     0.001083         1.000000 
## 
## Column anos_estudo with float64 data type 
##        counts  percentages  cum_percentages
## 5.0    23349     0.351271         0.351271
## 11.0   16790     0.252595         0.603866
## 15.0    5636     0.084790         0.688657
## 8.0     5017     0.075478         0.764134
## 10.0    2704     0.040680         0.804814 
## 
## Column cor/raca with object data type 
##            counts  percentages  cum_percentages
## Branca     31689     0.476741         0.476741
## Parda      28370     0.426809         0.903550
## Preta       5249     0.078968         0.982518
## Indigena     597     0.008981         0.991500
## Amarela      323     0.004859         0.996359 
## 
## Column salario with float64 data type 
##             counts  percentages  cum_percentages
##  NaN        18592     0.279705         0.279705
##  0.0         1841     0.027697         0.307402
## -1.0         1101     0.016564         0.323966
##  999999.0     367     0.005521         0.329487
##  5229.0       277     0.004167         0.333654 
## 
## Column estado_civil with float64 data type 
##       counts  percentages  cum_percentages
## 1.0   39066     0.587724         0.587724
## 0.0   27404     0.412276         1.000000 
## 
## Column regiao with object data type 
##                counts  percentages  cum_percentages
## sudeste        25220     0.379419         0.379419
## centro-oeste   14702     0.221182         0.600602
## norte          14653     0.220445         0.821047
## sul            11890     0.178878         0.999925
## nordeste           5     0.000075         1.000000</code></pre>
<p>Just for comparison lets look how we could do the same thing without the function.</p>
<pre class="python"><code>
for col in df:
  df[col].value_counts(dropna=False).head(5)</code></pre>
<pre><code>## 2047     1
## 41601    1
## 21151    1
## 23198    1
## 17053    1
## Name: Unnamed: 0, dtype: int64
## 1.100351e+10    2
## 3.132701e+10    1
## 1.501501e+10    1
## 3.230631e+10    1
## 5.003991e+10    1
## Name: id, dtype: int64
## 20    2104
## 28    2056
## 26    2040
## 22    2034
## 27    2017
## Name: idade, dtype: int64
## mulher      33607
## homem       32791
## gestante       72
## Name: sexo, dtype: int64
## 5.0     23349
## 11.0    16790
## 15.0     5636
## 8.0      5017
## 10.0     2704
## Name: anos_estudo, dtype: int64
## Branca      31689
## Parda       28370
## Preta        5249
## Indigena      597
## Amarela       323
## Name: cor/raca, dtype: int64
##  NaN         18592
##  0.0          1841
## -1.0          1101
##  999999.0      367
##  5229.0        277
## Name: salario, dtype: int64
## 1.0    39066
## 0.0    27404
## Name: estado_civil, dtype: int64
## sudeste         25220
## centro-oeste    14702
## norte           14653
## sul             11890
## nordeste            5
## Name: regiao, dtype: int64</code></pre>
</div>
</div>
<div id="replacing-columns-names" class="section level3">
<h3>Replacing columns names</h3>
<p>The columns are named in Portuguese we can replace their names for English equivalents in a lot of different ways</p>
<pre class="python"><code>df.columns</code></pre>
<pre><code>## Index([&#39;Unnamed: 0&#39;, &#39;id&#39;, &#39;idade&#39;, &#39;sexo&#39;, &#39;anos_estudo&#39;, &#39;cor/raca&#39;,
##        &#39;salario&#39;, &#39;estado_civil&#39;, &#39;regiao&#39;],
##       dtype=&#39;object&#39;)</code></pre>
<p>My favorite way of doing this sort of trades is using a dictionary defined outside the replace method, the cool thing about replace is that if we liked some of the column names previously defined we can simply omit them, for example, both “Unnamed: 0” and “id” are useless but since their names are already in English I don’t need to mess with them right now</p>
<details>
<summary>Translation discussion on race</summary>
<p>
<p>There is some valid discussion on whether to translate “cor/raca” into ethnic_group or color_race, but I am personally on the opinion that the ones making this data frame in 1970 were probably under other standards of naming conventions and racism accusations so I will keep their naming scheme, I apologize if anyone feels offended by the use of these terms</p>
</p>
</details>
<pre class="python"><code>dict_cols = {&quot;idade&quot; : &quot;age&quot;,
                &quot;sexo&quot; : &quot;sex&quot;,
                &quot;anos_estudo&quot; : &quot;years_study&quot;,
                &quot;cor/raca&quot; : &quot;color_race&quot;,
                &quot;salario&quot; : &quot;salary&quot;,
                &quot;estado_civil&quot; : &quot;civil_status&quot;,
                &quot;regiao&quot; : &quot;region&quot;
                }</code></pre>
<pre class="python"><code>df.rename(columns = dict_cols, inplace = True)</code></pre>
<p>Let’s see what changed</p>
<pre class="python"><code>df.columns</code></pre>
<pre><code>## Index([&#39;Unnamed: 0&#39;, &#39;id&#39;, &#39;age&#39;, &#39;sex&#39;, &#39;years_study&#39;, &#39;color_race&#39;, &#39;salary&#39;,
##        &#39;civil_status&#39;, &#39;region&#39;],
##       dtype=&#39;object&#39;)</code></pre>
<p>It look fine now we can translate some of our main features</p>
</div>
<div id="cleaning-categorical-data" class="section level3">
<h3>Cleaning categorical data</h3>
<p>First we need to know the categories present in each of our columns a simple loop would fails us when we reached a numeric variable, the simplest way to solve that would be using an if statement, another alternative is using conditional execution, I personally don’t know a simple way of doing that in python but I will show it in the R post</p>
<p>To discover the numeric and “categorical” variables, know that sometimes you will have to change some elements of these lists but looking at my outputs I think I got all the relevant ones</p>
<div id="finding-which-columns-are-categorical" class="section level4">
<h4>Finding which columns are categorical</h4>
<p>These are the numerical variables</p>
<pre class="python"><code>df.select_dtypes(include=[np.number]).columns</code></pre>
<pre><code>## Index([&#39;Unnamed: 0&#39;, &#39;id&#39;, &#39;age&#39;, &#39;years_study&#39;, &#39;salary&#39;, &#39;civil_status&#39;], dtype=&#39;object&#39;)</code></pre>
<p>And these are the Categorical variables</p>
<pre class="python"><code>list_cat = df.select_dtypes(exclude=[np.number]).columns</code></pre>
<p>Now we can run a simple loop</p>
<pre class="python"><code>for col in list_cat:
    df[col].unique()</code></pre>
<pre><code>## array([&#39;homem&#39;, &#39;mulher&#39;, &#39;gestante&#39;], dtype=object)
## array([&#39;Parda&#39;, &#39;Amarela&#39;, &#39;Indigena&#39;, &#39;Branca&#39;, &#39;Preta&#39;, nan],
##       dtype=object)
## array([&#39;norte&#39;, &#39;nordeste&#39;, &#39;sudeste&#39;, &#39;sul&#39;, &#39;centro-oeste&#39;],
##       dtype=object)</code></pre>
<p>The simpler method is comparing the dtype in each column to the desired output, but this would be harder if we needed the np.numeric</p>
<pre class="python"><code>for col in df:
  if df[col].dtype == &quot;O&quot;:
    df[col].unique()</code></pre>
<pre><code>## array([&#39;homem&#39;, &#39;mulher&#39;, &#39;gestante&#39;], dtype=object)
## array([&#39;Parda&#39;, &#39;Amarela&#39;, &#39;Indigena&#39;, &#39;Branca&#39;, &#39;Preta&#39;, nan],
##       dtype=object)
## array([&#39;norte&#39;, &#39;nordeste&#39;, &#39;sudeste&#39;, &#39;sul&#39;, &#39;centro-oeste&#39;],
##       dtype=object)</code></pre>
<p>The problem with the simpler approach is that sometimes you have columns that are categories and not objects so the simpler approach would fail when the more complex one would not, let’s convert sex to a category to prove my point</p>
<pre class="python"><code>df.sex =df.sex.astype(&quot;category&quot;)</code></pre>
<pre class="python"><code>df.dtypes</code></pre>
<pre><code>## Unnamed: 0         int64
## id               float64
## age                int64
## sex             category
## years_study      float64
## color_race        object
## salary           float64
## civil_status     float64
## region            object
## dtype: object</code></pre>
<pre class="python"><code>for col in df:
  if df[col].dtype == &quot;O&quot;:
    df[col].unique()</code></pre>
<pre><code>## array([&#39;Parda&#39;, &#39;Amarela&#39;, &#39;Indigena&#39;, &#39;Branca&#39;, &#39;Preta&#39;, nan],
##       dtype=object)
## array([&#39;norte&#39;, &#39;nordeste&#39;, &#39;sudeste&#39;, &#39;sul&#39;, &#39;centro-oeste&#39;],
##       dtype=object)</code></pre>
<p>It does not work anymore, of course you can still solve this “problem” with the simpler approach by including a “and” clause on your if statement but at that point you might as well use the more extensible appoach</p>
</div>
<div id="replacing-values-with-an-dictionary-1-column" class="section level4">
<h4>Replacing values with an dictionary: 1 column</h4>
<p>After looking into the categories I can create a dictionary for each column if I want to be safe on repeating terms or I can pass a master dictionary for the whole data frame, I think the column by column approach is tidier but for each their own</p>
<pre class="python"><code>dict_sex = {&quot;mulher&quot;   : &quot;woman&quot;,
            &quot;homem&quot;    : &quot;man&quot;,
            &quot;gestante&quot; : &quot;woman&quot;} # pregnant</code></pre>
<p>This is one strange data frame, it probably made sense to split women into pregnant and not pregnant but I think it will only complicate the otherwise simple analyses so I will group both into “woman”</p>
<pre class="python"><code>df.sex.replace(dict_sex,inplace = True)</code></pre>
<p>Showing the new amounts of women/mean</p>
<pre class="python"><code>df.sex.value_counts()</code></pre>
<pre><code>## woman    33679
## man      32791
## Name: sex, dtype: int64</code></pre>
<pre class="python"><code>df.sex.unique()</code></pre>
<pre><code>## array([&#39;man&#39;, &#39;woman&#39;], dtype=object)</code></pre>
<p>This fails</p>
<pre class="python"><code>pretty_value_counts(df.sex)</code></pre>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): KeyError: &#39;man&#39;
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;&lt;string&gt;&quot;, line 6, in pretty_value_counts
##   File &quot;/home/bruno-carlin/Documents/GIthub/TwoSidesData2/.venv/lib/python3.7/site-packages/pandas/core/series.py&quot;, line 1071, in __getitem__
##     result = self.index.get_value(self, key)
##   File &quot;/home/bruno-carlin/Documents/GIthub/TwoSidesData2/.venv/lib/python3.7/site-packages/pandas/core/indexes/base.py&quot;, line 4730, in get_value
##     return self._engine.get_value(s, k, tz=getattr(series.dtype, &quot;tz&quot;, None))
##   File &quot;pandas/_libs/index.pyx&quot;, line 80, in pandas._libs.index.IndexEngine.get_value
##   File &quot;pandas/_libs/index.pyx&quot;, line 88, in pandas._libs.index.IndexEngine.get_value
##   File &quot;pandas/_libs/index.pyx&quot;, line 128, in pandas._libs.index.IndexEngine.get_loc
##   File &quot;pandas/_libs/index_class_helper.pxi&quot;, line 91, in pandas._libs.index.Int64Engine._check_type</code></pre>
<p>Here is actually a example on why I don’t personally enjoy Pandas conversion of data, the function that we created pretty_value_counts is not gonna work in this example because Pandas converts a single column to an Series object, so we would have to write a pretty_value_counts for Series as well or we would have to mess with the Pandas method or we could convert the series back into a DataFrame like this</p>
<pre class="python"><code>pretty_value_counts(pd.DataFrame(data=  df.sex))</code></pre>
<pre><code>## Column sex with object data type 
##         counts  percentages  cum_percentages
## woman   33679      0.50668          0.50668
## man     32791      0.49332          1.00000</code></pre>
</div>
<div id="replacing-values-with-an-dictionary-multiple-columns" class="section level4">
<h4>Replacing values with an dictionary: multiple columns</h4>
<details>
<summary>Translation discussion on race part 2</summary>
<p>
<p>Again there is relevant discussion on whether I should translate “Parda” as brown but basically Brazil’s population sometimes answers that their skin color is “Parda” = brown when asked about for many reasons I will propose two, “Preta” black can be used as an racist term so some people prefer to be called “brown”, the second explanation is that most of the population is actually pretty well integrated meaning that there a lot of biracial couples in this case we see something like “Preta” parent + “Branca” parent = “Parda” = in English “brown”.</p>
<p>There is also the case for the English equivalent of brown skin we simply use “Indiano” = “Indian”.</p>
<p>Curiously the term “Negra” =~ &quot;N*gger&quot; is often preferred in Brazil, that may cause some confusion between Portuguese and English speakers.</p>
<p>I will use brown but do notice that there were multiple sensible approaches here.</p>
</p>
</details>
<p>This is a good opportunity to show failures in the master dictionary approach, realize that if I were to replace “nan” as no_answer or something like that python could thrown me an error because there are “nan” in some numerical columns such as salary but instead I get silence conversion of a numerical columns into object columns a dangerous feature.</p>
<pre class="python"><code>for col in list_cat:
  df[col].unique()</code></pre>
<pre><code>## array([&#39;man&#39;, &#39;woman&#39;], dtype=object)
## array([&#39;Parda&#39;, &#39;Amarela&#39;, &#39;Indigena&#39;, &#39;Branca&#39;, &#39;Preta&#39;, nan],
##       dtype=object)
## array([&#39;norte&#39;, &#39;nordeste&#39;, &#39;sudeste&#39;, &#39;sul&#39;, &#39;centro-oeste&#39;],
##       dtype=object)</code></pre>
<pre class="python"><code>dict_all = {&quot;Parda&quot;    : &quot;brown&quot;,
            &quot;Amarela&quot;  : &quot;yellow&quot;,
            &quot;Indigena&quot; : &quot;indigenous&quot;,
            &quot;Branca&quot;   : &quot;white&quot;,
            &quot;Preta&quot;    : &quot;black&quot;,
            np.nan      : &quot;no_answer&quot;}</code></pre>
<pre class="python"><code>df.replace(dict_all).salary.dtype</code></pre>
<pre><code>## dtype(&#39;O&#39;)</code></pre>
<pre class="python"><code>dict_all = {&quot;Parda&quot;    : &quot;brown&quot;, #col color_race
            &quot;Amarela&quot;  : &quot;yellow&quot;,
            &quot;Indigena&quot; : &quot;indigenous&quot;,
            &quot;Branca&quot;   : &quot;white&quot;,
            &quot;Preta&quot;    : &quot;black&quot;,
            &quot;norte&quot;    : &quot;north&quot;, # col region 
            &quot;nordeste&quot; : &quot;northeast&quot;,
            &quot;sudeste&quot;  : &quot;southeast&quot;,
            &quot;sul&quot;      : &quot;south&quot;,
        &quot;centro-oeste&quot; : &quot;midwest&quot;}</code></pre>
<p>Let’s pray that we don’t have this problem and use this shared dictionary</p>
<pre class="python"><code>df.replace(dict_all, inplace = True)</code></pre>
</div>
<div id="did-we-correctly-clean-the-categorical-variables" class="section level4">
<h4>Did we correctly clean the Categorical Variables?</h4>
<div id="conversion-of-types" class="section level5">
<h5>Conversion of types</h5>
<p>Well not really I would argue that year_study is an categorical variable as well
so let’s convert it.</p>
<pre class="python"><code>df.years_study = df.years_study.astype(&#39;category&#39;)</code></pre>
<pre class="python"><code>df.years_study.unique()</code></pre>
<pre><code>## [5.0, 8.0, 11.0, 15.0, 13.0, ..., 9.0, 10.0, 14.0, 12.0, NaN]
## Length: 12
## Categories (11, float64): [5.0, 8.0, 11.0, 15.0, ..., 9.0, 10.0, 14.0, 12.0]</code></pre>
<p>Some nan but otherwise this is could be a useful feature, I will convert it back into a numerical column so that if we can easily impute the NaN’s based on a mathematical method such as the mean of the column.</p>
<pre class="python"><code>df.years_study = df.years_study.astype(&#39;interger&#39;)</code></pre>
<pre><code>## Error in py_call_impl(callable, dots$args, dots$keywords): TypeError: data type &#39;interger&#39; not understood
## 
## Detailed traceback: 
##   File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;
##   File &quot;/home/bruno-carlin/Documents/GIthub/TwoSidesData2/.venv/lib/python3.7/site-packages/pandas/core/generic.py&quot;, line 5882, in astype
##     dtype=dtype, copy=copy, errors=errors, **kwargs
##   File &quot;/home/bruno-carlin/Documents/GIthub/TwoSidesData2/.venv/lib/python3.7/site-packages/pandas/core/internals/managers.py&quot;, line 581, in astype
##     return self.apply(&quot;astype&quot;, dtype=dtype, **kwargs)
##   File &quot;/home/bruno-carlin/Documents/GIthub/TwoSidesData2/.venv/lib/python3.7/site-packages/pandas/core/internals/managers.py&quot;, line 438, in apply
##     applied = getattr(b, f)(**kwargs)
##   File &quot;/home/bruno-carlin/Documents/GIthub/TwoSidesData2/.venv/lib/python3.7/site-packages/pandas/core/internals/blocks.py&quot;, line 559, in astype
##     return self._astype(dtype, copy=copy, errors=errors, values=values, **kwargs)
##   File &quot;/home/bruno-carlin/Documents/GIthub/TwoSidesData2/.venv/lib/python3.7/site-packages/pandas/core/internals/blocks.py&quot;, line 614, in _astype
##     dtype = pandas_dtype(dtype)
##   File &quot;/home/bruno-carlin/Documents/GIthub/TwoSidesData2/.venv/lib/python3.7/site-packages/pandas/core/dtypes/common.py&quot;, line 2055, in pandas_dtype
##     raise TypeError(&quot;data type &#39;{}&#39; not understood&quot;.format(dtype))</code></pre>
<p>Another numpy quirk you can’t use integers because there are NaN values.</p>
<pre class="python"><code>df.years_study = df.years_study.astype(&#39;float&#39;)</code></pre>
<p>Converting civil_status into a category.</p>
<pre class="python"><code>df.civil_status.unique()</code></pre>
<pre><code>## array([1., 0.])</code></pre>
<p>To know what 1 or 0 mean, so we need to check the dictionary</p>
<pre class="python"><code>dict_civil_status = { 0. : &quot;not_married&quot;,
                      1. : &quot;married&quot;}</code></pre>
<pre class="python"><code>df.civil_status = df.civil_status.replace(dict_civil_status)
df.civil_status.head()</code></pre>
<pre><code>## 0        married
## 1        married
## 2    not_married
## 3        married
## 4        married
## Name: civil_status, dtype: object</code></pre>
<p>Before we deal with numerical variables I will get rid of ‘Unnamed: 0’ and ‘id’ features because they are useless in this case.</p>
<pre class="python"><code>df.drop(columns=[&#39;Unnamed: 0&#39;, &#39;id&#39;],inplace=True)</code></pre>
</div>
</div>
</div>
<div id="python_plots_categorical" class="section level3">
<h3>Seeing the effects of categorical Variables</h3>
<p>We can use a colored barplot to see the interaction of these Categorical Variables with our Hypothesis.</p>
<pre class="python"><code>sns_plot = sns.catplot(x=&quot;sex&quot;, y=&quot;salary&quot;, hue=&quot;region&quot;, kind=&quot;bar&quot;, data=df)
plt.show(sns_plot)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-32-1.png" /></p>
<pre class="python"><code>sns_plot = sns.catplot(x=&quot;sex&quot;, y=&quot;salary&quot;, hue=&quot;civil_status&quot;, kind=&quot;bar&quot;, data=df)
plt.show(sns_plot)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-33-1.png" /></p>
<pre class="python"><code>sns_plot = sns.catplot(x=&quot;sex&quot;, y=&quot;salary&quot;, hue=&quot;color_race&quot;, kind=&quot;bar&quot;, data=df)
plt.show(sns_plot)</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-34-1.png" /></p>
</div>
<div id="cleaning-numerical-data" class="section level3">
<h3>Cleaning numerical data</h3>
<p>If we pull back the code that we used here are the numerical features of this dataset</p>
<pre class="python"><code>df.select_dtypes(include=[np.number]).columns</code></pre>
<pre><code>## Index([&#39;age&#39;, &#39;years_study&#39;, &#39;salary&#39;], dtype=&#39;object&#39;)</code></pre>
<p>It is very common to reuse these kind of codes in Data Science scripts, so you shouldn’t fell as bad about repeating yourself as you do in other endeavors such in normal software engendering and you call always clean your analysis latter.</p>
<p>In order to know what to “clean” in numerical data I like to use plot such as a histogram</p>
<pre class="python"><code>df.salary.hist(bins = 10)
plt.show()</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-36-1.png" /></p>
<p>Here we can see that the data may have a few outliers at 1000000 and that most of the salary data has a large Positive skew meaning that most data point are left to the mean of the dataset we can see that better using an density plot instead</p>
<pre class="python"><code>plot_density = df.salary.plot.kde()
plot_density.set_xlim(0,100000)</code></pre>
<pre><code>## (0, 100000)</code></pre>
<pre class="python"><code>plot_density</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-37-1.png" />
#### Replacing variables {#python_custom_function_2}</p>
<p>If we go back to our <a href="#python_custom_function_1">custom function</a> we can find that the values -1 and 999999 are unusually common after consulting the dictionary we decided to replace these values with the mean of the group.</p>
<p>This operation would be wrong for machine learning purposes since the mean of our train group would leak information from the test set as well but here in exploratory data analysis it is mostly fine also you need to replace the values with the numpy nan or else this operation doesn’t work as expected.</p>
<pre class="python"><code>df_copy = df.copy()
df_copy.salary.replace({-1: &quot;NaN&quot;,999999:&#39;NaN&#39;},inplace = True)
df_copy.salary.fillna(df.salary.mean(),inplace= True)</code></pre>
<pre class="python"><code>pretty_value_counts(pd.DataFrame(df_copy.salary))</code></pre>
<pre><code>## Column salary with object data type 
##                      counts  percentages  cum_percentages
## 19706.790323432902   18592     0.279705         0.279705
## 0.0                   1841     0.027697         0.307402
## NaN                   1468     0.022085         0.329487
## 5229.0                 277     0.004167         0.333654
## 7200.0                 260     0.003912         0.337566</code></pre>
<pre class="python"><code># Create the new na values



df.salary.replace({-1:np.nan,999999:np.nan},inplace = True)

df.salary.fillna(df.salary.mean(),inplace= True)</code></pre>
<pre class="python"><code>pretty_value_counts(pd.DataFrame(df.salary))</code></pre>
<pre><code>## Column salary with float64 data type 
##               counts  percentages  cum_percentages
## 12422.39119   20060     0.301790         0.301790
## 0.00000        1841     0.027697         0.329487
## 5229.00000      277     0.004167         0.333654
## 7200.00000      260     0.003912         0.337566
## 7560.00000      244     0.003671         0.341237</code></pre>
<p>And that is the magic of mutable Data Structures no extra assignments are required, quite useful, but be careful there is no going back if you haven’t saved a copy of your data.</p>
<div id="log-of-numerical-data" class="section level4">
<h4>Log of numerical data</h4>
<p>There is also a statisticall solution for the Positive skew in our Data we can take the log of the salary column, but we will have to add one to all values since log of 0 goes to -Inf</p>
<pre class="python"><code>df.log_salary = np.log1p(df.salary)</code></pre>
<pre><code>## /home/bruno-carlin/Documents/GIthub/TwoSidesData2/.venv/bin/activate_this.py:1: UserWarning: Pandas doesn&#39;t allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access
##   &quot;&quot;&quot;Activate virtualenv for current interpreter:</code></pre>
<p>But be carefull you can’t assign in pandas using the . you need to use the “[” operator</p>
<pre class="python"><code>df.log_salary</code></pre>
<pre><code>## 0        11.060384
## 1         9.427336
## 2         8.378713
## 3        11.478344
## 4        11.969090
##            ...    
## 66465     9.427336
## 66466     7.793999
## 66467     7.793999
## 66468     8.617075
## 66469     6.134157
## Name: salary, Length: 66470, dtype: float64</code></pre>
<pre class="python"><code>df.info()</code></pre>
<pre><code>## &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
## RangeIndex: 66470 entries, 0 to 66469
## Data columns (total 7 columns):
## age             66470 non-null int64
## sex             66470 non-null object
## years_study     66036 non-null float64
## color_race      66228 non-null object
## salary          66470 non-null float64
## civil_status    66470 non-null object
## region          66470 non-null object
## dtypes: float64(2), int64(1), object(4)
## memory usage: 3.6+ MB</code></pre>
<p>It simply is gone</p>
<p>The right way</p>
<pre class="python"><code>df[&#39;log_salary&#39;] = np.log1p(df.salary)</code></pre>
<pre class="python"><code>pretty_value_counts(pd.DataFrame(df.log_salary))</code></pre>
<pre><code>## Column salary with float64 data type 
##            counts  percentages  cum_percentages
## 9.427336   20060     0.301790         0.301790
## 0.000000    1841     0.027697         0.329487
## 8.562167     277     0.004167         0.333654
## 8.881975     260     0.003912         0.337566
## 8.930759     244     0.003671         0.341237</code></pre>
<pre class="python"><code>plot_density = df.log_salary.plot.kde(bw_method= 0.5)
plot_density.set_xlim(0,15)</code></pre>
<pre><code>## (0, 15)</code></pre>
<pre class="python"><code>plot_density</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-47-1.png" /></p>
<p>It is now a usefull feature for most simple linear models</p>
</div>
<div id="other-numerical-columns" class="section level4">
<h4>Other numerical columns</h4>
<pre class="python"><code>df.age.hist(bins = 20)
plt.show()</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-48-1.png" /></p>
<pre class="python"><code>plot_density = df.age.plot.kde()
plot_density</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-49-1.png" /></p>
<pre class="python"><code>pretty_value_counts(pd.DataFrame(df.age))</code></pre>
<pre><code>## Column age with int64 data type 
##      counts  percentages  cum_percentages
## 20    2104     0.031653         0.031653
## 28    2056     0.030931         0.062585
## 26    2040     0.030691         0.093275
## 22    2034     0.030600         0.123875
## 27    2017     0.030345         0.154220</code></pre>
<p>Age seems fine</p>
<p>Remember from the the categorical variables we passed years_study here so that we could impute its missing values</p>
<pre class="python"><code>df.info()</code></pre>
<pre><code>## &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
## RangeIndex: 66470 entries, 0 to 66469
## Data columns (total 8 columns):
## age             66470 non-null int64
## sex             66470 non-null object
## years_study     66036 non-null float64
## color_race      66228 non-null object
## salary          66470 non-null float64
## civil_status    66470 non-null object
## region          66470 non-null object
## log_salary      66470 non-null float64
## dtypes: float64(3), int64(1), object(4)
## memory usage: 4.1+ MB</code></pre>
<p>We are missing 66470 - 66036 = 434 observation, this is a small enough number that we decided to drop these rows</p>
<p>While we are droping missing values lets drop the color_race missing observations as well</p>
<pre class="python"><code>df.dropna(subset = [&quot;years_study&quot;,&quot;color_race&quot;],inplace= True)</code></pre>
<pre class="python"><code>df.info()</code></pre>
<pre><code>## &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
## Int64Index: 65795 entries, 0 to 66469
## Data columns (total 8 columns):
## age             65795 non-null int64
## sex             65795 non-null object
## years_study     65795 non-null float64
## color_race      65795 non-null object
## salary          65795 non-null float64
## civil_status    65795 non-null object
## region          65795 non-null object
## log_salary      65795 non-null float64
## dtypes: float64(3), int64(1), object(4)
## memory usage: 4.5+ MB</code></pre>
<p>Checking on year_study</p>
<pre class="python"><code>df.years_study.hist(bins = 20)
plt.show()</code></pre>
<p><img src="index_files/figure-html/unnamed-chunk-54-1.png" /></p>
<p>Let’s convert it back into a Category</p>
<pre class="python"><code>df.years_study = df.years_study.astype(&#39;category&#39;)</code></pre>
</div>
</div>
</div>
</div>
<div id="saving-our-work-for-later" class="section level1">
<h1>Saving our work for later</h1>
<p>Here we have many options we can for example run this script later or save this modified df as a csv, both options are okay but I will promote the usage of an Data format that keeps the mindful choices of encoding that we made into consideration, there are many alternatives in this case as well but I will use feather.</p>
<p>It is also always a good idea to separate the Data from the script if you want reproducible work, that is where Excel mostly fails for me.</p>
<p>So showing our Data Types</p>
<pre class="python"><code>df.dtypes</code></pre>
<pre><code>## age                int64
## sex               object
## years_study     category
## color_race        object
## salary           float64
## civil_status      object
## region            object
## log_salary       float64
## dtype: object</code></pre>
<p>Using csv will may lose some Data Types</p>
<pre class="python"><code>df.to_csv(&#39;finished_work.csv&#39;)</code></pre>
<pre class="python"><code>pd.read_csv(&#39;finished_work.csv&#39;).dtypes</code></pre>
<pre><code>## Unnamed: 0        int64
## age               int64
## sex              object
## years_study     float64
## color_race       object
## salary          float64
## civil_status     object
## region           object
## log_salary      float64
## dtype: object</code></pre>
<p>We lost our encoding of years_study and when writing a csv we made this useless to us Unnamed: 0 column</p>
<p>a better way is using the feather file format, you need to pip install pyarrow beforehand</p>
<pre class="python"><code>df.reset_index().to_feather(&#39;sex_thesis_assignment.feather&#39;)</code></pre>
<pre class="python"><code>pd.read_feather(&#39;sex_thesis_assignment.feather&#39;).dtypes</code></pre>
<pre><code>## index              int64
## age                int64
## sex               object
## years_study     category
## color_race        object
## salary           float64
## civil_status      object
## region            object
## log_salary       float64
## dtype: object</code></pre>
<p>Feather does keep the years study dtype, but feather is still in a experimental phase so be carefull with it, parquet unfortunally fails to keep the dtypes I don’t know why.</p>
<p>It is also a good idea to keep good file names so that you can easily identify your datasets and scripts.</p>
<p>If you then need to delete these files you can do it inside python</p>
<pre class="python"><code>#os.remove(&#39;finished_work.csv&#39;)
os.remove(&#39;sex_thesis_assignment.feather&#39;)</code></pre>
</div>
<div id="next-post" class="section level1">
<h1>Next post</h1>
<p>In the next post I will show the end of the analysis and the “answer” to our hypothesis.</p>
</div>
